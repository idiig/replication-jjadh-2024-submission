---
title: 古今和歌集の現代日本語訳における追加率要素の分析
author:
  - name: Xudong Chen
    corresponding: false
    roles: []
    id: jc
    orcid: 0000-0002-4542-2878
    email: xchen@shs.ens.titech.ac.jp
    affiliation:
      - name: Tokyo Institute of Technology
        city: Tokyo
        country: Japan
        url: 'https://www.titech.ac.jp/english/'
        isni: 0000000121792105
        ror: 0112mx960
  - name: Bor Hodošček
    corresponding: false
    roles: []
    id: jc
    orcid: 0000-0003-2246-8774
    email: hodoscek.bor.hmt@osaka-u.ac.jp
    affiliation:
      - name: Osaka University
        city: Osaka
        country: Japan
        url: 'https://www.osaka-u.ac.jp/en'
        isni: 0000000403733971
        ror: 035t8zc32
  - name: Hilofumi Yamamoto
    corresponding: true
    roles: []
    id: jc
    orcid: 0000-0001-6876-139X
    email: yamagen@lia.titech.ac.jp
    affiliation:
      - name: Tokyo Institute of Technology
        city: Tokyo
        country: Japan
        url: 'https://www.titech.ac.jp/english/'
        isni: 0000000121792105
        ror: 0112mx960
date: 2024/09/01
abstract: | 
  注釈書における翻訳における要素の追加を利用した古今和歌集の歌ことばのノンリテラル情報の可視化をこれまで行われてきたが、それら注釈における現代語訳や、現代語訳における追加要素に関する詳細の分析が示されていない。本論文の目的は、いままでの研究に用いられてきた古今集の現代語訳 10 種が、ノンリテラル要素の可視化に適している材料であるかについて詳細な分析を行うことである。まず、古今集の注釈における現代語訳について概観し、訳者の翻訳の意識についてまとめた。つぎに、直訳語をもたない歌ことばが原文に占める割合（不一致率）と現代語訳における追加要素の割合（追加率）の計算で、現代語訳の要素の追加と一致の実態を把握した。最後に、具体例を示し、現代語訳における追加要素の事例分析を行った。
  分析の結果、和歌の現代語訳の訳者の翻訳意識は、主観的に、作意中心・テキスト中心・読者中心と不明 4 類に分類できた。しかし、客観的には、翻訳意識が異なったとしても、計量的には同じ程度の追加要素を多く含めていた。B分析事例においては、センテンスレベルの訳においても、要素の追加にコーパスレベルの共出現傾向に基づく推論があり、語の意味の志向性について補足要素を多く足していることが確認できた。以上により、現代語訳をノンリテラルレベルの可視化に適用できることを示した。
# plain-language-summary: |
key-points:
  - a
  - b
citation:
  container-title: Journal of Japanese Association for Digital Humanities
  volume: 0
  issue: 0
  doi: 10.17928/jjadh.0.0_0
keywords:
  - 歌ことば
  - 現代語訳
  - ノンリテラル情報
license: CC BY
copyright:
  holder: 'Xudong Chen, Bor Hodošček, Hilofumi Yamamoto'
  year: 2024
funding: 'This work was supported by JSPS KAKENHI Grant Number JP18K00528 and JP23KJ0910, JP23K00545.'
format:
  html:
    code-links:
      - text: Data Import Code
        icon: file-code
        href: 'https://github.com/idiig/jjadh-replication/tree/main'
    theme: default
    toc: true
    toc-title: 目次
    toc-location: right-body
    number-sections: true
    html-math-method: katex
    fig_caption: true
    cap-location: margin
    reference-location: margin
    citation-location: document
    code-fold: true
    fig-path: artifacts/figures
    fig-format: svg
    fig-width: 6
    fig-height: 3.71
  pdf:
    toc: true
    toc-title: 目次
    number-sections: true
    fig_caption: true
    fig-path: artifacts/figures
    fig-format: svg
    fig-width: 6
    fig-height: 3.71
    pdf-engine: xelatex
    citation-location: document
  docx:
    toc: true
    toc-title: 目次
    number-sections: true
    fig_caption: true
    fig-path: artifacts/figures
    fig-format: png
    fig-width: 6
    fig-height: 3.71
    citation-location: document
execute:
  freeze: auto
  message: false
bibliography: references.bib
crossref:
  fig-title: Figure
  tbl-title: Table
  title-delim: ':\quad'
  fig-prefix: Figure
  tbl-prefix: Table
  sec-prefix: Section
  eq-prefix: Eq.
---

:::{.callout-important title="Note"}
test


```{R}
#| label: libraries
#| message: false
library(fitdistrplus)
library(tidyverse)
library(knitr)
library(rstatix)

library(brms)
library(tidybayes)
library(scales)
library(ggdist)
library(ggplot2)
library(ggpubr)
library(ggridges)
library(ggokabeito)

library(glossr)
```

```{R}
#| label: themes
theme_set_b <- function() {
  theme_void() +
    theme(
      strip.background = element_rect(
        color = "white", 
        fill = "white"
      ),
      panel.grid.major.y = element_line(
        color = "gray80",
        linetype = "solid"
      ),
      strip.text = element_text(
        color = "black",
        size = rel(1),
        angle = 90,
        vjust = 0.5,
        hjust = 1
      ),
      axis.text.y = element_text(
        color = "black", 
        hjust = 0
      ),
      strip.text.y.left = element_text(
        angle = 180
      ),
      axis.title.x = element_text(
        size = rel(1.3)
      ),
      axis.title.y = element_text(
        size = rel(1.3),
        angle = 90,
        vjust = 0.5
      ),
      legend.position = "bottom",
      legend.title = element_text(
        size = rel(1),
        face = "bold"
      )
    )
}
```
:::

# はじめに

## 目的と結論の概要

本論文の目的は、原文との非一致率、訳文においての追加率の計算と対応事例の追加要素の分析におけるという二つの側面から、和歌の現代語訳が、たとえ直訳・逐語訳に拘っているとしても、訳し方の意図が異なっても、解釈材料として、和歌における語の非字義的な情報を補足説明するために利用できることを示すことである。

本研究の主要な貢献は以下にある。

1. 材料として、著作権の消滅した @kaneko1933Kokin における古今和歌集の現代語訳における初の語彙データを公開した。
2. 古今和歌集の口語訳の歴史的変遷を俯瞰し、特に20世紀における和歌の注釈書における現代語訳の訳し方の調査と整理を行った。
3. 古語と現代語訳の語レベルの非一致率、現代語訳における追加率の計算により、翻訳アプローチにかかわらず現代語訳における情報の追加が普遍的であることを示した。
4. 具体的な現代語訳の事例を提示し、対象語のコーパスレベルの共出現語、共出現語の全体的な志向性がセンテンスレベルの現代語訳それぞれにに反映される可能性の有無を確認できた。

以上により、現代語訳をノンリテラル情報の可視化への応用が現実的であることを示した。

## 背景

### 和歌と和歌におけるノンリテラル要素

古今和歌集仮名序にあるように、歌人が「心に思ふもの」を見聞きした自然界の物事に託しており、直接明言することが珍しい。和歌のことば（以降「歌ことば」とする）を字義通り理解したところで、その「心に思ふもの」には直接アクセスしているとはいえない。古今集の恋の歌を例にあげよう：

> 初雁の鳴きこそわたれ世の中の人の心の秋しうければ (古今・恋五・貫之)

このテキストを読むとして、それぞれの語の字義的・リテラルな意味がわかれば、文字通り^[初雁が鳴いて渡ってくるのだが、人の心の秋が来るのが悲しいので（筆者訳）。]には理解できる。しかし、歌ことば辞典で「秋【あき】」[@katagiri1983Uta, 3] を調べると、リテラルな意味だけでは読まれていない情報があることに気付く。

> 秋【あき】 […]「秋」と「飽」を掛け、過ぎ去ってゆく秋と過ぎ去ってゆく愛を惜しむことが多かった。【脚注】[雁の]「鳴く」を人が「泣く」と同列にしか把握しない […]

この記述に従い読み解いていけば、恋人の心が「飽き（秋）」て、歌人が「泣（鳴）」いている「失恋」の話であろうと推測される。このように「秋」から読み取る「飽きる恋」の情報は、原文の文脈（周辺語）ではノンリテラル的、つまりノンリテラルであるため、語の文字通りの意味だけでは読み取れない。厳密に語のノンリテラル情報の範囲を限定することが難しいが、ここでは限定として 2 つとりあげる：

1. 物理的にテキストに出現しない
2. 性質上ではその語由来の連想にかかわる説明か、その語の言語変種（地域方言・社会方言・時代・年代など）にかかわる説明

### 現代語訳の追加要素に基づく歌ことばのノンリテラル要素の可視化 

このようなノンリテラル的要素の可視化に向けて、古今和歌集の 10 人の現代日本語訳をベースにした可視化システムは、筆者らがこれまでに開発を行ってきた [@Yamamoto2005Mathematical; @Yamamoto2006Extraction; @chin2022Tango; @Chen2024Translationbased]。理論背景としてコミュニケーションモデルに立脚し、古語と現代語訳との相対化に見えてくる補足要素に歌ことばのノンリテラル情報が含まれていることしている。

ここでの現代語訳との相対化というのは、現代語の要素（要素の決め方も重要な課題であり、本稿では対象としない）の集合から和歌の原文の要素を取り除き、現代語にしか存在しない要素を諸手法により引き立てることである。この考えが @kondo2001Ngram, @kondo2011Heian では「引き算」と称している。しかし、引き算で残った要素、つまり現代語訳で追加された要素は、どのような性格であるか、ノンリテラル要素に捉えられるかいなか、明確にする必要がある。

翻訳における要素の追加などの処理と操作に関して、@Koller1979Einfuehrung [p. 249] では翻訳者による「介入 (Eingriff)」としている。「無害」とされる介入には、目的言語の読者の不足している背景知識や、デノテーション・コノテーション面の情報、そして、言語内的、社会文化的、間テキスト的な情報の損失を補うための注釈付き翻訳手法の結果としての追加が含まれていると指摘している [@Koller1979Einfuehrung p. 249]。そこで、翻訳が注釈・辞書同様に解釈資料としてノンリテラル的な情報の抽出に有効な材料と認識しうる。

ただし、翻訳における追加は読者の理解力を過大評価・過小評価した産物にもありうる [@Nida1964Science, p. 155; @Koller1979Einfuehrung, pp249--250]。この点においては、訳者による翻訳の追加要素のバリエーションは無視してはならない。古今和歌集の歌ことばの解釈資料としての現代語訳の有用性については、@Chen2024Translationbased  では触れたものの、そのバリエーションについて十分説明されていない。材料として和歌の口語訳の歴史、使用してきた 10 人の現代語の背景や、訳者個人個人の翻訳の見方を踏まえ再検討する余地が大いにある。

したがって、本稿では材料として使用してきた 10 種類現代語訳の成立背景、追加要素の量的性質、質的性質について分析を行う。前述にあったように、翻訳における追加は読者の理解力の過大評価・過小評価に基づき生成された産物である可能性があるため、異なる訳者が和歌の情報をどこまで現代読者に開示しているか、あるいは開示できるか、それぞれ独自の考えがあるはずである。訳者の翻訳アプローチの意識を整理し、その異同を明確にする。そして、10 人の翻訳の実践としてにはそれぞれ主観的に意識している翻訳アプローチを守っているかを客観的に分析することで、翻訳の普遍的な課題と限界を考察することができよう。

以上の知見を踏まえ、ノンリテラル的要素の可視化システムの根拠をより明確にでき、さらにその改善の方向性をも明確にできる。

## 問題意識と本稿の構成 Research questions and structure

ノンリテラルな要素の可視化の前提として、本稿では具体的に以下 4 つの面から再検討する：

1. 注釈書における現代語訳の背景の調査、翻訳アプローチの調査と分類
  - 訳者の翻訳の主観意識はどのように分類するか。
2. 現代語訳において原文の要素が削りが量的に少ないであることの明確化
  - 訳文に一致要素が存在しない原文の要素（不一致率）がどれほどあるか。
3. 現代語訳における追加要素が翻訳アプローチを問わず量的に十分であることの証明
  - 訳文において追加要素がどれほどあるか、翻訳アプローチによる統計的に差が認められるか。
4. 現代語訳におおける追加要素がノンリテラル情報として扱えることの説明：
  - コーパスレベルの共出現情報の全体的傾向が、翻訳の追加要素に反映される例があるか。

本稿は次のように構成される：@sec-materials では、材料 10 人の現代語訳の説明に兼ねて、20 世紀の和歌の口語訳の成立の背景をまとめる。 @sec-methods では、本稿の 4 つのリサーチクエスチョンに対しそれぞれの方法の詳細を説明する。@sec-results では方法と結果で得られた結果を提示し、@sec-conclusions では結果に対する考察と課題を行う。最後に、本稿の結論を述べる。

# データ：古今集、注釈と現代語訳 {#sec-materials}

本節では、材料である古今集の説明に併せ、和歌、古今集、注釈と、その現代語訳について、その歴史的な事情について概観する。

## 古今集

和歌は「歌」「詠む」と言われるだけあって、本来は、宮廷で、声を上げて歌われていたものであり、基本的に当時の話しことばである。古今集はその名前が示すように、それ以前の古代の歌と当時の歌を集めたものである。
古代の和歌は、主に『万葉集』に収められた和歌を指し、7 世紀から 8 世紀の和歌も収録され、山部赤人、柿本人麻呂、額田王など和歌の歴史上重要な歌も仮名で収められている。

古今集は、その後の勅撰和歌集、二十一代集の冒頭に成立し、その後の勅撰和歌集の基本的な形式を確立したものである。その序章には、編者、紀貫之による古今和歌集仮名序が記載されており、和歌の理論書として位置付けられている。和歌文学の研究資料として、のちの本歌取りの元歌の前提とされている、「源氏物語」、「土佐日記」、「伊勢物語」ほか、数々の作品に掲載されている、など日本文学の基本的な資料としても重要である。また、前述のように、話しことばの特徴を持つため、日本語の歴史的変遷を知る上でも重要な資料となっている。

## 古今集の注釈と現代日本語訳

日本古典文学の歴史において、古今集は数多くの注釈書を生み出し、その注釈書はそれ自体の歴史ができるほどである [@kubota1960Kokin, 319]。注釈書に見られる多くの現代語訳は読者の和歌の理解を助けるために書かれており、翻訳家の翻訳目的は主に和歌の解釈を伝えるためである。近代については、必ずしも現代語とは言えないが、無視するわけにはいかないので、近代までの古今集の注釈の歴史を簡略に説明し、明治以後、注釈書掲載の現代語訳について考察する。

近代 (1868年) 以前は多くの古今集の注釈書が出版された。近代前（1600 年--1868 年）の間に、70 以上の注釈書が出版されている [@kojima1989Kokin, 447--450]。表 @tbl-annotation は近代前の著名な注釈書名を 5 つ示す。

北村季吟の八代集抄は 108 巻（50 冊）からなる八代集^[八代集とは古今集、後撰集、拾遺集、後拾遺集、金葉集、詞花集、千載集、新古今集の 8 つの勅撰集である。]の注釈書である。契沖（1640--1701）の古今和歌集余材抄は最初の実践的な古今集の研究書である [@ozawa1971Kikon, p.36]。賀茂真淵（1697--1767）による古今和歌集打聴は基本的に契沖のものを継承したものである。しかし、賀茂真淵は新しい歌よりも万葉集のような古今以前の歌に焦点を当てている。本居宣長の古今和歌集遠鏡はすべての和歌を当時の口語に翻訳する試みである^[しかしながら、本居の翻訳意図は他の現代語の翻訳者のものとは少々異なっている。本居の意図は、古今集の注釈としてではなくて、純粋に人々に古今集がおもしろく価値のある文学であることを伝えようとしたところにあり、このことから本研究においてこの翻訳を他の翻訳者と同等に扱うことはできない。さらに、@Shiozawa1993Motoori によると、遠鏡で使われている口語表現の実態、すなわち、どんな単語が使われているのか、どういう意味なのかがはっきりわかっているわけではないし、江戸時代の口語表現それ自身についても明らかになっているわけではないので、本研究で取り扱うことはできない。]。香川景樹（1768--1843）は「古今和歌集正義」でそれ以前の注釈書をかなり強い調子で批判している [@ozawa1971Kikon, p. 36; @matsuda1968Shinshaku, p. 58]。とはいえ、1868年以来の多くの注釈書は上記の注釈書の影響を多かれ少なかれ受けていることは確かである。

現代になって重版、改訂などを含めて古今集の注釈書は 30 あまりと多数出版されているようである。

::: {#tbl-annotation}

| Author                       | Year   | Annotation book title                         |
| ---------------------------- | ------ | --------------------------------------------- |
| Kitamura Kigin 北村季吟        | 1682   | *Hachidaishūshō* 八代集抄                   |
| Keichū 契沖                    | 1692   | *Kokin Yozaishō* 古今余材抄                   |
| Kamo no Mabuchi 賀茂真淵       | 1784   | *Kokinshū Uchigiki* 古今和歌集打聴       |
| Motoori Norinaga 本居宣長       | 1793?  | *Kokin Tōkagami* 古今集遠鏡                   |
| Kagawa Kageki 香川景樹         | 1832   | *Kokinshū Seigi* 古今和歌集正義           |

: 近代前（1600--1868）の古今集の代表的な注釈書

:::

## 20 世紀の注釈における現代語訳とデータの概要

21 世紀に入っても現代語訳を含む注釈書が多数出版されているが、これまでの可視化システムの研究において整備できたものは、比較的近代以後に出版された古今集の現代語訳である [@tbl-CT-data]。それぞれ、本稿の研究対象でありデータでもある。

データフォーマットは、@Hodoscek2023Development で公開された space-delimited format に準拠している。トークンタイプの識別子（メタコード）として、旧分類語彙表番号が付与されている。データセットの特徴は、多義語に複数分類語彙表番号が付与されていることと、複合語にその下位分解を同時に提供していることがあげられる。複数の基準でフレキシブルな分析に対応できる。

ただし、これらの注釈書から文字化されたデータは和歌の現代語訳の著作権、校訂著作権、翻刻著作権などがあり、公開できない。本稿では、そのうち、著作権の消滅した @kaneko1933Kokin のデータのみを公開する。

<!-- |     | Abbr. | Reference          | Manuscript  | Token count | Type count | Document count | -->
|     | 略号 | 注釈書          | 底本  | トークン数 | タイプ数 | 文書数 |
|-----|-------|--------------------|-------------|------------:|-----------:|---------------:|
| 1   | KNK   | @kaneko1933Kokin        | Teika       | 42,439      | 3,356      | 1,000          |
| 2   | KBT   | @kubota1960Kokin          | Teika       | 32,210      | 2,701      | 1,000          |
| 3   | MTD   | @matsuda1968Shinshaku     | Teika       | 31,860      | 3,007      | 1,000          |
| 4   | OZW   | @ozawa1971Kikon           | Teika       | 36,173      | 3,384      | 1,000          |
| 5   | TKOK  | @takeoka1976Kokin         | Teika       | 29,844      | 2,861      | 1,000          |
| 6   | OKMR  | @okumura1978Kokin         | Teika       | 32,321      | 3,153      | 1,000          |
| 7   | KSJ   | @kyusojin1979Kokin        | Teika       | 34,050      | 2,770      | 1,000          |
| 8   | KMCY  | @komachiya1982Kokin       | Teika       | 30,869      | 2,692      | 1,000          |
| 9   | K&A   | @kojima1989Kokin          | Teika       | 33,867      | 2,955      | 1,000          |
| 10  | KTGR  | @katagiri1998Kokinhyoshaku| Teika       | 36,362      | 2,882      | 1,000          |
|     | Total |                           |             | 339,995     | 8,252      | 10,000         |

: 古今和歌集の短歌の20世紀の現代語訳 10 種：トークン・タイプ数の集計においては、複合表現の場合、その下位分解をカウントしていない。 {#tbl-CT-data}

```{python}
#| label: read-raw-db

from typing import List

def poem_mode(poem: str, mode: int = 2) -> List[str]:
    """
    Function to filter and output data based on the given mode.

    Mode 1: Original output.
    Mode 2: Filter rows where the decomposition code starts with 'A' or 'B' or 'D' and the first digit of the number part is '0'.
    Mode 3: Filter rows where the decomposition code starts with 'A' or 'C' or 'E' and the first digit of the number part is '0',
            and filter out decompositions of multi-sense words (i.e., if a 'B' or 'D' row is found, skip its 'C' or 'E' blocks).

    :param poem: A string block with multiple lines of input data representing the poems.
    :param mode: Mode to determine the filtering behavior:
        - 1: Original output.
        - 2: Basic sense, ignore decomposition ('A', 'B', 'D' with '0' in decomposition code).
        - 3: Basic sense, consider decomposition ('A', 'C', 'E' with '0' in decomposition code), and filter multi-sense decompositions.
    :return: Filtered list of strings based on the mode.
    """
    if mode == 1:
        # If mode is 1, return the original poem string split by lines
        return poem.strip().splitlines()

    # Split the input string by lines and further split each line by whitespace for other modes
    data = [line.split() for line in poem.strip().splitlines()]
    result = []

    skip_decompositions = False  # Flag to skip decompositions related to 'B' or 'D' rows

    for row in data:
        decomposition_code = row[1]  # Second column represents the decomposition code
        first_char = decomposition_code[0]  # Get the first character of the decomposition code (A, B, C, D, or E)

        # Ensure the first character is one of 'A', 'B', 'C', 'D', or 'E'
        assert first_char in ['A', 'B', 'C', 'D', 'E'], f"Unexpected decomposition code: {decomposition_code}"

        # Explanation of decomposition code first_digit:
        # 0: Basic sense (primary meaning)
        # Other integers: Other senses (secondary meanings or further decompositions)
        first_digit = decomposition_code[1]  # Get the first digit of the numeric part (0 for basic sense)

        if mode == 2 and first_char in ['A', 'B', 'D'] and first_digit == '0':
            # Mode 2: Basic sense, ignore decomposition (A, B, D)
            result.append(" ".join(row))
        elif mode == 3:
            if skip_decompositions and first_char in ['C', 'E']:
                # Skip 'C' or 'E' decompositions after 'B' or 'D' multi-sense lines
                continue
            elif first_char in ['B', 'D'] and first_digit != '0':
                # If we encounter a multi-sense row (first digit != '0'), we set the flag to skip its decompositions
                skip_decompositions = True
            else:
                skip_decompositions = False  # Reset the flag if we're not in a multi-sense situation

            if first_char in ['A', 'C', 'E'] and first_digit == '0':
                # Mode 3: Basic sense, consider decomposition (A, C, E)
                result.append(" ".join(row))

    return result
  

def translation_mode(translation: str, mode: int = 2) -> List[str]:
    """
    Function to filter and output translation data based on the given mode, with an added functionality to number each token
    and remove punctuation based on the POS column (6th column).

    Mode 1: Original output.
        - Returns the translation data with numbering, as is.

    Mode 2: Ambiguity set to 1, ignore decomposition.
        - Filters rows where the first column is 1 (ambiguity set to 1) and the fourth column is 0 or 1 (decomposition ignored),
          and skips the current row if the next row's fourth column is 3.

    Mode 3: Ambiguity set to 1, consider decomposition.
        - Filters rows where the first column is 1 (ambiguity set to 1) and the fourth column is 0, 2, or 3 (decomposition considered),
          and skips the current row if the next row's fourth column is 3.

    Additionally, each token will be numbered based on the decomposition field (4th column) and punctuation will be removed
    based on the POS column (6th column):
        - If the POS column is 76 or greater, the line is considered a punctuation and will be skipped.
        - The number will be added at the end of each line.

    :param translation: A string block with multiple lines of input data, representing the translations.
    :param mode: Mode to determine the filtering behavior.
        - 1: Original output
        - 2: Ambiguity set to 1, ignore decomposition
        - 3: Ambiguity set to 1, consider decomposition
    :return: Filtered list of strings with numbered tokens based on the mode.
    """
    # First, remove punctuation and add global numbering to the tokens
    numbered_data = []
    for line in translation.strip().splitlines():
        clean_line = _remove_punctuation(line)
        if clean_line:  # Skip the line if it's a punctuation
            numbered_data.append(_add_token_numbering(clean_line))

    # If mode is 1, return the data directly without any filtering
    if mode == 1:
        return numbered_data

    # Now apply the mode filtering for mode 2 and 3
    result = []
    for i, row in enumerate(numbered_data):
        row_fields = row.split()
        ambiguity = int(row_fields[0])
        decomposition = int(row_fields[3])

        # Apply filtering based on mode
        if mode == 2 and ambiguity == 1 and decomposition in [0, 1]:
            result.append(row)  # Ambiguity set to 1, ignore decomposition
        elif mode == 3 and ambiguity == 1 and decomposition in [0, 1, 3]:
            # Check if the current row's fourth column is 1, and if the next row's fourth column is 3
            if decomposition == 1 and i + 1 < len(numbered_data) and int(numbered_data[i + 1].split()[3]) == 3:
                continue  # Skip current row if the next row's fourth column is 3
            result.append(row)  # Ambiguity set to 1, consider decomposition

    return result


def _add_token_numbering(line: str) -> str:
    """
    Internal function to add numbering to each line based on the decomposition field (4th column).

    :param line: A single line of the translation data.
    :return: The line with numbering added to the end of the line.
    """
    row = line.split()
    decomposition_field = row[3]  # The decomposition field (4th column)

    # Static variable to hold the token counter across function calls
    if not hasattr(_add_token_numbering, "token_counter"):
        _add_token_numbering.token_counter = 0

    # Check the decomposition field and update the token counter accordingly
    if decomposition_field != "0" and decomposition_field != "1":
        row.append(str(_add_token_numbering.token_counter))
    else:
        _add_token_numbering.token_counter += 1
        row.append(str(_add_token_numbering.token_counter))

    return " ".join(row)


def _remove_punctuation(line: str) -> str:
    """
    Internal function to remove lines that are considered punctuation based on the POS column (6th column).

    :param line: A single line of the translation data.
    :return: The original line if it is not punctuation, otherwise an empty string.
    """
    row = line.split()
    pos_column = int(row[4])  # POS column is the 5th column
    polysemy_colomn = row[0]  # Polysemy coloum is first column

    # POS 76 and greater are considered punctuation, so we skip them
    # When polysemy_colomn is N, the row is un validated, so we skip them
    if pos_column >= 76 or polysemy_colomn == "N":
        return ""  # Return an empty string to indicate this line is punctuation and should be skipped

    return line
```

# 方法 {#sec-methods}

現代語訳からノンリテラル要素が効率よく抽出できるかの問題に対して、2 つの ステップで確認する。第一に、訳者の翻訳に対する主観的な認識を明確にし、主観的な認識においてノンリテラル情報の扱い方への言及を精査する。第二に、客観的にそれぞれの翻訳実践がその翻訳アプローチにの主観意識に従っているかいなかを調査する。

訳者の主観的意識・認識の調査には、注釈書における現代語訳の方針に関する言及の文献調査を行い、主に訳者の翻訳行動に際してのフォーカスを分類する。訳者の実践において、訳、とりわけ訳における要素の追加がその翻訳のアプローチに影響されているか、どの程度影響されているかについて、原文要素の不一致率、訳における追加率を算出し、統計的に翻訳アプローチによる差があるか明確にする。さらに、訳における追加要素がノンリテラル要素として認められるかについて、事例分析を行う。

具体的な方法の説明は次につづく。

## 文献調査による翻訳アプローチの分類

本節では 20 世紀の古今集の注釈書の著者の現代語訳執筆方針について文献調査を行い整理する。 @Yamamoto2005Mathematical [p. 102] では、訳者の理論的考えを踏まえつつ、それぞれの現代語訳を実際に観察し、「逐語訳 (word-for-word) 」「作者の意思の尊重 (intension-oriented)」「字句を補う (supplement for words)」「語順・語法を変える (word change)」「不詳 (not mentioned)」のように分類しているが、「作者の意思の尊重 (intention-oriented)」は翻訳の目標・フォーカスであり、その他は具体的な訳し方である、分類の視座が統一されていない。そのため、基準の統一た分類が必要である。ここでは、@Yamamoto2005Mathematical で採用された @Schramm1954Process のコミュニケーションモデルの観点から翻訳の力点の置き方の分類を行う (@fig-schramm-schema)。

現代語訳のコミュニケーションモデルは 2 つのサブプロセスを含めている。翻訳者が 10 世紀のサブプロセスの受信者でありながら、20 世紀のサブプロセスの発信者である。2 つのサブプロセスの経験野をコミュニケートする役割を果たしている。

このモデルの考え方に基づき、翻訳アプローチを 3 つに分類する：

1. 歌人本位のアプローチ (Poet-focused approach): 10 世紀のサブプロセスの中のソースである歌人の作意をハイライトする
2. 原文本位のアプローチ (Text-focused approach): 10 世紀のサブプロセスにおけるシグナルであるテキストの文字通りの意味をハイライトする
3. 読者本位のアプローチ (Reader-focused approach): 20 世紀のサブプロセスの中のデスティネーションである読者の理解をハイライトする

そのほかには、翻訳においては、訳自体のもつ読み物としての文学性、つまり 20 世紀の中のシグナルを重視するアプローチも想定できるが、注釈における訳であるため訳の面白さや文学性への重点的なが考えにくい。ここでは触れないようにする。

::: {#fig-schramm-schema layout-nrow=2}
![コミュニケーションモデル](figures/fig-process-comm.svg){#fig-schramm-schema-orig}

![翻訳アプローチの分類とコミュニケーションモデルにおける位置づけ](figures/fig-schema-op-ct-tikz.svg){#fig-schramm-schema-adap}

コミュニケーションモデルから見る翻訳アプローチの分類

:::

## 追加率・不一致率の計算

読者本位・歌人本位の訳文は解釈と推論の追加の可能性が高いため、ノンリテラル要素を多く抽出できそうであると思われる。しかし、訳者の主観的に読者本位・歌人本位と意識しても、翻訳実践と翻訳アプローチのずれが存在しないわけではない。この点について、客観的に追加率の調査で明確にしなければならない。それぞれの訳者が自身の翻訳アプローチに従い、どこまで一貫して訳しているかについて、実際の和歌と現代語訳の不一致率で計算する。不一致率の計算は、要素の順序と重複を考慮しない集合演算による方法（バッグ法）と、要素の順序と重複を考慮するアライメントによる方法（整列法）を考えている。手順については @Yamamoto2005Mathematical と @Yamamoto2019Analysis にもあるが、説明の紙幅で明確に手順を示さなかった。本稿では先行研究で曖昧な部分を含め、計算のプロセスを明確にする。

@Yamamoto2005Mathematical と @Yamamoto2019Analysis のアプローチは、分解可能でかつ語の複数の意味のメタコードを同時に保持して不一致率の計算を行っている。つまり和歌の語のデフォルトの分類語彙表番号、または、複合語において一致語がある場合、その下位分解やその他の意味の一致可能性について省略する。逆の場合は、その下位の分解や他の潜在的な意味における一致の可能性を考慮して探索する。したがって、和歌の述べ語数を計算する際、複合語単位で対応するか、単語のどの意味で一致がるか，対象となる単位が結果から遡り動的に決められている。このアプローチのメリットは、複合表現対複合表現の一致を優先することと多義語の複数の意味のうち、いずれかの一致の可能性を計算の中間プロセスに含めることにある。 実際の計算において、このアプローチには強い前提が設けられている：翻訳者が主観的な努力として 100% の情報を翻訳に含めようとしていると見なしている。そのため現代語において形式的に一致語が存在しない語であっても、原文のいずれかの要素と潜在的に 1 対 1 で対応しているとして、追加率を計算する際追加率からその分が引かれている（残った追加率を純粋なアノテーション (pure annotation) と呼んでいる）。 しかし、明らかに歌ことばに対応語が存在しないことは、その語の情報の欠落を訳者が認識していることでもあるため、逐語で訳されている前提は理論的である。
また、対応の単位が変動するため追加率の分母である訳語の数のカウントが変動し、個々の翻訳者の追加率の比較においては直感的でない問題もあるように思われる。

そこで本稿では、追加率の計算の説明の明確化と結果の再現性について補足を行う。計算における調整は、当初の結論を覆すものではない。本稿の計算では、単位の設定のデフォルトの分類語彙表の意味メタコードと、分解された最小単位に統一した上で行う。^[計算のスクリプトは、ほかの選択肢を与えている。]

#### 旧分類語彙表番号（旧 WLSP 番号）に基づく一致の層づけ {.unnumbered}

歌ことばと現代語訳語の「一致・不一致」は、次の式のように、二語のメタコード（旧 WLSP 番号）の最長共通部分列 (Longest common subsequence, LCS) [@Sankoff1972Matching; @Traum2000Generation] の長さで $U$（不一致）, $G$（グループマッチ）, $F$（フィールドマッチ）, $E$（正確マッチ）の 4 つに層づけする。

$$
\text{match}(s,t) \in
\begin{cases}
U, & \text{if } \text{LCS}(s,t) < 10 \\
G, & \text{if } 10 \leq \text{LCS}(s,t) < 13 \\
F, & \text{if } 13 \leq \text{LCS}(s,t) < 17 \\
E, & \text{if } \text{LCS}(s,t) \geq 17 \\
\end{cases}
$$

この式では、$s$ はソーステキスト（和歌）における語のメタコードであり、$t$ はターゲットテキスト（現代語訳）における語のメタコードである。$\text{LCS}(s,t)$ は $s$, $t$ 二語のメタコードの Longest common subsequence である。以下具体の分類例をあげる。

1. **Unmatch** ($\text{match}(s,t) \in U$; $\text{LCS}(s,t)=4$):
  - $s=$ `[BG-0]1-5520-20-0401` 梅 (plum)
  - $t=$ `[BG-0]8-0061-07-010-A` の (of, genetive case)
2. **Group match** ($\text{match}(s,t) \in G$; $\text{LCS}(s,t)=11$):
  - $s=$ `[BG-01-5520-]20-0401` 梅 (plum)
  - $t=$ `[BG-01-5520-]19-115-A` 秋萩 (autumn)
3. **Field match** ($\text{match}(s,t) \in F$; $\text{LCS}(s,t)=11$):
  - $s=$ `[BG-01-2030-01-]0300` 神 (god)
  - $t=$ `[BG-01-2030-01-]030-A` 仏 (Buddha)
4. **Exact match** ($\text{match}(s,t) \in E$; $\text{LCS}(s,t)=17$):
  - $s=$ `[BG-01-5520-20-040]1` 梅 (plum)
  - $t=$ `[BG-01-5520-20-040]-A` 梅 (plum)

The agreement ("match/unmatch") between poetic words and their contemporary translations is categorized into four layers—$U$ (Unmatch), $G$ (Group Match), $F$ (Field Match), and $E$ (Exact Match)—determined by the length of the Longest Common Subsequence (LCS) [@Sankoff1972Matching; @Traum2000Generation] between the two words' metacodes (old-version WLSP codes), as outlined in the following formula.

$$
\text{match}(s,t) \in
\begin{cases}
U, & \text{if } \text{LCS}(s,t) < 10 \\
G, & \text{if } 10 \leq \text{LCS}(s,t) < 13 \\
F, & \text{if } 13 \leq \text{LCS}(s,t) < 17 \\
E, & \text{if } \text{LCS}(s,t) \geq 17 \\
\end{cases}
$$

In this formula, $s$ represents the metacode of a word in the source text (the poem), and $t$ represents the metacode of a word in the target text (the contemporary translation). $\text{LCS}(s,t)$ refers to the LCS between the two metacodes $s$ and $t$. Below, we provide examples for each classification.

1. **Unmatch** ($\text{match}(s,t) \in U$; $\text{LCS}(s,t)=4$):
  - $s=$ `[BG-0]1-5520-20-0401` 梅 (plum)
  - $t=$ `[BG-0]8-0061-07-010-A` の (of, genetive case)
2. **Group match** ($\text{match}(s,t) \in G$; $\text{LCS}(s,t)=11$):
  - $s=$ `[BG-01-5520-]20-0401` 梅 (plum)
  - $t=$ `[BG-01-5520-]19-115-A` 秋萩 (autumn)
3. **Field match** ($\text{match}(s,t) \in F$; $\text{LCS}(s,t)=11$):
  - $s=$ `[BG-01-2030-01-]0300` 神 (god)
  - $t=$ `[BG-01-2030-01-]030-A` 仏 (Buddha)
4. **Exact match** ($\text{match}(s,t) \in E$; $\text{LCS}(s,t)=17$):
  - $s=$ `[BG-01-5520-20-040]1` 梅 (plum)
  - $t=$ `[BG-01-5520-20-040]-A` 梅 (plum)

```{python}
#| label: match-string

from difflib import SequenceMatcher

def LCS(s: str, t: str) -> int:
    """
    Calculate the length of the longest common subsequence (LCS) between two strings.

    This is an internal function that uses a sequence matching algorithm to determine
    the longest common subsequence between the two input strings.

    :param s: The first input string.
    :param t: The second input string.
    :return: The length of the longest common subsequence between the two strings.
    """
    seq_matcher = SequenceMatcher(None, s, t)
    match = seq_matcher.find_longest_match(0, len(s), 0, len(t))
    return match.size


def match_category(s: str, t: str) -> str:
    """
    Classify the match between two strings into one of four categories based on the LCS (Longest Common Subsequence) length.

    The function calculates the LCS length between two strings and classifies the match into one of four categories:
    - 'U': [U]nmatch, when LCS length is less than 10.
    - 'G': [G]roup match, when LCS length is between 10 and 12.
    - 'F': [F]ield match, when LCS length is between 13 and 16.
    - 'E': [E]xact match, when LCS length is 17 or greater.

    :param s: The first input string to compare.
    :param t: The second input string to compare.
    :return: A string representing the match category ('U', 'G', 'F', or 'E') based on the LCS length.
    """
    # Calculate LCS length using the internal function
    lcs_length = LCS(s, t)

    # Categorize based on the LCS length
    if lcs_length < 10:
        return "U"
    elif 10 <= lcs_length < 13:
        return "G"
    elif 13 <= lcs_length < 17:
        return "F"
    else:
        return "E"
```

#### バッグ法による不追加率の計算 Calculation of addition rate using the bag method {.unnumbered}

バッグ法による追加率（現代語訳における和歌原文に対する追加要素の割合）は、2 つのテキストを 2 つの集合と見做し、順序関係せず集合における一致語の数をもとに計算する。ソーステキスト（和歌）$S=(s_i)_{i \in \mathbb{Z}^{+}}$ とターゲットテキスト（現代語訳） $T=(t_i)_{i \in \mathbb{Z}^{+}}$ が与えられた時、2 テキストのターゲットテキストにおける追加率の計算は下記に従う。

$$
\begin{align}
\text{U}_{T}(S,T) &= 1 - \frac{1}{|T|}\text{agreement}_{S}\\
\text{agreement}_{S} &= \sum_{s_i \in S} \mathbb{I} \left( \exists t_j \in T \text{ such that } \text{match}(s_i, t_j) \notin U \right)
\end{align}
$$

$\text{agreement}_{S}$ は、ソーステキストにおける 2 テキストの重複なし (non-repetive) の一致語をもつトークンの数である。$\frac{1}{|T|}\text{agreement}_{S}$ を一致率（バッグ法）と定義する。分母ははターゲットテキストのトークン数にしている。$|T|$ はターゲットテキストの長さを指し、$s_i$, $t_j$ はそれぞれソーステキストの $i$ 番目と、ターゲットテキストの $j$ 番目のトークンを意味する。追加率は 1 から一致率を引いて計算する。$\mathbb{I}$ は指示関数（Indicator Function）であり、インプットが真（$s_i$ が訳において一致語が存在する）の場合 1 を、偽（$s_i$ が訳において一致語が存在しない）の場合 0 を返す。^[ここの一致率の計算の厳しさは $\mathbb{I}$ 内の条件で調節できる。ここでは、$E, F, G$ のいずれかのレベルで一致できていれば、1 を返すように設定している。]

ここでの計算で注意されたいのは、一致率の分子が原文の語が一致語をもつトークンの数であり、訳文の語が一致語をもつケースの数ではない。つまり、現代語訳における一対多の訳は、その中の一部のみが和歌の要素と一致し、残りの部分が追加要素にあたるという認識である。たとえば、「散る」を「散り乱れる」と訳す場合は、一対多の訳とするべきかはやはり曖昧であり、本稿では処理の一貫性を重視するため、短単位の訳について一対一の訳を大前提としている。^[そのかわりに、本稿ではデータベースを利用して 3 パターンの単位基準の入力を提供している：多義性と複合単位を無視し短単位のみでの計算、多義性を無視し複合単位を優先する計算と、多義性の複合単位の潜在的分解をそのまま残す計算を選択できる。結果の報告では短単位で進める。]

一方で、不一致率は、原文にある要素のうち、訳において一致語が存在しない割合として同様な計算を行う。ここではもちろん、分母をソーステキストの数にしている。

$$
\begin{align}
\text{U}_{S}(S,T) &= 1 - \frac{1}{|S|}\text{agreement}_{S}
\end{align}
$$

バッグ法で計算された追加率は、統計分析に用いて訳者の主観的意識による影響を検証する（詳しくは次節参照）。
不一致率については初歩的な記述統計でまず確認する。

We calculate the addition rate, which represents the proportion of additional elements in the contemporary translation relative to the original poem, using the bag method. In this approach, we treat both texts as sets and base the calculation on the number of agreements without considering their order. Given the source text (poem) $S=(s_i)_{i \in \mathbb{Z}^{+}}$ and the target text (contemporary translation) $T=(t_i)_{i \in \mathbb{Z}^{+}}$, we calculate the addition rate for the target text as follows:

$$
\begin{align}
\text{U}_{T}(S,T) &= 1 - \frac{1}{|T|}\text{agreement}_{S}\\
\text{agreement}_{S} &= \sum_{s_i \in S} \mathbb{I} \left( \exists t_j \in T \text{ such that } \text{match}(s_i, t_j) \notin U \right)
\end{align}
$$

Here, $\text{agreement}_{S}$ represents the number of tokens in the source text that have non-repetitive agreements with tokens in the target text. The term $\frac{1}{|T|}\text{agreement}_{S}$ gives the agreement rate (bag method) for the translation, where the denominator is the total number of tokens in the target text. We use $|T|$ to denote the total number of tokens in the target text, and $s_i$, $t_j$ to represent the $i$th and $j$th tokens in the source and target texts, respectively. We calculate the addition rate by subtracting the agreement rate from 1. The indicator function $\mathbb{I}$ returns 1 if the input condition is true (i.e., if $s_i$ has an agreement in the translation), and 0 if it is false (i.e., if $s_i$ has no agreement in the translation). ^[We can adjust the strictness of the agreement rate calculation through the conditions within $\mathbb{I}$. In this case, the function returns 1 if a match exists at any of the $E$, $F$, or $G$ levels.]

One key point is that the numerator of the agreement rate reflects the number of agreements in the source text, not the number of agreements in the translation. This approach allows us to recognize one-to-many translations in the target text, where part of the translation corresponds to elements in the poem, while the rest is considered additional. For example, translating "chiru" 散る (scatter) as "chirimidareru" 散り乱れる (scatter wildly) raises the question of whether this should be treated as a one-to-many translation. To ensure consistency, we assume a one-to-one translation as the default for simplex units. ^[We also provide three input unit options in the database: one that ignores polysemy and focuses only on simplex units, one that prioritizes compound units while ignoring polysemy, and one that retains potential decompositions of compound units. For this paper, we use the simplex unit approach.]

We calculate the unmatch rate similarly, as the proportion of elements in the source text that have no agreement in the translation, using the following formula:

$$
\begin{align}
\text{U}_{S}(S,T) &= 1 - \frac{1}{|S|}\text{agreement}_{S}
\end{align}
$$

We use the addition rate calculated by the bag method for statistical analysis to examine the influence of the translator's subjective awareness of their translation approach, as detailed in the previous section. We review the unmatch rate using basic descriptive statistics.

```{python}
#| label: count-match-bag

def match_count_bag(poem_lines: List[str], translation_lines: List[str]) -> dict:
    """
    Calculate the total match count between the poem and translation for Exact (E), Field (F), and Group (G) matches.

    The function compares each element in the poem with the elements in the translation.
    The match is counted with priority: Exact (E) > Field (F) > Group (G), meaning if an E match is found,
    it will not check for F or G, and similarly for F before G.

    :param poem_lines: A list of strings representing the poem data (already filtered).
    :param translation_lines: A list of strings representing the translation data (already filtered).

    :return: A dictionary containing the total match counts for 'E', 'F', and 'G' categories.

    Example Usage:
    --------------
    poem_data = [
        "01:000001:0001 A00 BG-01-1630-01-0100 02 年 年 とし 年 とし",
        "01:000001:0002 A00 BG-08-0061-07-0100 61 の の の の の"
    ]

    translation_data = [
        "1 katagiri 0001 1 51 50 07 BG-03-1940-01-010-A 早く はやい 早い 1",
        "1 katagiri 0001 2 51 50 07 BG-03-1660-03-010-A -- はやい 早い 1"
    ]

    match_counts = match_count(poem_data, translation_data)
    print(f"Match counts: {match_counts}")
    """

    # Initialize counters for E, F, G matches
    match_counts = {"E": 0, "F": 0, "G": 0}

    # Calculate total match count based on poem as the source
    for poem_line in poem_lines:
        s = poem_line.split()[2]  # BG ID string from poem
        assert len(s) == 18, f"Invalid BG ID string: {s}"

        found_match = False

        # First, search for E match
        for translation_line in translation_lines:
            t = translation_line.split()[7]  # BG ID string from translation
            assert len(t) == 19, f"Invalid BG ID string: {t}"

            if match_category(s, t) == "E":
                match_counts["E"] += 1
                found_match = True
                break  # Stop once an E match is found

        # If no E match is found, search for F match
        if not found_match:
            for translation_line in translation_lines:
                t = translation_line.split()[7]
                if match_category(s, t) == "F":
                    match_counts["F"] += 1
                    found_match = True
                    break  # Stop once an F match is found

        # If no F match is found, search for G match
        if not found_match:
            for translation_line in translation_lines:
                t = translation_line.split()[7]
                if match_category(s, t) == "G":
                    match_counts["G"] += 1
                    break  # Stop once a G match is found

    # Assert to ensure that the total matches (E + F + G) equal the number of poem lines
    total_matches = match_counts["E"] + match_counts["F"] + match_counts["G"]
    assert total_matches <= len(poem_lines), f"Total matches {total_matches} exceed the number of poem lines {len(poem_lines)}"

    return match_counts
```

#### 整列法による追加率の計算 Calculation of addition rate using the alignment method {.unnumbered}

整列法による計算について説明する。整列法による計算は、文字通りアライメントを推定して、アライメントにある 2 語対の一致の数で計算を行うわけであり、集合としてではなく、シーケンスとして順序を考慮する計算になっている。

本稿では、分類語彙表番号を用いた動的計画法に基づきアライメントを行う。動的計画法を用いて 2 つのシーケンス間のアライメントを計算するためのスコーア関数は以下のように定義する。

$$
\begin{align}
\text{S}_{\text{DP}}(i, j) &=
\begin{cases}
0 & \text{if } i = 0 \text{ or } j = 0 \\
\max
\begin{cases}
\text{S}_{\text{DP}}(i-1, j) - \text{gap} \\
\text{S}_{\text{DP}}(i-1, j-1) + \text{weight}(s_i, t_j) \\
\text{S}_{\text{DP}}(i, j-1) - \text{gap}
\end{cases} & i > 0 \text{ and } j > 0
\end{cases}\\

\text{weight}(s,t) &=
\begin{cases}
-1, & \text{if } \text{match}(s,t) \in U \\
10, & \text{if } \text{match}(s,t) \in G \\
13, & \text{if } \text{match}(s,t) \in F \\
17, & \text{if } \text{match}(s,t) \in E \\
\end{cases}\\

\text{gap} &= 0.01
\end{align}
$$

ソーステキストのシーケンス $S$ とターゲットテキストのシーケンス $T$ の部分列を用いて、位置 $i$ および $j$ までの最適なアライメントスコア $\text{S}_{\text{DP}}(i,j)$ を再帰的に計算する。重みづけ関数 $\text{weight}(s,t)$ は LCS の値をそのまま用いる。Unmatch の場合は $-1$ のペナルティを課す。gap はギャップ（空白）を挿入する際に課されるペナルティ (gap panelty) であり、ここでは便宜上 $0.01$ と設定する。^[単純に観測からして、和歌の翻訳で遠い対応が多く存在しているので、ギャップペナルティは 0.01 と設定することで、遠くの語の対応を許容させる。] この式に基づき、最尤なアライメントを探索する。整列した結果の例は次のようになる。

```
>| 立田姫ーー手向けるーーーー神のあれ　ばこそーーーーーーー秋の木の葉の幣ーーーと散るーーーらめー [Kokinshu 298]
>| 竜田姫は、手向けをするべき神があるのでーーそのつかさどる秋の木の葉が幣のように散るのであろうよ [@kubota1960Kokin]
```

この基礎の上で、一致率と追加率を計算する。整列後の $S^{\prime}$ と $T^{\prime}$ がある^[ここでは、整列されたのでもちろん $|S^{\prime}| = |T^{\prime}|$ になっている。]として、整列法による一致率 $\text{agreement}^{\prime}_{T}(S^{\prime},T^{\prime})$ の計算は次に示す。

$$
\begin{align}
\text{U}^{\prime}_{T}(S,T) &= 1-\frac{1}{|T|}\text{agreement}^{\prime}_{S}\\
\text{agreement}^{\prime}_{S}) &= \sum_{s_i \in S^{\prime}} \mathbb{I} \left(\text{match}(s_i^{\prime}, t_i^{\prime}) \notin U \right)
\end{align}
$$

この式では、prime ($\prime$) 記号がついているものは整列後のテキストにおけるものを意味する。指示関数 $\mathbb{I}$ において、アライメントが一致する場合 1 を返し、アライメントが一致しない場合 0 を返す。ギャップが入っているアライメントは計算の対象としない。
一致率・不一致率・追加率の計算において、分母は整列前のソーステキストのトークン数にする。

動的計画法は、和歌の翻訳における語順の交換などの site swap に弱く、句の順序、語順が入れ替えられる訳の場合アライメントがうまくできなくなる。さらに、整列法はアライメントの2 語対が一致するという厳しめの前提が設けてあり、この前提と現実とはかなり異なる可能性が高い。したがって、整列法で計算される追加率は、全体的に統計的に分析せず、ケーススターディの説明においてのみ提示する。

We now explain the calculation method using the alignment approach. Unlike the bag method, which ignores word order, the alignment method estimates aligned word pairs and calculates the number of agreements within the alignment, treating the poem and its translation as sequences rather than sets.

In this paper, we perform the alignment using dynamic programming. The score function for calculating the alignment between two sequences is defined as follows:

$$
\text{S}_{\text{DP}}(i, j) =
\begin{cases}
0 & \text{if } i = 0 \text{ or } j = 0 \\
\max
\begin{cases}
\text{S}_{\text{DP}}(i-1, j) - \text{gap} \\
\text{S}_{\text{DP}}(i-1, j-1) + \text{weight}(s_i, t_j) \\
\text{S}_{\text{DP}}(i, j-1) - \text{gap}
\end{cases} & i > 0 \text{ and } j > 0
\end{cases}\\
$$

The matching weight function is based on the LCS value of the two word sense identifiers, i.e., the WLSP codes. For an unmatch, we apply a penalty of $-1$:

$$
\text{weight}(s,t) =
\begin{cases}
-1, & \text{if } \text{match}(s,t) \in U \\
10, & \text{if } \text{match}(s,t) \in G \\
13, & \text{if } \text{match}(s,t) \in F \\
17, & \text{if } \text{match}(s,t) \in E \\
\end{cases}
$$

Using the subsequences of the source text $S$ and the target text $T$, we recursively calculate the optimal alignment score $\text{S}_{\text{DP}}(i,j)$ for positions $S_i$ and $T_j$. The gap penalty (for inserting gaps) is set to 0.01, which allows for distant word alignments, a common occurrence in translations of poetry. ^[The gap penalty is set to 0.01 to account for the fact that translations of poems often involve distant agreements between words.] Based on this formula, we search for the most likely alignment. An example of the aligned result is shown below:

```
>| Tatsutahime give       god exist Reson emp         autumn tree leaf ??     scatter   inference
>| 立田姫ー手向けるーーーー神のあれ　ばこそーーーーーーー秋の木の葉の幣ーーーと散るーーーらめー [298]
>| 竜田姫は手向けをするべき神があるのでーーそのつかさどる秋の木の葉が幣のように散るのであろうよ [KBT]

>| Tatsuta+hime.....tamukeru............kami=no.are..=ba=koso.................aki=no.ki=no.ha=no.nusa=to.......chiru.....=rame [298]
>| Tatsuta+hime=ha..tamuke=wo.suru=beki.kami=ga.aru=node.....sono.tsukasadoru.aki=no.ki=no.ha=ga.nusa=no.yo=ni.chiru=no=dearou [KBT]
```

With such alignment, we can calculate the agreement and addition rates. Given the aligned sequences $S^{\prime}$ and $T^{\prime}$ ^[Naturally, in alignment, $|S^{\prime}| = |T^{\prime}|$.], the agreement rate $\text{agreement}^{\prime}_{T}(S^{\prime},T^{\prime})$ using the alignment method is calculated as follows:

$$
\begin{align}
\text{U}^{\prime}_{T}(S,T) &= 1-\frac{1}{|T|}\text{agreement}^{\prime}_{S}\\
\text{agreement}^{\prime}_{S} &= \sum_{s_i \in S^{\prime}} \mathbb{I} \left(\text{match}(s_i^{\prime}, t_i^{\prime}) \notin U \right)
\end{align}
$$

In this formula, any term with a prime ($\prime$) refers to the aligned text. The indicator function $\mathbb{I}$ returns 1 if the alignment is an agreement and 0 if it is not. Alignments with gaps are excluded from the calculation. For the calculation of the agreement, unmatch, and addition rates, we use the total number of tokens in the source text (before alignment) as the denominator.

Dynamic programming is sensitive to issues such as word/chunk order changes (site swaps) in translations of poems, where phrases and word order are often rearranged. Additionally, the alignment method operates on a strict assumption that the aligned word pairs are exact matches, which may not hold in many cases. For this reason, we do not use the addition rate calculated by the alignment method for general statistical analysis but instead present it as part of case study explanations.

```{python}
#| label: weight-function

def weight(s: str, t: str, u: int = -1, g: int = 10, f: int = 13, e: int = 17) -> int:
    """
    Calculate the weight based on the match category between two strings.

    The function first classifies the match category using the `match_category` function.
    It allows custom weight values for each match category (U, G, F, E).
    - 'U' (Unmatch) returns the weight for unmatch (default is -1).
    - 'G' (Group match) returns the weight for group match (default is 10).
    - 'F' (Field match) returns the weight for field match (default is 13).
    - 'E' (Exact match) returns the weight for exact match (default is 17).

    :param s: The first input string to compare.
    :param t: The second input string to compare.
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).
    :return: An integer weight based on the match category.
    """
    category = match_category(s, t)

    if category == "U":
        return u
    elif category == "G":
        return g
    elif category == "F":
        return f
    else:  # "E"
        return e
```

```{python}
#| label: alignment

def alignment(poem_lines: List[str], translation_lines: List[str], gap_penalty: float = 0.01, u: int = -1, g: int = 10, f: int = 13, e: int = 17) -> str:
    """
    Align the poem and translation sequences using dynamic programming and return the alignment in a formatted output.

    :param poem_lines: A list of strings representing the poem data (already filtered).
    :param translation_lines: A list of strings representing the translation data (already filtered).
    :param gap_penalty: Float representing the penalty for inserting gaps (default is 0.01).
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).

    :return: A formatted string representing the aligned sequences, including matching category and token information.
    """

    # Get the size of the poem and translation
    poem_size = len(poem_lines)
    translation_size = len(translation_lines)

    # m: number of poem lines, n: number of translation lines
    m, n = poem_size, translation_size

    # Initialize the DP (Dynamic Programming) table and traceback table
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    traceback = [[(0, 0)] * (n + 1) for _ in range(m + 1)]

    # Fill DP table with gap penalties for alignment
    for i in range(1, m + 1):
        dp[i][0] = dp[i - 1][0] + gap_penalty  # Penalty for gaps in translation
        traceback[i][0] = (i - 1, 0)  # Record traceback
    for j in range(1, n + 1):
        dp[0][j] = dp[0][j - 1] + gap_penalty  # Penalty for gaps in poem
        traceback[0][j] = (0, j - 1)  # Record traceback

    # Fill the DP table with alignment scores based on the weight function
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            match_weight = dp[i - 1][j - 1] + weight(poem_lines[i - 1], translation_lines[j - 1], u=u, g=g, f=f, e=e)
            gap_poem = dp[i - 1][j] + gap_penalty  # Gap in translation
            gap_translation = dp[i][j - 1] + gap_penalty  # Gap in poem

            dp[i][j] = max(match_weight, gap_poem, gap_translation)

            # Track the source of the best alignment decision (match, gap in poem, gap in translation)
            if dp[i][j] == match_weight:
                traceback[i][j] = (i - 1, j - 1)
            elif dp[i][j] == gap_poem:
                traceback[i][j] = (i - 1, j)
            else:
                traceback[i][j] = (i, j - 1)

    # Traceback step to retrieve the optimal alignment path
    aligned_poem = []
    aligned_translation = []

    i, j = m, n
    while i > 0 or j > 0:
        prev_i, prev_j = traceback[i][j]
        if i > 0 and j > 0 and (prev_i, prev_j) == (i - 1, j - 1):
            aligned_poem.append(poem_lines[i - 1])
            aligned_translation.append(translation_lines[j - 1])
        elif i > 0 and (prev_i, prev_j) == (i - 1, j):
            aligned_poem.append(poem_lines[i - 1])
            aligned_translation.append("-")  # Gap in translation
        else:
            aligned_poem.append("-")  # Gap in poem
            aligned_translation.append(translation_lines[j - 1])
        i, j = prev_i, prev_j

    # Reverse the alignments to reflect the original sequence
    aligned_poem.reverse()
    aligned_translation.reverse()

    # Initialize output
    output = []

    # Process each aligned pair for final output
    for pair_id, (op_token, ct_token) in enumerate(zip(aligned_poem, aligned_translation), 1):

        # Extract necessary fields for poem and translation tokens
        op_fields = op_token.split() if op_token != "-" else ["-"] * 9  # Handle gaps with placeholder
        ct_fields = ct_token.split() if ct_token != "-" else ["-"] * 12  # Handle gaps with placeholder

        assert len(op_fields) == 9, f"Invalid op_fields length: {len(op_fields)}. Fields: {op_fields}"

        # Unpack poem fields
        (
            token_identifier_op,  # AnthologyID:PoemID:SequentialID
            polysemy_decomposition_op,
            bg_id_op,
            pos_op,
            surface_op,
            lemma_kanji_op,
            lemma_kana_op,
            conjugation_kanji_op,
            conjugation_kana_op
        ) = op_fields

        # Unpack translation fields
        (
            polysemy_ct,
            # Explanation for polysemy_ct:
            # 1=non-polysemy
            # 2=polysemy
            translator,
            poem_id,
            polysemy_decomposition_ct,
            # Explanation for polysemy_decomposition_ct:
            # 0=default sense(non-polysemy and simplex);
            # 1=defaut sense(compound);
            # 2=potential sense; 3=decomposition of compound
            pos_ct,
            pos_b_ct,
            pos_c_ct,
            bg_id_ct,
            surface_ct,
            lemma_kana_ct,
            lemma_kanji_ct,
            seq_id_ct
        ) = ct_fields

        # Handle potential sense and decomposition flags
        potential_sense_op = "" if (polysemy_decomposition_op == "-" or polysemy_decomposition_op[1] == "0") else "*"
        potential_sense_ct = "" if (polysemy_decomposition_ct == "-" or (polysemy_ct == "1" and polysemy_decomposition_ct != "2")) else "*"
        decomposition_op = "+" if (polysemy_decomposition_op[0] == "C" or polysemy_decomposition_op[0] == "E") else ""
        decomposition_ct = "+" if polysemy_decomposition_ct == "3" else ""

        # Determine match category based on score (Exact, Field, Group)
        category = match_category(bg_id_op, bg_id_ct) if (op_token != "-" and ct_token != "-") else "-"
        match_value = category

        # Sequential ID for poem
        seq_id_op = int(token_identifier_op.split(":")[-1]) if token_identifier_op != "-" else "-"

        # Padding
        padding_width_op = 7 - 1 * len(surface_op) if surface_op != "-" else 7
        if padding_width_op < 0:
            padding_width_op = 0
        padding_width_ct = 7 - 1 * len(lemma_kanji_ct) if lemma_kanji_ct != "-" else 7
        if padding_width_ct < 0:
            padding_width_ct = 0

        # Format the final aligned output with appropriate columns and alignment
        output.append(
            f"{pair_id:>2} {match_value:>2} {pos_op:>2} {bg_id_op:>18} {surface_op:>{padding_width_op}} {seq_id_op:>2} {potential_sense_op:>1} "
            f"{decomposition_op:>1} <-> {decomposition_ct:<1} {potential_sense_ct:<1} {seq_id_ct:<2} {lemma_kanji_ct:<{padding_width_ct}} {bg_id_ct:<18}"
        )

    # Prepare the formatted output with headers and alignment
    translator = translation_lines[0].split()[1]
    poem_id = translation_lines[0].split()[2]
    header = (
        f"args: translator:{translator}; poem No.{poem_id}; weight:(U={u}, G={g}, F={f}, E={e}); gap penalty: {gap_penalty}\n"
        " +------- pair No.\n"
        " |  +---- matching level (E=Exact, F=Field, G=Group)\n"
        " |  |  +- pos No.\n"
        " |  |  |  OP decomposition (+) ----------+     +--------------- CT decomposition\n"
        " |  |  |  OP potential sense (*) ------+ |     | +------------- CT potential sense\n"
        " |  |  |  OP token No. --------------+ | |     | | +----------- CT token No.\n"
        " |  |  |  OP token ---------------+  | | |     | | |  +-------- CT token\n"
        " |  |  |  OP WLSP code ---+       |  | | |     | | |  |       + CT WLSP code\n"
        " |  |  |                  |       |  | | |     | | |  |       |"
    )
    output = [header] + output

    return "\n".join(output)
```

```{python}
#| label: count-match-alignment

def match_count_alignment(alignment_output: str) -> dict:
    """
    Count the occurrences of match categories (E, F, G) in the alignment output.

    This function counts only the E (Exact), F (Field), and G (Group) matches in the alignment output.
    It does not calculate or track unmatched (U) tokens.

    :param alignment_output: A string representing the alignment output, where each line represents a pair.

    :return: A dictionary with counts of E, F, and G matches.
    """
    # Initialize the counters for each match category
    counts = {"E": 0, "F": 0, "G": 0}

    # Extract the total number of OP tokens from the header
    lines = alignment_output.strip().splitlines()

    # Iterate through the lines and count occurrences of E, F, G
    for line in lines:
        # Skip lines that do not contain match category information
        if len(line.strip()) == 0 or line.strip().startswith('+'):
            continue

        # Extract the match category from the line (2nd field)
        match_category = line.split()[1].strip()

        # Count E, F, G and skip lines with "-"
        if match_category == "E":
            counts["E"] += 1
        elif match_category == "F":
            counts["F"] += 1
        elif match_category == "G":
            counts["G"] += 1

    return counts
```

```{python}
#| label: count-macth

def match_count(match_counts: dict, level: int = 1) -> int:
    """
    Calculate the total match count based on the specified match level.

    The match count is calculated by summing the appropriate categories of matches
    based on the selected level of strictness:

    - Level 1: Only count Exact (E) matches.
    - Level 2: Count Exact (E) and Field (F) matches.
    - Level 3: Count Exact (E), Field (F), and Group (G) matches.

    :param match_counts: A dictionary with counts of E, F, G, and U matches.
    :param level: Integer representing the matching strictness level (default is 1).
        - Level 1: Only count Exact matches (E).
        - Level 2: Count Exact (E) and Field (F) matches.
        - Level 3: Count Exact (E), Field (F), and Group (G) matches.

    :return: An integer representing the total match count.
    """

    # Ensure the level is valid
    assert level in [1, 2, 3], "Invalid level. Must be 1, 2, or 3."

    # Calculate the total match count based on the level
    if level == 1:
        total_match_count = match_counts["E"]
    elif level == 2:
        total_match_count = match_counts["E"] + match_counts["F"]
    else:  # level == 3
        total_match_count = match_counts["E"] + match_counts["F"] + match_counts["G"]

    return total_match_count
```

```{python}
#| label: pipe

def pipe(poem: str, translation: str, mode: int = 3, level: int = 3, gap_penalty: float = 0.01, u: int = -1, g: int = 10, f: int = 13, e: int = 17):
    """
    A complete pipeline function that processes poem and translation data, computes match counts,
    alignment results, and rates (addition and unmatch rates), and writes results to a CSV file.

    :param poem: The poem data as a string.
    :param translation: The translation data as a string.
    :param mode: The mode to filter the poem and translation (default is 3).
    :param level: The strictness level for calculating match counts (default is 3).
    :param gap_penalty: Gap penalty for alignment (default is 0.01).
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).
    """

    # Process the poem and translation using poem_mode and translation_mode
    poem_lines = poem_mode(poem, mode)
    translation_lines = translation_mode(translation, mode)

    # Calculate poem and translation sizes
    poem_size = len(poem_lines)
    translation_size = len(translation_lines)

    # Info
    translator = translation_lines[0].split()[1]
    poem_id = translation_lines[0].split()[2]

    # Calculate match counts using the bag method
    match_count_bag_ = match_count_bag(poem_lines, translation_lines)
    exact_match_bag = match_count_bag_["E"]
    field_match_bag = match_count_bag_["F"]
    group_match_bag = match_count_bag_["G"]
    unmatch_bag = poem_size - exact_match_bag - field_match_bag - group_match_bag
    total_match_bag = match_count(match_count_bag_, level)

    # Calculate alignment and match counts from alignment
    alignment_output = alignment(poem_lines, translation_lines, gap_penalty=gap_penalty, u=u, g=g, f=f, e=e)
    match_count_alignment_ = match_count_alignment(alignment_output)
    exact_match_alignment = match_count_alignment_["E"]
    field_match_alignment = match_count_alignment_["F"]
    group_match_alignment = match_count_alignment_["G"]
    unmatch_alignment = poem_size - exact_match_alignment - field_match_alignment - group_match_alignment
    total_match_alignment = match_count(match_count_alignment_, level)

    # Calculate addition and unmatch rates
    addition_rate_bag = 1 - total_match_bag / translation_size if translation_size > 0 else 0
    addition_rate_alignment = 1 - total_match_alignment / translation_size if translation_size > 0 else 0
    unmatch_rate_bag = unmatch_bag / poem_size if poem_size > 0 else 0
    unmatch_rate_alignment = unmatch_alignment / poem_size if poem_size > 0 else 0

    # Format the statistics according to the required structure
    statistics = (
        f"mode={mode}; level={level}\n"
        f"OP={poem_size}; CT={translation_size};\n"
        f"bag (E={exact_match_bag}, F={field_match_bag}, G={group_match_bag}, U={unmatch_bag}, T={total_match_bag}, "
        f"AddRate={addition_rate_bag:.2%}, UnmatchRate={unmatch_rate_bag:.2%});\n"
        f"alignment (E={exact_match_alignment}, F={field_match_alignment}, G={group_match_alignment}, U={unmatch_alignment}, "
        f"T={total_match_alignment}, AddRate={addition_rate_alignment:.2%}, UnmatchRate={unmatch_rate_alignment:.2%})"
    )
    
    # Print alignment output and formatted statistics
    print("statistics:", statistics)
    print(alignment_output)
```

## 翻訳の主観的意識と追加率の関係に関する統計モデリング Statistical modeling of the relationship between translation approach and the addition rate

先行研究 [@Yamamoto2005Mathematical; @Yamamoto2019Analysis]  ではグループ・フィールド・同義レベルの一致率（言い換え率）、理論的・実験的追加率などの多くの指標を計算しているが、翻訳者別の追加率の平均と標準偏差しか提示していない。データの更新や、計算手順もすこし異なったので、結果の変化も生じる。そこで、新たに計算した追加率を対象に統計分析を行う。

訳者の翻訳意識が実践に移り、実際の現代語訳における追加率に影響を与えているかどうかを確認するために、統計モデリングを行う。具体的には、翻訳意識（`Focus`）が追加率（`additional_rate`）^[ここでは、バッグ法によって算出された追加率を用いる。] に与える影響を検討するために、ベータ分布^[計算された応答変数は、$(0, 1)$ の区間にあり、二項分布を仮定して用いることも考えられる。ただし、二項分布を用いる場合は、現代語訳文の全語数と追加に相当する語数の情報が必要であり、本稿の計算は @Yamamoto2019Analysis の計算結果を踏まえたため、全語数について情報が不足していることを前提としないベータ分布を用いる。] に基づく回帰モデルを採用した。このモデルは、訳者（`translator`）と歌（`poem`）を変動を統制するためにランダム効果としてモデルに入れている。統計モデルは付録を参照されたい。

モデルの推定は、Markov Chain Monte Carlo (MCMC) 法を用いる。具体的には、4 つのチェーンを使用し、各チェーンで 2000 回のイテレーションを行い、そのうち 1000 回をウォームアップ (burn-in) として設定する。`R` [@???] パッケージ `brms` パッケージ [@???] を用いてモデルを実装し、事後分布の収束の評価は R-hat 指標および有効サンプルサイズ (ESS) を提示し確認する。モデルの推定結果として、翻訳アプローチが追加率に与える影響を示し、事後分布をサンプリングし、事後分布の中央値と95% 事後最狭信用区間 (posterior highest credible interval) を報告する。

Previous studies [@Yamamoto2005Mathematical; @Yamamoto2019Analysis] have calculated various metrics such as agreement rates (paraphrase rates) at the group, field, and synonym levels, as well as theoretical and practical addition rates. However, they only provided the mean and standard deviation of the addition rate by translator. Given the updates to the data and calculation procedures, the results may differ. Therefore, we conduct a new statistical analysis using the recalculated addition rates.

To assess whether the translators' intended approaches influence the addition rate in contemporary translations, we perform statistical modeling. Specifically, we examine the effect of translation approach on the addition rate^[In this analysis, we use the addition rate calculated via the bag method.]. We employ a hierarchical model based on a beta distribution^[Since the response variable lies within the $(0, 1)$ interval, we considered using a binomial distribution. However, this would require detailed information on the total number of words in the translation and the number of additional elements. Based on @Yamamoto2019Analysis, we use a beta distribution, which does not assume this information.] to analyze this effect. Translator and poem are included as random effects to account for variability across these factors. Details of the statistical model are available in the appendix.

We estimate the model's coefficients using the Markov Chain Monte Carlo (MCMC) method, running 4 chains with 2000 iterations each, with the first 1000 iterations used as warm-up (burn-in). The model is implemented using the `brms` package in R (`{r} version$version.string`) [@???], and we evaluate the convergence of the posterior distribution using the R-hat statistic and effective sample size (ESS). The results will reveal how translation focus influences the addition rate, and we will report the posterior median along with the 95% highest posterior credible interval (HDI).


```{R}
#| label: data-process
#| message: false

data <- read.csv("artifacts/calc_results.csv") |>
  mutate(
    Translator = as.factor(Translator),
    Focus = case_when(
      Translator %in% c(
        "kaneko",
        "kubota",
        "katagiri"
      ) ~ "Text-focused",
      Translator %in% c(
        "okumura",
        "takeoka"
      ) ~ "Poet-focused",
      Translator %in% c(
        "ozawa",
        "kyusojin"
      ) ~ "Reader-focused",
      Translator %in% c(
        "matsuda",
        "kojimaarai",
        "komachiya"
      ) ~ "Others",
    ),
    Focus = factor(
      Focus,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    ),
    Translator = factor(
      Translator,
      levels = c(
        "kaneko",
        "kubota",
        "katagiri",
        "okumura",
        "takeoka",
        "ozawa",
        "kyusojin",
        "matsuda",
        "kojimaarai",
        "komachiya"
      )
    )
  ) |>
  select(
    Translator,
    PoemID,
    Focus,
    AdditionRate,
    UnmatchRate
  )

translator_labels <- c(
  "kaneko" = "KNK",
  "kubota" = "KBT",
  "katagiri" = "KTGR",
  "okumura" = "OKMR",
  "takeoka" = "TKOK",
  "ozawa" = "OZW",
  "kyusojin" = "KSJ",
  "matsuda" = "MTD",
  "kojimaarai" = "K&A",
  "komachiya" = "KMCY"
  )
```


```{r}
#| label: beta-model
#| cache: true
#| messge: false

# backend
options(
    mc.cores = parallel::detectCores(),
    brms.backend = "cmdstanr"
)

# Global setting
chains <- 4
iter <- 2000
warmup <- 1000
bayes_seed <- 1234

# Formula
formula <- bf(
  AdditionRate ~ a + b, 
  a ~ 1 + (1 | Translator) + (1 | PoemID),
  b ~ 0 + Focus,
  phi ~ 1 + (1 | PoemID),
  nl = TRUE
)

prior = c(
  prior(student_t(3, 0, 2.5), nlpar = b),
  prior(
    student_t(3, 0, 2.5),
    class = b,
    coef = Intercept,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    group = Translator,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    group = PoemID,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = Intercept,
    dpar = phi
  ),
  # Default prior for standard deviation of phi parameter in PoemID group
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    dpar = phi,
    group = PoemID
  )
)

# Model
model <- data %>%
  brm(
    data = .,
    formula = formula,
    family = Beta(), 
    prior = prior, 
    chains = chains,
    iter = iter,
    warmup = warmup,
    seed = bayes_seed,
    silent = 2,
    adapt_delta = 0.9,
    control = list(max_treedepth = 12),
    file = "./artifacts/model_beta_bayes",
    save_model = TRUE
  )
```

## 「タツタ」歌の事例分析 Case Study of the "Tatsuta" Poem, No. 298

和歌に対する現代語訳は、なんらかの言い換えと追加を行っていることが分っても、その追加要素や言い換え要素の性格がわかっているわけではない。これら要素の性格は、アライメントにおける一致を確認しながら、コーパス言語学の視点から分析する。本稿では @Sinclair1996Search の拡張意味単位モデルの視座から示唆を得て、和歌の原文のコーパスレベルに観測されている傾向性が、センテンスレベルの対訳文でどのように処理されているかを明確にする。

拡張意味単位モデルは以下の 4 つのレベルから対象言語単位の記述を行っている。

1. コロケーション（collocation）：他の語の共出現関係 [@Sinclair1970English, p. 15]
2. 類連結（colligation）：構文パターンや文法的要素との共出現関係 [cf., @Firth1968Selected, p. 183; @Sinclair1996Search, p. 11; @Sinclair2003Reading, p. 171]
3. 意味的志向（semantic preference）：特定の意味の語群（semantic set）との共出現関係 [@Sinclair2003Reading, p. 178]
4. 談話韻律（discourse prosody）：拡張意味単位全体の評価・態度・語用論的意味 [@Sinclair2004Trust, p. 174]

コロケーションから談話韻律へと、直接な観測ができなくなり、明示的でなくなっていく [@Stubbs2001Words, pp. 87--88]。

和歌の性質とデータの量の少なさからして、確実に拡張意味単位を捉えることが難しいことがある。よって、本稿では単純に拡張意味単位の 4 つのレベルを 4 つの視座とみて、この 4 つの視座のうち、共出現の語、共出現の構文パターン、共出現の語の意味的まとまりで考えられる志向性から、10 人の翻訳でどのように処理されているかを分析する。

@Yamamoto2005Mathematical では、現代語訳の紹介に歌枕「タツタ」の歌 298 番をとりあげている。本稿でも同じ歌をとりあげ、それが 10 人の翻訳、異なる翻訳の方針でどのように処理されているか、前掲の 3 つの視座から分析する。

コロケーションのレベルで確認すると、八代集全体における 54 首において、
「タツタ」の文脈に頻出する内容語 (`chasenID`が60以前のもの) には「山」(30 as collocates and 15 as decomposition of tatsuta-yama)「紅葉づ」(17)「川」(15 as decomposition of tatsuta-gawa)「秋」(15)「見る」(12)「紅葉葉」(9)「錦」(9) があげられる。
頻度5以上の語には、「神無備」(5)「姫」(8 as decomposition of tatsuta-hime) など神に関連する語と、「散る」(8)「流る」(5)「吹く」(6)「紅葉」(5)「黄葉」(5) など、落葉に関連する語が存在している。^[附録を参照する。]

共出現する構文パターンとして、動詞の終止形で終わる歌の少なさ (古今集 12 首の中で 1 首のみ) が観測される。また、古今集の中では、係り結びは 9 (12) 首観測されており、
余韻の残し方に特徴があると考えられる。これら終わり方の構文パターンが、翻訳における処理について考察する。

共出現する語の性質は、内容語のコロケーションは基本的に、「タツタガワ」「タツタ（の）ヤマ」など地名を構成する「山・川」のグループ、秋の「神」に関連する関連語のグループに属している。秋・紅葉が有名な神聖な場所の歌枕の性質が伺える。

298 番歌の訳における追加要素のバリエーションを示しながら、以上のコーパスレベル・コレコティブレベルの要素が 298 番歌のセンテンスレベルで組み込まれるか、どのように組み込まれているかを確認する。


While we know that contemporary translations of classical Japanese poetry often involve paraphrasing and adding elements, the precise nature of these additions and paraphrases remains unclear. To clarify the characteristics of these elements, we analyze the alignments and examine them from a corpus linguistics perspective. Drawing on Sinclair's Extended Unit of Meaning model [@Sinclair1996Search], this paper explores how the tendencies observed at the corpus level of the original text are reflected in the sentence-level translations.

The extended unit of meaning model describes linguistic units across four levels:

1. **Collocation**: The tendency of words to co-occur with other words [@Sinclair1970English, p. 15].
2. **Colligation**: The tendency of words to co-occur with specific syntactic patterns or grammatical elements [cf., @Firth1968Selected, p. 183; @Sinclair1996Search, p. 11; @Sinclair2003Reading, p. 171].
3. **Semantic preference**: The tendency of words to co-occur with particular semantic sets [@Sinclair2003Reading, p. 178].
4. **Discourse prosody**: The specific attitudinal, emotional, or evaluative tendency expressed by the extended unit of meaning [@Sinclair2004Trust, p. 174].

From the level of collocation to that of discourse prosody, the elements become less explicitly observable and more implicit [@Stubbs2001Words, pp. 87–88].

Given the nature of classical poetry and the limited data available, capturing extended units of meaning with certainty is often challenging. Therefore, we treat the four levels of the extended unit as distinct perspectives. Through these perspectives—co-occurring words, syntactic patterns, and semantic sets—we analyze how the ten different translations handle the tendencies present in the original text.

@Yamamoto2005Mathematical uses poem #298 as an example to illustrate how the word "Tatsuta" is processed in contemporary translations. We analyze the same poem, focusing on how it is handled in the ten translations, each employing different translation approaches, based on the three perspectives mentioned above.

At the level of collocation, we observe that in the *Hachidaishū* dataset, the following content words^[Content words are identified by `chasen`-based PoS number below 60.] frequently appear in the context of "Tatsuta": 山 (*yama*, "mountain") (30 as collocates, 15 as a decomposition of 立田山 *tatsuta-yama*, "Mt. Tatsuta"), 紅葉づ (*momidzu*, "(leaves) turning red") (17), 川 (*kawa*, "river") (15 as a decomposition of 立田川 *Tatsuta-gawa*, "River Tatsuta"), 秋 (*aki*, "autumn") (15), 見る (*miru*, "to see") (12), 葉 (*ha*, "leaves") (9), and 錦 (*nishiki*, "brocade") (9). Words related to gods, such as 神無備 (*Kamnabi*, "Kamnabi (proper noun)") (5) and 姫 (*hime*, "goddess/princess") (8 as a decomposition of 立田姫 *Tatsuta-hime*, "Goddess Tatsuta"), also frequently appear, along with words associated with falling leaves, such as 散る (*chiru*, "scattering") (8), 流る (*nagaru*, "flowing") (5), 吹く (*fuku*, "blowing") (6), 紅葉 (*momidzi*, "red leaves") (5), and 黄葉 (*momidzi*, "yellow leaves") (5).^[See the appendix for details.]

Regarding co-occurring syntactic patterns, we find that poems ending in the conclusive form of a verb are rare (only one in the *Kokinshū* out of twelve poems). Additionally, nine poems in the *Kokinshū* utilize the emphatic grammatical structure "kakarimusubi" (係り結び), which emphasizes a lingering resonance at the poem’s conclusion. We will examine how these distinctive syntactic patterns are handled in the translations.

As for the semantic properties of the co-occurring words, the collocates of content words typically fall into two main groups: those related to place names (e.g., 立田川 *tatsuta-gawa*, "River Tatsuta", 立田の山 *tatsuta-no-yama*, "Mountain of Tatsuta") and those associated with the autumn goddess. These suggest that the poetic word "Tatsuta" is closely tied to a sacred location known for its autumnal colors.

Finally, we examine how the corpus-level and collective elements described above are incorporated into the sentence-level translations of poem #298, highlighting the variations in added elements across the ten translations.

::: {.callout-note}
### 拡張意味単位モデルの視座

意味の拡張単位モデルでは、意味の単位を以下の五つの要素に分けている [@Sinclair1996Search]。 @Sinclair1996Search は *true feeling* から「(not) [EXPRESS] [one's] *true feeling*」といった意味の拡張単位を抽出している例とりあげているので、この例で要素について @tbl-EUoM にまとめ説明する:

| 要素                | 説明                                                    | 例                                                                                          | 方法                                |
|:--------------------|:--------------------------------------------------------|:--------------------------------------------------------------------------------------------|:------------------------------------|
| コア（core）        | 拡張意味単位における不変の成分                            | *true feeling*                                                                              | 検索語・フレーズとして使用。         |
| コロケーション（collocation） | コアと語の共出現                                      | 高頻度共出現語 (*their*, *express*, *hide*, *reveal*) + *true feeling*                      | span $\pm$ 4、出現率50%以上。       |
| 類連結（colligation）     | コアと構文・パターンとの共出現                | 所有格形容詞 (*thier/his/her/our*) + *true feeling*                                        | コンコーダンスによる観測・帰納。    |
| 意味的志向（semantic preference） | コアと特定の意味の語群との共出現                        | **(not)EXPRESS** (*express/hide/reveal/conceal*) + *true feeling*                          | コンコーダンスによる観測・帰納。    |
| 談話韻律（discourse prosody）    | 拡張意味単位全体の評価・態度・語用論的意味               | 否定語 + **EXPRESS** -> 「客観的・主観的できない」（reluctance/inability）                        | コンコーダンスによる観測・帰納。    |

: 拡張意味単位の要素、説明、事例、操作例 {#tbl-EUoM}

1. コア（core）は拡張意味単位における不変の成分である [@Sinclair2004Trust, p. 204]。*true feeling* がこの例におけるコアであり、検索語として使用されている。^[@Sinclair1996Search の例では、コアは実際には検索語に相当するものである。]
2. コロケーション（collocation）：コアと語の共出現関係である [@Sinclair1970English, p. 15]。*true feeling* のコンテキストでは、*their*, *express*, *hide*, *reveal* などがあげられる。@Sinclair1996Search では、コンテキストのウィンドーは 4 に、閾値は 50% の出現率に設定されている。^[@Koller1979Computer はにすべきであるとしている。]
3. 類連結（colligation）はコアと構文・パターンとの共出現関係である [cf., @Firth1968Selected, p. 183; @Sinclair1996Search, p. 11; @Sinclair2003Reading, p. 171]。例えば、*true feeling* の前方共出現に *thier/his/her/our* が多く、それらの性質は所有格形容詞であるため、所有格形容詞が *true feeling* の類連接と認める。この類連接は直接の観測ができないため、コンコーダンス・コロケーションリストによる観測・帰納に基づく。
4. 意味的志向（semantic preference）はコアと特定の意味の語群（semantic set）との共出現関係 [@Sinclair2003Reading, p. 178]。例えば、*express/hide/reveal/conceal* など **EXPRESS** まとは **EXPRESS** の否定のグループが常に *true feeling* のコンテキストに生起している。この意味的志向も類連接同様、コンコーダンス・コロケーションリストによる観測・帰納に基づく。
5. 談話韻律（discourse prosody）は拡張意味単位全体の評価・態度・語用論的意味 [@Sinclair2004Trust, p. 174]である。**EXPRESS**の左には*less/not*などの否定が頻繁に出現するため、*true feeling* については「客観的・主観的に表現できない」（reluctance/inability）といったネガティブな談話韻律が推測される。これも同様、コンコーダンス・コロケーションリストによる観測・帰納による。

コア、コロケーションから談話韻律へと、直接な観測ができなくなり、明示的でなくなっていく [@Stubbs2001Words, pp. 87--88]。

和歌の性質とデータの量の少なさからして、確実に拡張意味単位を捉えることが難しいことがある。よって、本稿では単純に拡張意味単位の 4 つのレベルを 4 つの視座とみて、この 4 つの視座のうち、共出現の語、共出現の構文パターン、共出現の語の意味的まとまりで考えられる志向性から、分類された 10 人の翻訳でどのように処理されているかを分析する。

視座とする以上、いくつかのアダプテーションについて述べる。まず、拡張意味単位の本来の分析では要素の順序とコンテキスト・ウィンドーの設定はあるが、本稿では意味単位の共出現について順序の設定を考慮しない。57577の制限の中で、語の順番の入れ替えが多く、コアを中心とする線形配列が望ましくない。つぎに、出現率の閾値の設定はしない。テキストの数が少なく、大規模コーパスのようにロバストな結果として出すよりも、傾向を重視する。
:::

# 結果 Results {#sec-results}

## 現代語訳の整理と分類 Classification of contemporary translation approaches

注釈書の前書き、導入部に記されている翻訳に対する認識・意識に基づき、10 人の翻訳アプローチをコミュニケーションの主体への視座の置き方に基づき、3 類に分類された：

1. テキストの字義を重視する方針： @kaneko1933Kokin; @kubota1960Kokin; @katagiri1998Kokinhyoshaku
2. 作者の意図を重視する方針： @okumura1978Kokin; @takeoka1976Kokin
3. 読者の理解を重視する方針： @ozawa1971Kikon; @kyusojin1979Kokin

内方針が明確に記されなかったのは @matsuda1968Shinshaku; @kojima1989Kokin; @komachiya1982Kokin である

この中で、原文の字義を重視する翻訳アプローチは、もっとも逐語訳に拘っている。作者の意図・感受を重視する・読者の理解を重視する翻訳アプローチでは、多少の語と語順の入れ替え、語句の補いを許容しているように述べている。

Based on the prefaces and introductions in the annotation books, where the translators express their awareness, understanding, and intent regarding translation approaches, the approaches of the ten translators are classified into three categories according to their focus in the communication process:

1. **Focus on the text's literal meaning (signal)**: @kaneko1933Kokin; @kubota1960Kokin; @katagiri1998Kokinhyoshaku
2. **Focus on the author's intent (source)**: @okumura1978Kokin; @takeoka1976Kokin
3. **Focus on the reader's comprehension (destination)**: @ozawa1971Kikon; @kyusojin1979Kokin

The translation approach was not clearly stated in the works of @matsuda1968Shinshaku, @kojima1989Kokin, and @komachiya1982Kokin.

Among these, the translators who focus on the literal meaning of the original text tend to adhere most closely to word-for-word translation. On the other hand, those who prioritize the author’s intent or the reader’s understanding tend to allow for some reordering of words and the supplementation of expressions.

### Text-focused approach: KNK, KBT, KTGR {.unnumbered}

原文テキストの字義通りの解釈を重視する訳のグループは、原文に忠実に翻訳することに重みを置き、できるだけ語順や意味を変えずに翻訳を行う：@kaneko1933Kokin は「逐語訳」に徹し、語を加えたり、削除することを避けており、慎重に翻訳していると述べている；
@kaneko1933Kokin は歌の意をそこねたり、調をあやまったりすることを恐れて、鏡花水月の訳法（あからさまに説明せず、ただその姿を眼前に思い浮ばせるようにする漢文の表現法）に従ひ、きわめて小心に、一字一語の出入をもゆるがせにせぬことを期したことを述べている。また、文体的には、金子の翻訳調はたとえば「くずをれる」のような古めかしいことばをわざと翻訳に入れるところなど、本居宣長の「遠鏡」に似ている。
@kubota1960Kokin は、現代語訳の方針について、逐語訳にこだわり、語順を変えたり、新しい語を加えることを避けていると述べている。@katagiri1998Kokinhyoshaku も同様に、逐語訳を行い、和歌の省略や長大な増補を避け、可能な限り忠実に現代語訳しているとしている。

The group of translations that emphasize a literal interpretation of the original text focuses on translating as faithfully as possible, minimizing changes in word order or meaning. @kaneko1933Kokin states that he follows a strict word-for-word approach, avoiding the addition or omission of words, and carefully translating to maintain the integrity of the original. He states that, fearing to distort the meaning or rhythm of the poems, he adhered to the *kyōkasuigetsu* (鏡花水月) method^[A classical Chinese expression that suggests presenting the essence of something without explicit explanation, allowing the reader to imagine it.], paying meticulous attention to every word without altering even a single word. Stylistically, Kaneko's translation resembles Motoori Norinaga's *Kokin Tōkagami* in his deliberate inclusion of archaic expressions.

@kubota1960Kokin also emphasizes a strict adherence to word-for-word translation, avoiding changes in word order or word additions. Similarly, @katagiri1998Kokinhyoshaku follows the same approach, performing a literal translation while avoiding omissions or extensive additions, aiming to remain as faithful as possible to the original poems.

### Poet-focused approach: OKMR, TKOK {.unnumbered}

歌人の作意を重視する訳のグループでは、表面的な意味よりも、原文の意図と感受性を重視する群である。
@okumura1978Kokin [p. 7] は「口語訳は、原歌の言葉づかいや言い廻しを尊重し、一首の意味を厳密に解釈するより、基本的な作意をまず感じとってもらうことに重点をおいた」としている。原文の意図の理解を重視し、逐語訳よりも作意を優先して翻訳している。@takeoka1976Kokin [p. 21] は、訳(口語訳)は原文の「筋」の紹介や解説の類ではなく，作者の認識のしかた・感じ方をあらゆる面より明らかにしたのち、それ現代語に存在する同じあるいは極力それに近似した認識のしかた、感じ方の表現にそっくりうつしかえることをいう。つまり、表面では、原歌の同義語に拘るものの、原歌における歌人の感受性の保持に重点を置いてる。具体的な現代語訳の方針としては、@takeoka1976Kokin [pp. 11--12] は、次のような独自の理論を提案している。

$$
S=\left[\left(a+b+c+\dots+n\right)\times X \right]\times Y
$$

$S$ は翻訳された歌であり、$a, b, c, \dots, n$ のそれぞれは歌における語、$X$ は訳に含まれる要素であり、$Y$ は訳に効果的に加えられた要素である。$a,b,c, \dots, n$ それぞれの一般的普遍的意義は辞書で理解でき、それぞれの $+$ のしかたに相当するものは文法書を参照すれば了解できる」としている。@takeoka1976Kokin [p. 11] は $Y$ はふつうは 0 の値であるが、和歌にはいくつか効果的な要素が含まれる時、翻訳者は $Y$ に何らかの値、たとえば終助詞（わ、ね、よ）のようなものを付け加わえる。したがって、現代語訳作成のための重要な変数は $X$ となる。その $X$ は、語句の分割、対応する適切な現代語、語順、助詞・接続詞を含めた訳語、文の構造、話の流れ（談話）、場面の７つに分類されるとしている。このように、歌の筋より作者の意図を細部まで還元することを強調していると捉えられる。^[契沖の「古今和歌集余材抄」以来のの 7 種の注釈書の注を統合したはじめてのものである。竹岡はこの注釈書にて文学研究に分析的アプローチを組み込んでいる。竹岡は賀茂真淵、香川景樹の仕事を分析に根拠がないとして同意できないとしている一方で、契沖、本居宣長、富士谷成章 (1738–79) らの注釈を評価している。加えて、特に古典文法、語彙の観点から 7 種すべての古注間の違いについて慎重に議論している。]

The group of translations that emphasize the poet’s intent focuses more on the underlying meaning and sensibility of the original text than on its surface meaning. @okumura1978Kokin [p. 7] states that the contemporary translation respects the wording and phrasing of the original poem, but rather than strictly interpreting the meaning of each poem, the emphasis is placed on conveying the basic intent of the poet. 

In this approach, understanding the original intent takes precedence over a literal word-for-word translation. @takeoka1976Kokin [p. 21] explains that translation (into contemporary colloquial Japanese) is not a mere introduction or explanation of the plot of the original text, but rather aims to clarify the poet’s way of perceiving and feeling in all aspects, and then transposes these expressions into modern equivalents as faithfully as possible. While synonyms in the original poem are considered important, the emphasis is on preserving the poet’s intent and feelings. As a specific translation strategy, @takeoka1976Kokin [pp. 11–12] proposes the following unique theory:

$$
S=\left[\left(a+b+c+\dots+n\right)\times X \right]\times Y
$$

In this formula, $S$ represents the translated poem, $a, b, c, \dots, n$ are the individual words in the poem, $X$ represents the elements included in the translation, and $Y$ represents additional elements effectively included in the translation. Takeoka explains that the general universal meaning of $a, b, c, \dots, n$ can be understood through a dictionary, and the way they are combined (denoted by $+$) can be clarified by referencing grammar books. @takeoka1976Kokin [p. 11] also notes that $Y$ typically has a value of 0, but when effective elements are included in a poem, the translator adds a value to $Y$, such as a final particle (e.g., わ *wa*, ね *ne*, よ *yo*). Therefore, the most important variable for creating a contemporary translation is $X$. Takeoka divides $X$ into seven categories: word segmentation, corresponding modern vocabulary, word order, particles and conjunctions, sentence structure, discourse, and scene. This approach emphasizes fully conveying the poet’s intent rather than just the surface meaning of the poem’s structure.^[This method represents the first integrated analysis of the seven major commentaries on the *Kokinshū* since Keichū’s *Kokinshū Yozaishō*. Takeoka adopts an analytical approach in his literary studies, while rejecting the work of Kamo no Mabuchi and Kagawa Kageki as lacking in analytical foundation. However, he values the annotations of Keichū and Motoori Norinaga. Additionally, he carefully discusses the differences among all seven classical annotation books from the perspectives of the studies of classical Japanese grammar and vocabulary.]

### Reader-focused approach: OZW, KSJ {.unnumbered}

読者の理解を重視する訳のグループは、原文に忠実であることよりも、読者の内容の理解や解釈を読者に伝えることを重視している。そのため、語順を変えたり、新しい語を加えることもある。
@ozawa1971Kikon は原作の語順・語法を変更することをいとわず、読者が理解しやすいように内容を優先した翻訳を行っている。 @ozawa1971Kikon [p. 46] は「口語訳はそれだけ独立しても意味がよくわかるように努めたので、時には原作の語順・語法を変えている」と述べており、逐語訳よりも内容の理解の方に力点が置かれている。@kyusojin1979Kokin は、平易な口語訳を採用し、必要に応じて語句を補っており、解釈を重視した翻訳を行っている。現代語訳の方針としては「歌意は、歌句に基づく平易な口語訳としたが、必要と思われる場合は字句を補った」と述べている [@kyusojin1979Kokin, p.6]。

The group of translations that prioritize the reader’s understanding focuses more on conveying the meaning and interpretation of the original poem to the reader, rather than strictly adhering to the original text. This often involves changing the word order or inserting additional words. @ozawa1971Kikon does not avoid modify the word order and grammar of the original, prioritizing a translation that is easier for the reader to understand. @ozawa1971Kikon [p. 46] states that he made sure that the translation could stand alone and still be understood, even if it meant changing the word order or grammar of the original text. This highlights a focus on comprehension over literal word-for-word translation. Similarly, @kyusojin1979Kokin adopts a plain and accessible translation, supplementing expressions where necessary to prioritize interpretation. The translation approach is explained that the intent of the poem is expressed in a highly-readable translation based on the original poems, but additional words were added where necessary [@kyusojin1979Kokin, p. 6].

### 不詳 Approaches that were not specified: KMCY, MTD, K&A {.unnumbered}

現代語訳の方針について、 @komachiya1982Kokin, @matsuda1968Shinshaku, @kojima1989Kokin は明確に述べていない。

うち、 @matsuda1968Shinshaku の現代語訳は他の 10 名の共同執筆者によって作られている。この注釈書冒頭のの解説には、現代語訳は今までの研究にしたがって作られたとは述べているものの、10 名の共著者の間での翻訳の共通認識、作成方針は明らかに述べられていない。また、松田は古今集の和歌について、歌人の感情についてだけでなく、選者の編集意識についても、解釈にも含めようとしていると述べている [@matsuda1968Shinshaku, p. 9]。各歌の後に、順次、「通釈」「語釈」「古注」「評」の項目を設け、解釈・鑑賞などが記されている。
@kojima1989Kokin の特色の一つは注釈は江戸期 (1600–1868) だけでなく、これまでの注釈書では無視されてきた中世期 (1392–1600) に作られた注釈も取り入れていることである (pp. 481--482)。また、万葉集の和歌と用語が対比されて引用されている [@kojima1989Kokin, p. 480]。各歌の注釈としては「歌番号」「大意」「語句の注」「参考事項」の順で述べられている。他の注釈本と比べてさほど量的に違いはないが、付録にはさまざまな資料が含まれており、付録だけで本の 30 % を占めているほどである。

The translation approach is not explicitly stated in the works of @komachiya1982Kokin, @matsuda1968Shinshaku, and @kojima1989Kokin.

Among these, the contemporary translation in @matsuda1968Shinshaku was produced by ten co-authors. Although the preface of the annotation book mentions that the translation was created based on previous research, it does not clarify the shared understanding or guidelines for translation among the ten co-authors. Additionally, Matsuda states that his interpretation of the *Kokinshū* not only includes the poets' emotions but also the editors' intentions in compiling the anthology [@matsuda1968Shinshaku, p. 9]. Following each poem, the annotation book includes sections titled "General Explanation (通釈 *Tsūshaku*)," "Word Explanation (語釈 *Goshaku*)," "Classical Commentaries (古注 *Kochū*)," and "Evaluations (評 *Hyō*)," providing interpretation and appreciation of the poems.

One distinguishing feature of @kojima1989Kokin is that it incorporates annotations from the medieval period (1392–1600), which were often overlooked in previous annotation books, alongside annotations from the Edo period (1600–1868) (pp. 481--482). Additionally, comparisons and references to *Man'yōshū* poems and terms are frequently made [@kojima1989Kokin, p. 480].

### まとめ Summary {.unnumbered}

それぞれの翻訳の方針を見る限り、ほとんどの作者が逐語訳を基本に原文の意味を変えない翻訳を試みているが、力点の置き方が若干異なっている。本稿では、「テキストの字義を重視」「作者の意図・感受の解釈を重視」「読者の理解を重視」「不詳」のようにコミュニケーションの観点から分類を行った。この中で、原文の字義を重視する翻訳アプローチは、もっとも逐語訳に拘っていた。作者の意図・感受を重視する・読者の理解を重視する翻訳アプローチでは、多少の語と語順の入れ替え、語句の補いを許容していた。ただし、この分類は、もちろんのこと、互いに重なる部分もあるが予想される。

When examining the translation approaches, most translators aim to maintain the original meaning without altering it, primarily adhering to word-for-word translation, though the emphasis differs slightly. In this paper, we categorized these approaches from the perspective of the communication model into the following groups: text-focused approach, poet-focused approach, reader-focused approach, and approaches that were not specified. Among these, the text-focused approach was the most committed to word-for-word translation. On the other hand, approaches that prioritized the author’s intent or the reader's understanding allowed for some reordering of words and the supplementation of phrases. However, there is likely overlap among these categories. It should also be noted that these approaches are based on the translators' subjective awareness of their own translation strategies.

## 不一致率と追加率の推定結果 Results of unmatch and addition rate estimates

追加率の計算結果は、@fig-data を参照する。不一致率は 0--88 % である [@tbl-data-review]。TKOK の現代語訳がもっとも不一致率が低く 17.2 % (sd = 0.1)であった [@fig-unmatch-rate]。一方、OZW の現代語訳がもっとも高く 23% (sd = 0.112) であった [@fig-unmatch-rate]。既に述べたように、OZW は語順を変更することを惜しまないのに対して、竹岡は自身の方針に遵守して翻訳した。それが如実にデータとしてあらわれていた。

10 種の現代語訳のうち、697番歌は、88.2% ともっとも不一致率の高い和歌であった [@tbl-data-review]。つまり、和歌の中のほとんどの語が訳されていないと見てよい。このような歌については「考察」で改めて確認する。

Referring to @fig-data for the calculation results of the addition rate, we can observe that the unmatch rate ranges from 0% to 88% [@tbl-data-review]. TKOK's translation had the lowest unmatch rate at 17.2% (sd = 0.1) [@fig-unmatch-rate], while OZW's translation recorded the highest at 23% (sd = 0.112) [@fig-unmatch-rate]. As mentioned earlier, OZW showed greater flexibility in changing word order, whereas Takeoka adhered strictly to his translation principles, a difference clearly reflected in the data.

Of the 10 contemporary translations analyzed, Poem #697 exhibited the highest unmatch rate at 88.2% [@tbl-data-review], indicating that most of the words in the poem were not literally translated. We will revisit these poems in the "Discussion" section for further analysis.

```{R}
#| label: fig-data
#| fig-scap: 訳者別の追加率の確率分布
#| fig-cap: 訳者別の追加率の確率分布 Probability distribution of addition rates by translator
#| messge: false
#| warning: false

by_focus_annotation <- data |> group_by(Focus) |> 
  get_summary_stats(
    AdditionRate, 
    type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    ) 
  ) |>
  select(annotation) |>
  pull()

by_translator_annotation <- data |> group_by(Translator) |> 
  get_summary_stats(
      AdditionRate, 
      type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    )
  )|>
  select(annotation) |>
  pull()

data |>
  arrange(Focus, Translator) |>
  ggplot(
    aes(
      x = AdditionRate, 
      y = Translator, 
      fill = Focus,
      )
    ) + 
  stat_density_ridges(
    color = palette_okabe_ito(5),
    quantile_lines = TRUE, 
    quantiles = c(0.025, 0.5, 0.975), 
    jittered_points = TRUE, 
    position = "raincloud",
    vline_width = 1, vline_color = "red",
    point_size = 0.001, 
    point_alpha = 0.1,
    point_color = "black",
    alpha = 0.8,
    scale = 1,
    ) +
  # scale_fill_brewer(palette = "Blues") +  
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.2, 1.2)
  ) +  
  scale_y_discrete(labels = translator_labels) +
  geom_hline(
    yintercept = c("matsuda", "ozawa", "okumura", "kaneko"),
    linetype = "solid", 
    color = "black",
    linewidth = 1.5
    ) + 
  annotate(
    geom="text",
    x = -0.2, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    # color = "blue",
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = -0.1,
    hjust = 0,
    size = 6,
    label = c(
      "Others", 
      "Reader-focused",
      "Poet-focused",
      "Text-focused"
      )
    ) + 
  annotate(
    geom="text",
    x = -0.2, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = 1.2,
    hjust = 0,
    size = 3,
    label = by_focus_annotation,
    parse = TRUE
    ) + 
  annotate(
    geom="text",
    x = 1.2, y = c(levels(data$Translator)),
    color = "black",
    vjust = -0.2,
    hjust = 1,
    size = 3,
    label = by_translator_annotation,
    parse = TRUE
    ) +
  xlab("Addition Rate") +
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  labs(
    fill = "Translation Focus: ",
    caption = "2.5%, 50%, 97.5% quantiles are shown with red line"
  ) + 
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.text.y = element_text(
      face = "italic"
    ),
    legend.title = element_text(size = 12),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 2)) 
```

```{r}
#| label: fig-unmatch-rate
#| fig-scap: 不一致率（明確な対応をもたない要素が和歌原文を占める割合）の概要
#| fig-cap: 訳者別の不一致率の確率分布（明確な対応をもたない要素が和歌原文を占める割合） Probability distribution of unmatch rates by translator (unmatch rate is the proportion of elements in the original poem without agreement)

by_focus_annotation <- data |> group_by(Focus) |> 
  get_summary_stats(
    UnmatchRate, 
    type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    ) 
  ) |>
  select(annotation) |>
  pull()

by_translator_annotation <- data |> group_by(Translator) |> 
  get_summary_stats(
      UnmatchRate, 
      type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    )
  ) |>
  select(annotation) |>
  pull()

data |>
  arrange(Focus, Translator) |>
  ggplot(
    aes(
      x = UnmatchRate, 
      y = Translator, 
      fill = Focus,
    )
  ) + 
  stat_density_ridges(
    color = palette_okabe_ito(5),
    quantile_lines = TRUE, 
    quantiles = c(0.025, 0.5, 0.975), 
    jittered_points = TRUE, 
    position = "raincloud",
    vline_width = 1, vline_color = "red",
    point_size = 0.001, 
    point_alpha = 0.1,
    point_color = "black",
    alpha = 0.8,
    scale = 1,
  ) +
  # scale_fill_brewer(palette = "Blues") +  
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.2, 1.2)
  ) + 
  scale_y_discrete(labels = translator_labels) +
  geom_hline(
    yintercept = c("matsuda", "ozawa", "okumura", "kaneko"),
    linetype = "solid", 
    color = "black",
    linewidth = 1.5
  ) + 
  annotate(
    geom = "text",
    x = 0.4,
    y = c(
      "kojimaarai", "kyusojin",
      "takeoka", "katagiri"
    ), 
    # color = "blue",
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = -0.1,
    hjust = 0,
    size = 5,
    label = c(
      "Others", 
      "Reader-focused",
      "Poet-focused",
      "Text-focused"
    )
  ) + 
  annotate(
    geom = "text",
    x = 0.4, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = 1.2,
    hjust = 0,
    size = 2.5,
    label = by_focus_annotation,
    parse = TRUE
  ) + 
  annotate(
    geom="text",
    x = 1.2, y = c(levels(data$Translator)),
    color = "black",
    vjust = -0.2,
    hjust = 1,
    size = 2.5,
    label = by_translator_annotation,
    parse = TRUE
  ) +
  geom_vline(
    xintercept = 0.2,
    color = palette_okabe_ito(9),
    linewidth = 1
  ) +
  xlab("Unmatch Rate") +
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  labs(
    fill = "Translation Focus: ",
    caption = "2.5%, 50%, 97.5% quantiles are shown with red line\n20% line is shown with black dashed line"
  ) + 
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.text.y = element_text(
      face = "italic"
    ),
    legend.title = element_text(size = 12),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 2)) 
```

```{R}
#| label: tbl-data-review
#| tbl-cap: "不一致率・追加率の概要 Summaries of unmatch and addition rates"
#| tbl-subcap: 
#|   - "不一致率・追加率の概要 Summary of unmatch and addition rates"
#|   - "不一致率のもっとも高い歌・訳対 Poems and translations with the highest unmatch rates"
#|   - "不一致率のもっとも低い歌・訳対 Poems and translations with the lowest unmatch rates"
#|   - "現代語訳の不一致率のもっとも高い歌 Poem with the highest unmatch rate in contemporary translations"
#|   - "現代語訳の追加率のもっとも高い歌 Poem with the highest addition rate in contemporary translations"
#| layout: [[100], [45, -10, 45], [45, -10, 45]]

data |>  
  get_summary_stats(
    UnmatchRate, AdditionRate,
    type = "full"
  ) |>
  select(variable, min, max, median, mean, sd) |>
  kable()

data |>  
  mutate(
    UnmatchRate = round(UnmatchRate, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  arrange(UnmatchRate) |>
  slice(n():(n()-4)) |>
  select(Translator, PoemID, UnmatchRate) |>
  kable()

data |>
  mutate(
    AdditionRate = round(AdditionRate, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  arrange(AdditionRate) |>
  slice(1:5) |>
  select(Translator, PoemID, AdditionRate) |>
  kable()

data |>
  mutate(
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  group_by(PoemID) |> 
  get_summary_stats(
    UnmatchRate,
    type = "mean_sd"
  ) |>
  arrange(mean) |>
  slice(n():(n()-4)) |>
  select(PoemID, variable, mean, sd) |>
  kable()

data |> 
  mutate(
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |> 
  group_by(PoemID) |> 
  get_summary_stats(
    AdditionRate,
    type = "mean_sd"
  ) |>
  arrange(mean) |>
  slice(n():(n()-4)) |>
  select(PoemID, variable, mean, sd) |>
  kable()
```

## 統計モデルの推定結果：翻訳アプローチと追加率の関連 Results from statistical modeling: relationship between translation approach and addition rate

モデルから翻訳アプローチごとの現代語訳の追加率をサンプリングした [@fig-poster]。推定効果のいずれの R-hat も 1 になっており、1.1 を下回り収束が良好であると示した [@Brooks1998General]。検証したい効果について、有効サンプルサイズ (ESS) がすべて 2000 程度を達した。

The model sampled the addition rates for each translation according to the translation approach [@fig-poster]. The $R^{\hat}$ values for all estimated effects were 1, indicating good convergence, as they remained below the threshold of 1.1 [cf., @Brooks1998General]. Additionally, the effective sample size (ESS) reached approximately 2000 in all cases.

```{r}
#| label: posterier-data
#| messge: false
#| warning: false

set.seed(123)

pred_addition_rate <- model |> 
  epred_draws(
    newdata = tibble(
      Focus = c(
       'Text-focused', 
       'Poet-focused',
       'Reader-focused',
       'Others'
      ),
      PoemID = NA,
      Translator = NA
    )
  ) |>
  mutate(
    Focus = factor(
      Focus,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    )
  )

pred_focus_annotation <- pred_addition_rate |>
  median_hdi(.epred, .width = 0.95) |> 
  mutate_if(is.numeric, round, digits = 2) |>
  mutate(median = paste0(
    "$",
    .epred*100,
    "\\%$"
    )
  ) |>
  mutate(annotation = paste0(
    .epred, 
    "*'%; '*",
    .width * 100,
    "*'% CrI ['*", 
    .lower, 
    "*', '*",
    .upper, 
    "*']'", 
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$\\mathrm{posterior\\; median} = ",
    .epred, 
    "\\%; ",
    .width * 100,
    "\\%\\;\\mathrm{CrI} = [", 
    .lower, 
    ", ",
    .upper, 
    "]$", 
    sep = ""
    )
  ) |>
  select(Focus,annotation, description, median)

pred_addition_rate_diff <- pred_addition_rate |> 
  compare_levels(
    variable = .epred, 
    by = Focus
  ) |>
  mutate(
    Focus = factor(
      Focus,
      levels = c(
        "Poet-focused - Text-focused",
        "Reader-focused - Poet-focused",
        "Reader-focused - Text-focused",
        "Others - Poet-focused",
        "Others - Reader-focused",
        "Others - Text-focused"
      )
    )
  )

pred_diff_CrI_annotation <- pred_addition_rate_diff |>
  median_hdi(.width = 0.95) |> 
  mutate_if(is.numeric, round, digits = 2) |>
  mutate(median = paste0(
    "$",
    .epred*100,
    "\\%$"
    ) 
  ) |>
  mutate(annotation = paste0(
    "Delta==",
    .epred, 
    "*'%; '*",
    .width * 100,
    "*'% CrI ['*", 
    .lower,  
    "*', '*",
    .upper, 
    "*']'", 
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$\\mathrm{posterior\\; median} = ",
    .epred, 
    "\\%; ",
    .width * 100,
    "\\%\\;\\mathrm{CrI} = [", 
    .lower, 
    ", ",
    .upper, 
    "]$", 
    sep = ""
    )
  ) |>
  select(Focus, annotation, description, median)

pred_diff_prob_g_0_annotation <- pred_addition_rate_diff |>
  group_by(Focus) |>
  summarise(
    prob_g_0 = mean(.epred > 0) * 100
  ) |>
  mutate_if(is.numeric, round, digits = 1) |>
  mutate(annotation = paste0(
    "italic(P)(Delta>0)==", 
    prob_g_0,
    "*'%'",
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$P(\\Delta>0) = ",
    prob_g_0,
    "\\%$",
    sep = ""
    )
  ) |>
  select(Focus, annotation, description, prob_g_0)
```

### 翻訳アプローチによる追加率の相違が小さい No Significant Differences in Addition Rate by Translation Approach {.unnumbered}

モデルの可視化と解釈について、@Yu2020Tradeoff に類似した方法で、比較 2 群の差の事後分布の 95% の CrI が 0 をカバーしているかを観測する以外に、2 群の差が 0 より大きい確率を同時に確認する。まず、95% の CrI が 0 をカバーしていない場合、2 群に差があると判断する；95% の CrI が 0 をカバーしていても、2 群の差が 0 より大きい確率が 95% より大きい、または 5% より小さい場合、傾向差があると判断する。

その結果、(a) 追加率は、翻訳アプローチを問わず 現代語訳の要素の 50% 前後が、追加的な要素であることがわかった。この点は、観測データからも確認された。(b) 翻訳アプローチグループで比較した結果、2 グループの差の事後分布の 95% の CrI はすべて 0 をカバーしており、それぞれの 2 群の追加率は異なることが認められなかった。
傾向としては、`Reader-focused` 群の追加率に比べ `Other` 群の追加率が `{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(median) |> I()` 程度下回った (`{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`)。`Reader-focused` 群の追加率は、`Poet-focused` 群より `{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(median) |> I()` 程度下回った (`{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`) ことが観測されているが、傾向差の基準を満さなかった。

For the visualization and interpretation of results from the model, following a method similar to @Yu2020Tradeoff, we observed whether the 95% CrI of the posterior distribution of the difference between two groups included 0, and we assessed the probability that the difference between the two groups was greater than 0. First, if the 95% CrI does not include 0, we conclude that there is a significant difference between the two groups. Even if the 95% CrI includes 0, if the probability that the difference is greater than 0 exceeds 95%, or is lower than 5%, we consider it a notable trend.

The results were as follows: (a) Regardless of the translation approach, approximately 50% of the elements in the translation were additional elements, a finding corroborated by descriptive statistics. (b) When comparing the translation approach groups, the 95% CrI of the posterior distribution for the difference between groups included 0 in all cases, indicating no statistically significant differences in addition rates between the groups.

A trend was observed where the addition rate of the `Other` group was approximately `{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(median) |> I()` lower than that of the `Reader-focused` group (`{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`). The addition rate for the `Reader-focused` group was approximately `{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(median) |> I()` lower than that of the `Poet-focused` group (`{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`), although this did not meet the threshold for a significant trend.

```{r}
#| label: fig-poster
#| fig-scap: 予測された追加率の事後分布
#| fig-cap: 予測された追加率の事後分布 Posterior distribution of addition rates
#| fig-subcap: 
#|   - "予測された各翻訳アプローチの追加率の事後分布 Posterior distribution of addition rates for each translation approach"
#|   - "予測された翻訳アプローチによる追加率の相違の事後分布 Posterior distribution of differences in addition rates by translation approach"
#| messge: false
#| warning: false
#| laylayout-nrow: 2
##| layout: [[61, 27]]

pred_addition_rate |>
  ggplot(aes(x = .epred, y = Focus)) + 
  stat_slab(
    aes(
      fill = Focus,
      fill_ramp = after_stat(
        cut_cdf_qi(cdf, .width = c(0.02, 0.8, 0.95, 1))
        )
      ),
    # height = 4,
    color = "white",
    slab_size = 0.05,
  ) + 
  stat_pointinterval(
    .width = c(.95, .8, .2)
  ) + 
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  scale_fill_ramp_discrete(range = c(1, 0.2), guide = "none") +
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.4, 0.85)
    ) +  
  labs(
    x = "Estimated Addition Rate",
    y = "Focus",
    caption = "Posterior medians are shown with points\n 80% and 95% credible intervals (HDI) are shown with inner, outer intervals and shading"
  ) +
  annotate(
    geom="text",
    x =-0.4, y = c(levels(pred_addition_rate$Focus)),
    color = palette_okabe_ito(order=c(1, 6, 3, 2)),
    # color = "black",
    vjust = -0.2,
    hjust = 0,
    size = 5,
    label = pred_focus_annotation$annotation,
    parse = TRUE
  ) + 
  geom_vline(
    xintercept = 0.5, 
    color = palette_okabe_ito(9), 
    linetype="dashed",
    linewidth = 1
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.title.y = element_blank()
  )

pred_addition_rate_diff  |>
  separate(
    Focus, 
    into = c("FocusA", "FocusB"), 
    sep = " - ",
    remove = FALSE
  ) |>
  mutate(
    FocusA = factor(
      FocusA,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    ),
    FocusB = factor(
      FocusB,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    )
  ) |>
  ggplot(
    aes(
      x = .epred, y = Focus
    )
  ) + 
  stat_halfeye(
    aes(
      fill = FocusA, 
      fill_ramp = stat(x < 0)
    )
  ) +
  stat_pointinterval(
    .width = c(.95, .8, .2)
  ) + 
  scale_fill_okabe_ito(order = c(6, 3, 2)) +
  scale_fill_ramp_discrete(
    from = "grey95",
    range = c(1, 0), guide = "none") +
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(-0.25, 0, 0.25, 0.5, 0.75),
    limits = c(-0.6, .4)
    )+  
  labs(
    x = "Estimated Addition Rate Differences",
    y = "Focus",
    caption = "Posterior medians are shown with points\n 80% and 95% credible intervals (HDI) are shown with inner and outer intervals",
    fill = "Base Translation Focus"
  ) +
  annotate(
    geom="text",
    x = -0.05, y = c(levels(pred_addition_rate_diff$Focus)),
    # color = palette_okabe_ito(order=c(1, 6, 3, 2)),
    # color = "black",
    vjust = -0.1,
    hjust = 1,
    size = 3,
    label = pred_diff_CrI_annotation$annotation,
    parse = TRUE
  ) + 
  annotate(
    geom="text",
    x = 0.1, y = c(levels(pred_addition_rate_diff$Focus)),
    color = palette_okabe_ito(order=c(6, 3, 3, 2, 2, 2)),
    # color = "black",
    vjust = -0.1,
    hjust = 0,
    size = 3,
    label = pred_diff_prob_g_0_annotation$annotation,
    parse = TRUE
  ) + 
  geom_vline(
    xintercept = 0, 
    color = palette_okabe_ito(9), 
    linetype="dashed",
    linewidth = 1
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 3)) 
```

### 訳者による追加率の変動より歌による変動のほうが大きい Variation in Addition Rates Is Greater Between Poems Than Between Translators {.unnumbered}

階層モデリングにおいて、訳者と歌をランダム切片としてモデル化している。各グループレベルがそれぞれ共有していると仮定した正規分布のパラメータである標準偏差の事後分布を可視化した [@fig-hyperparameter]。訳者グループの標準偏差の分布が歌グループのより左寄りでであった。訳者の間の変動よりも、歌の間の変動のほうが大きいことが伺える。つまり、ランダム効果の視点からは、歌が訳者に比べ追加率の変動に寄与していると考えられる。

In hierarchical modeling, translators and poems are modeled as random intercepts. The posterior distribution of the standard deviations, which are parameters of the normal distribution shared by each group level, has been visualized [@fig-hyperparameter]. The standard deviation distribution for the translator group was greater than that of the poem group. This suggests that the variation between poems is greater than the variation between translators. In other words, from the perspective of random effects, poems contribute more to the variation in addition rates than translators.

```{r}
#| label: fig-hyperparameter
#| fig-scap: グループレベルのハイパーパラメータの事後分布
#| fig-cap: グループレベルのハイパーパラメータの事後分布 Posterior distribution of group-level hyperparameters
#| warning: false
#| message: false

post <- model |> 
  as_draws_df() |>
  select(starts_with("sd")) |>
  select(-contains("pattern"))

group_labels <- c(
  "sd_PoemID__a_Intercept" = "Poem",
  "sd_Translator__a_Intercept" = "Translator"
  )

post |>
  pivot_longer(sd_PoemID__a_Intercept:sd_Translator__a_Intercept) |> 
  mutate(name = factor(name)) |>
  ggplot(aes(x = value, fill = name)) +
  geom_density(linewidth = 0, alpha = 3/4, adjust = 2/3, show.legend = F) +
  annotate(
    geom = "text", 
    x = 0.3, y = 20, 
    label = expression(sigma["Poem"]),
    color = palette_okabe_ito(7)
  ) +
  annotate(
    geom = "text", 
    x = 0.1, y = 10, 
    label = expression(sigma["Translator"]), 
    color = palette_okabe_ito(5)
  ) +
  scale_fill_okabe_ito(order = c(7, 5), guide = "none") + 
  scale_x_continuous(
    breaks = c(0.1, 0.2, 0.3),
    limits = c(0, .4)
    )+  
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression("Group hyperparameter"~sigma~"value"),
    y = "Group",
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 1
    ),
    axis.title.y = element_blank(),
    panel.grid.major.x = element_line(
      color = "gray80",
      linetype = "solid"
    )
  )
```

## 298番「立田」歌の訳の事例分析 Case analysis of the translation of "Tatsuta" Poem #298

```{bash}
#| include: false
 
echo 'Original poem:'
grep 01:000298 ./data/hachidaishu/hachidai.db |\
  awk '$2 ~ /^[ABD]0/ {printf "%s", $5}'
echo ""

echo 'Contemporary translations:'
translators=("katagiri" "kubota" "matsuda" "okumura" "takeoka" "kaneko" "kojimaarai" "komachiya" "kyusojin" "ozawa")

for translator in "${translators[@]}"
do
    echo -n "$translator: "
    awk -v translator="$translator" '$3 ~ /0298/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
    echo ""
done
```

298 番「タツタ」の歌についての事例分析は、アライメントを示しながら進める。

298 番歌の不一致率、翻訳における追加率のまとめは @tbl-tatsuta-review に提示している。ここでの計算は整列法の結果である。歌のトークン数 19 の内、アライメントの 2 語対が一致する数が、OZW 以外に 14 を越えた。OZW はやはり、文の入れ替えを行っているため、うまくアライメントができなかった。原文の要素の不一致率が低い水準にキープされており、訳における追加率は OZW を取り除き 50% -- 70% になっていた。1 語あたり 1.5 -- 1.7 語で訳されていた。さて、どのような追加要素になっているか確認していく。

アライメントはプログラム出力を修正した上で @fig-alignment に整理した。生の出力は、supplementary materials (@sec-app-tatsuta) を参照されたい。

The case analysis of the "Tatsuta" Poem #298 begins by illustrating the alignment.

@tbl-tatsuta-review presents the unmatch rate and addition rate for the translations of "Tatsuta" Poem #298, calculated using the alignment method. Out of the 19 tokens in the poem, all translations except OZW aligned more than 14 word pairs. Due to its sentence reordering, OZW struggled to align effectively. The unmatch rate for elements in the original text remains low, while the addition rate for the translations (excluding OZW) ranges from 50% to 70%. On average, translators used 1.5 to 1.7 words per word in the original. Next, we examine the types of elements added.

@fig-alignment shows the refined alignment from the alignment script output. For the raw output, refer to the supplementary materials (@sec-app-tatsuta).

```{R}
#| label: tbl-tatsuta-review
#| tbl-cap: 「タツタ」歌 298 番の現代語訳の不一致率・追加率の概要 Overview of unmatch and addition rates in contemporary translations of "Tatsuta" Poem #298

read.csv("artifacts/calc_results.csv") |> filter(PoemID==298) |>
  mutate(
    UnmatchRate_a = round(UnmatchRate_a, 3),
    AdditionRate_a = round(AdditionRate_a, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID),
    Method = "Alignment" 
  ) |>
  select(Translator, PoemID, Method, TotalMatch_a, UnmatchRate_a, AdditionRate_a) |> 
  rename(
    `TotalMatch` = TotalMatch_a, 
    `UnmatchRate` = UnmatchRate_a, 
    `AdditionRate` = AdditionRate_a
  ) |>
  kable()
```

:::: {#fig-alignment layout-nrow=2}
::: {#fig-alignment-1}

```
#  Tatsutahime (the Goddess of autumn):
>| ーーーーーーーーーーーーーーーーー立田姫ーーーーーーーーーーーーーーーーーーーーーー [298]
>| ーーーーーーーー【秋をつかさどる】龍田姫【が旅立ちにあたって】ーーーーーーーーーーー [KTGR]
>| ーーーーーーーーーーーーーーーーー竜田姫【は】ーーーーーーーーーーーーーーーーーーー [KBT]
>| ーーーーーーーーーーーーーーーーー竜田姫【には】ーーーーーーーーーーーーーーーーーー [MTD]
>| ーー【秋も終りに近づき秋の女神の】龍田姫【がお帰りになる】ーーーーーーーーーーーーー [OKMR]
>| ーーーーーーーーーーーーーーーーー竜田姫【が旅にあって】ーーーーーーーーーーーーーー [TKOK]
>| ーーーーーーーーーーーーーーーーー立田姫【は秋の神だが】ーーーーーーーーーーーーーー [KNK]
>| ーーーーーーーーーーーーーーーーー竜田姫【が】ーーーーーーーーーーーーーーーーーーー [K&A]
>| 【秋の末近くなって帰り道についた】龍田姫【が道中の無事を願って】ーーーーーーーーーー [KMCY]
>| ーーーーーーー【秋も終りに近づき】竜田姫【がお帰りになる際に】ーーーーーーーーーーー [KSJ]
>| ーーーーーーー【もはや秋の終りで】龍田姫【が帰り道にお着きになった】ーーーーーーーー [OZW]


#  Dedicate something to the god
>| ーーーーーーーーーーーーーーーーーーー手向けーーーーーーるーーーーーー神ーーーーのー [298]
>| ーーーーーーーーーーーーーーーーーーー手向けーーー（をする）ーーーーー神ーーーーがー [KTGR]
>| ーーーーーーーーーーーーーーーーーーー手向けー（をするべき）ーーーーー神ーーーーがー [KBT]
>| 【旅中】ーーーーーーーーーー（供え物をささげ）ーーーーーるーー【道祖】神ーーーーがー [MTD]
>| 【姫が道中の安全を祈って】ーーーーーー手向けーー（をなさる）ーーーーー神ーーーーがー [OKMR]
>| ーーーーーーーーーーーーーーーーーーー手向けーーーーーーるーーーーーー神ーーーーがー [TKOK]
>| 【それすら暮れて行かれる折には】【お】手向けーーー（なさる）ー【道の】神【様】ーがー [KNK]
>| ーーーーーーーーーーーーーーーーーーー手向けーーー（をする）ーーーーー神【さま】がー [K&A]
>| ーーーーーーーーーーーーーーーーーーー手向けーーー（をする）ーーーーー神ーーーーがー [KMCY]
>| 【旅の安全を祈って】ーーーーーーーーー手向けーーー（られる）ーーーーー神ーーーーがー [KSJ]
>| 【中略】【道の】（神様）【にそれを】（供えていらっしゃる）＊　　　　　　　　　　　　 [OZW]

#  Exists, so that
>| ーーーーーあれーーーーーーーーーーーーーーーーーーーーーーーーばーこそーーーーーーー [298]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーーーーーーーーーー [KTGR]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーのでーーーーーーーーーー [KBT]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [MTD]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそ【だろう】ーー [OKMR]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [TKOK]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [KNK]
>| ーー（おられる）ーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [K&A]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [K&A]
>| ーーーーーあるーーーーーーーーーーーーーーーーーーーーーーーからーこそーーーーーーー [KSJ]
>| 【中略】（のは）【姫が道の神様にそれを供えていらっしゃる】（のだ）【な】＊　　　　　 [OZW]
```

アライメント（前半）：たつたひめ 手向ける神の あればこそ Alignment (first half): Tatsutahime tamukeru kami no areba koso '[There is the] god exits [for] Tatsutahime to dedicate [things], so that ...'

:::

::: {#fig-alignment-2}

```
#  Leaves of autumn
>| ーーーーーーーーーーーーーーーーー秋のーーーーーー木の葉ーーーーーーのーーーーーーー [298]
>| ーーーーーーーーーーーーーーーーー秋のーーーーーー木の葉ーーーーーーがーーーーーーー [KTGR]
>| 【そのつかさどる】ーーーーーーーー秋のーーーーーー木の葉ーーーーーーがーーーーーーー [KBT]
>| ーーーーーーーーーーーーーーーーー秋の【紅葉した】ー（葉）ーーーーーがーーーーーーー [MTD]
>| ーーーーーーーーーーーーーーーーー・・ーーーーーー（紅葉）ーーーーーがーーーーーーー [OKMR]
>| 【それであのように】ーーーーーーー秋のーーーーーー木の葉ーーーーーーがーーーーーーー [TKOK]
>| 【このように御自身お染めなされた】秋のーーーーーー木の葉ーーーーーーがーーーーーーー [KNK]
>| ーーーーーーーーーーーーーーーーー秋のーーーーーー木の葉【のもみじ】がーーーーーーー [K&A]
>| ーーーーーーーーーーーーーーーーー秋のーーーーーー木の葉ーーーーーーがーーーーーーー [KMCY]
>| ーーーーーーーーーーーーーーーーー秋のーーーーーー（紅葉）ーーーーーがーーーーーーー [KSJ]
>| ーーーーーーーーーーーーーーーーー・・ーー【山の】（紅葉）ーーーーーがーーーーーーー [OZW]

#  Scattered as scared paper (which are ritual objects used in Shinto practices)
>| ーーーーーーーー幣ーーーーーーーーとー散ーーーーるーーーーーーーーらめーーーーーーー [298]
>| ーーーーーーーー幣【を撒く】（ように）散（っている）ーーーーのーだろうーーーーーーー [KTGR]
>| ーーーーーーーー幣ーーーー（のように）散ーーーーるーーーーーのであろうーーーー【よ】 [KBT]
>| ーーーーーーーー幣ーーーー（のように）散（っている）ーーーーのーだろうーーーーーーー [MTD]
>| ーーーーーーーー幣ーーーー（のように）散（っている）ーーーーー【だろう＊】ーーーーー [OKMR]
>| ーーーーーーーー幣ーーーーー（として）散（っている）ーーーーのであろうーーーーーーー [TKOK]
>| ー【手向けの】ー幣ーーーー（のように）散ーーーーるーーーーーのであろうーーーーーーー [KNK]
>| ー【手向け】（もの）ーーーー（として）散ーーーーるーーーーーのでしょうーーーー【ね】 [K&A]
>| ーーーーーーーー幣ーーーー（となって）散（っている）ーーーーのーだろうーーーーーーー [KMCY]
>| ーーーーーーーー幣ーーーー（となって）散（っている）ーーーーのであろうーーーーーーー [KSJ]
>| 【色とりどりの】幣ーーーー（となって）散（っている）【中略】のだーー・ーーーー【な】 [OZW]
```

アライメント（後半）：秋の木の葉の 幣と散るらめ Alignment (second half): aki no konoha no nusa to chiru rame 'leaves of autumn may be scattered as scared papers [which is dedicated to the god]'

:::

10人の訳者のアライメント（筆者がアライメント推定プログロムの出力を修正して作成）：「【】」は追加と判断する要素である；「（）」は言い換えと判断する要素である。「＊」は、句の順序の入れ替えで対応しうる文・語である。「・」は直訳されていないと判断する要素のプレースホルダーである。 Alignment of translations by 10 translators (the author corrected the output of the alignment estimation program): Elements in "【】" are judged as additions, those in "（ ）" are considered paraphrases, "＊" indicates phrases or words aligned through sentence reordering, and "・" represents elements judged not to be translated directly.

::::

#### 共出現語の訳出 Additional elements regarding co-occurring words {.unnumbered}

コーパスレベルの共出現語を確認する。「タツタ」歌において、内容語の「山」「川」「紅葉づ」「姫」「手向く」「紅葉葉」「神無備」「秋」「幣」「散る」の頻度が高い。298 番歌は典型的な「タツタ」歌として、「姫」「手向く」「幣」「秋を含めている。含まれている語のほとんどは、そのまま訳出された。298 番には出現しない「紅葉葉」「紅葉づ」などは、298 番歌において「木の葉」が暗示しているため、次のように処理されている：

- 紅葉した葉 [MTD]
- 木の葉のもみじ [K&A]
- 紅葉  [KSJ, OZW, OKMR]

TKOK, KNK, KMCY は「このは」の処理をしなかった。

また、コーパスレベルの共出現語「幣」について

- 【色とりどりの】幣 [OZW]
- 【手向けの】幣 [KNK]
- 幣【を撒く】（ように）散（っている） [KTGR]

のように追加は見られた。ただし、これらの追加が「タツタ」に帰属させるべきか、判断が難しい一面がある。「幣」に経由して間接的な情報と捉えて妥当であろう。

基本的に、コーパスレベルにおいて「タツタ」の共出現要素の処理は、そのまま残す方針か、その他の要素より多く追加する方針かになっていることが伺える。また、「このは」のような共出現ではないものについては、大局的なコロケーションを踏まえ「紅葉」であるとして訳出されるケースが見られた。訳出の方針は、訳者を問わず安定的な翻訳になっている。

訳と原文の差分において、コーパスレベルの共出現語について重要な情報が見えてくると推測できる。

This section examines the translation process for co-occurring words at the corpus level. In the "Tatsuta" poem, content words such as "mountain" (*yama* 山), "river" (*kawa* 川), "to turn colored" (*momidzu* 紅葉づ), "princess/goddess" (*hime* 姫), "to dedicate offerings to the gods" (*tamuku* 手向く), "colored leaf" (*momiji-ba* 紅葉葉), "Kamnabi" (proper noun, *kamnabi* 神無備), "autumn" (*aki* 秋), "ritual paper" (*nusa* 幣), and "to be scattered" (*chiru* 散る) frequently appear. As a typical "Tatsuta" poem, Poem #298 includes "princess/goddess," "to dedicate offerings to the gods," "ritual paper," and "autumn." Most of the words from the original poem are translated directly. Words like "colored leaf" (*momidzi-ba* 紅葉葉) and "to get colored" (*momidzu* 紅葉づ), which do not explicitly appear in Poem #298, are implied by "leaves" (*konoha* 木の葉) and are translated as follows:

- 【紅葉した】葉 *[momiji shita] ha* ("[colored] leaves") [MTD]
- 木の葉【のもみじ】 *konoha [no momiji]* ("[coloring of] leaves") [K&A] 
- 紅葉 *[momiji]* ("[colored leaves]") [KSJ, OZW, OKMR]

Translators TKOK, KNK, and KMCY did not address the translation of "leaves."

For the corpus-level co-occurrence of "ritual paper," the following translations added extra elements:

- 【色とりどりの】幣 *[irotoridori no] nusa* ("[colorful] ritual paper") [OZW]
- 【手向けの】幣 *tamuke no nusa* ("ritual paper [offered to the gods]") [KNK]
- 幣【を撒くように】 *nusa wo maku yo ni* ("ritual paper [scattered like]") [KTGR]

These additions raise some challenges in determining whether they should be attributed specifically to "Tatsuta." However, interpreting them indirectly within the context of "ritual paper" seems reasonable.

Overall, the process of co-occurring elements in "Tatsuta" either retains the original content or adds more compared to other factors. In cases where words like "leaves" do not explicitly co-occur, translators opted for "colored leaves," considering broader collocations. Regardless of the translator, the approach to translation remained consistent.

The differences between the translations and the original text suggest that co-occurring words at the corpus level may offer important insights into translation choices.

#### 構文パターンの訳出 Translation of grammatical patterns {.unnumbered}

共出現する構文パターンとして、終止形で終わる歌の少なさ (古今集 12 首の中で 1 首のみ) が観測されている。また、古今集の中では、係り結びは 9 (12) 首と観測されており、
余韻の残し方に特徴があると思われる。これら終わり方の構文パターンは、298 番歌の訳における処理について分析した。

298 番歌の係り結びは、強意の「こそ」と推量の「らむ」の已然形「らめ」で形成されていた。その訳として、10 人の中の 7 人が「こそ」を残しており、さらに 9 人が文末において「強意」の「ノダ」構文を使用した。推量の「らむ」について 9 人が「だろう・でしょう」と訳した。唯一「だろう」で訳さない OZW は「だな」という詠嘆的な口調で訳されている。
KBT, K&A は文末にそれぞれ「よ」「ね」の終助詞を追加した。

典型的な構文パターンとして、その訳出が非常にロバストなものになっていることが確認できた。ほかの係り受けを使わない「タツタ」歌の翻訳においても、この構文パターンが干渉して追加されているかいなか確認したところ、事例が見当たらなかった。つまり、特徴的な共出現の構文パターンの処理は、如実な訳であった。

その他文法的な要素、格助詞の「と」、動詞の「-u」段変形の訳は、コーパスレベルにおいて「タツタ」の特徴的の共出現ではないが、観察した。その結果、次のようにそれぞれ多様な訳し方が確認された。

[幣]「と」：

- [幣を撒く|幣の]ように [KTGR, KBT, MTD, OKMR, KNK]
- [幣|手向けもの]として [TKOK, K&A]
- [幣]となって [KMCY, KSJ, OZW]

[散]「る」

- [散っ]ている [KTGR, MTD, OKMR, TKOK, KMCY, KSJ, OZW]
- [散]る [KBT, KNK, K&A]

[手向け]「る」

- [手向けを]する [KTGR, K&A, KMCY]
- [供え物をささげ|手向け]る [MTD, TKOK]
- [手向けを|お手向け]なさる [OKMR, KNK]
- [手向けを]するべき [KBT]
- [手向け]られる [KSJ]
- [それを供え]ていらっしゃる [OZW]

コーパスレベルの共出現構文要素より訳の追加・言い換えの揺れが大きい。この中で動詞フレーズの訳され方の揺れについては、@Yamamoto2023Development でも報告されている。これらの追加要素と言い換えは、古語・現代語の言語変化・変異に由来したものと考えている。分類語彙表番号で一致と認定できず、現代語訳と原文の差分において抽出されるようになるが、ノンリテラル情報とは言い難い。

Co-occurring grammatical patterns in the *Kokinshū* reveal a noticeable scarcity of poems ending in the conclusive form (only 1 out of 12), along with a frequent use of *kakarimusubi* (9 out of 12 poems), which contributes to a lingering tone at the end of the poems. This analysis focuses on how these grammatical patterns were handled in the translation of Poem #298.

In Poem #298, the *kakarimusubi* is formed by the emphasis particle "こそ" (*koso*) and the inferential mood auxiliary verb "らむ" (*ramu*) in its conjugation "らめ" (*rame*). Of the 10 translators, 7 retained *koso*, and 9 used the EMPHASIS "の[でしょう]" (*no*) construction at the end of the sentence. Regarding inferential *ramu*, 9 translators rendered it as "だろう" (*darō*) or "でしょう" (*deshō*) ("likely modality/inferential mood"). OZW, the only translator who did not use "だろう" (*darō*), translated it with the exclamatory "だな" (*da na*). KBT and K&A added the final particles "よ" (*yo*) and "ね" (*ne*), respectively, at the sentence’s end.

This confirms that the translation of this typical grammatical pattern is highly robust. In translations of other "Tatsuta" poems that do not use *kakarimusubi*, no instances were found where this grammatical pattern was added. Thus, the handling of these distinctive co-occurring grammatical patterns was consistently reflected in the translations.

Other grammatical elements, such as the particle "と" (*to*) and the translation of the *-u* verb conjugation, were also observed, though they are not characteristic co-occurring elements of "Tatsuta" at the corpus level. The following variations in translation were noted:

**幣「と」 (*nusa "to"*):**

- 幣を撒く「ように」 *nusa wo maku [youni]* ("[like] scattering ritual paper") [KTGR, KBT, MTD, OKMR, KNK]
- 幣「として」 *nusa [toshite]* ("[as] ritual paper") [TKOK, K&A]
- 幣「となって」 *nusa [tonatte]* ("[becomes] ritual paper") [KMCY, KSJ, OZW]

**散「る」 (*chir-[u]*):**

- 散っ「ている」 *chir-[teiru]* ("scatter + [progressive aspect]") [KTGR, MTD, OKMR, TKOK, KMCY, KSJ, OZW]
- 散「る」 *chir-[u]* ("scatter") [KBT, KNK, K&A]

**手向け「る」 (*tamuker-[u]*):**

- 手向けを「する」 *tamuke wo suru* ("[do] dedicating") [KTGR, K&A, KMCY]
- 供え物をささげ「る」 *sonaemono wo sasager-[u]* | 手向け「る」 *tamuker-[u]* ("dedicate") [MTD, TKOK]
- 手向けを「なさる」 *tamuke wo nasaru* | お手向けなさる *o-tamuke nasaru* ("[make+(honorific)] dedicating") [OKMR, KNK]
- 手向けを「するべき」 *tamuke wo suru [beki]* ("[do + likely mood/modality] dedicating") [KBT]
- 手向け「られる」 *tamuke [rareru]* ("dedicate + [honorific]") [KSJ]
- それを供えて「いらっしゃる」 *sore wo sonaete [irassharu]* ("dedicate + [progressive aspect + honorific]") [OZW]

The co-occurring grammatical elements at the corpus level show significant variation in the addition and paraphrasing of translations. The variability in how naked verb phrases are translated has also been reported in @Yamamoto2023Development. These additions and paraphrases likely stem from linguistic change and variation between classical and contemporary Japanese. While they cannot be identified using WLSP codes for identifying agreements, they emerge from the differences between the contemporary translations and the original text. But they are not considered non-literal information.

#### 共出現語の意味傾向の訳出 Translation of semantic preferences {.unnumbered}

「タツタ」のコーパスレベルでの共出現語の傾向としては、「タツタガワ」「タツタ(の)ヤマ」など地名を構成する「山・川」のグループ、秋の「神」に関連する関連語のグループに属していることがあげられる。秋・紅葉が有名な神聖な場所の歌枕として使われている性質が伺える。この傾向性は、298番の歌でどのように明確にされているかはやはり直接な追加がなかった。ただし、間接的な現象として、10 人の訳では、「タツタヒメ」「カミ」のまわりに追加要素が集中して出現していることが確認された。
「タツタヒメ」に対する要素の追加は、10 人のうち 7 人が行っている：

- 【秋をつかさどる】龍田姫【が旅立ちにあたって】 [KTGR]
- 【秋も終りに近づき秋の女神の】龍田姫【がお帰りになる】 [OKMR]
- 竜田姫【が旅にあって】 [TKOK]
- 立田姫【は秋の神だが】 [KNK]
- 【帰り道についた】龍田姫【が道中の無事を願って】 [KMCY]
- 【秋も終りに近づき】竜田姫【がお帰りになる際に】 [KSJ]
- 【もはや秋の終りで】龍田姫【が帰り道にお着きになった】 [OZW]

KBT, MTD, K&A の訳では「タツタヒメ」のまわりの追加が確認されなかった。
「手向ける神」の文脈に確認できる追加は 5 人の訳から観測できた。

- 【旅中】（供え物をささげる）【道祖】神 [MTD]
- 【姫が道中の安全を祈って】手向け（をなさる）神 [OKMR]
- 【それすら暮れて行かれる折には】【お】手向け（なさる）【道の】神【様】 [KNK]
- 【旅の安全を祈って】手向け（られる）神 [KSJ]
- 【道の】（神様）【にそれを】（供えていらっしゃる）＊ [OZW]

K&A, KMCY, KTGR, KBT, TKOK は要素の追加を行わなかった。「タツタヒメ」「手向く」「カミ」の情報について、ほかの要素よりも重点的に情報の提供を行っていることが推測される。「タツタヒメ」が「秋の神」・秋の擬人化で、立田姫の「手向く」目的が「旅の安全」で、手向く対象の「神」が道の神、旅の神、道祖神であるといった、情報の補足が現代語訳と原文の差分で抽出できると考えられる。

At the corpus level, the co-occurring words in "Tatsuta" tend to belong to groups like "mountain" and "river" (*yama* and *kawa*), which form place names such as "Tatsutagawa" (Tatsuta River) and "Tatsuta(no)yama" (Mountain of Tatsuta). Additionally, words related to the "gods" of autumn are prominent. These reflect the nature of *utamakura* (poetic place names), which represent sacred locations associated with autumn and autumn leaves. Although this tendency is not directly emphasized in Poem #298 through explicit additions, it was observed indirectly that additional elements often appeared around "Tatsutahime" (Goddess Tatsuta) and "kami" (god) in the translations by the 10 translators.

Seven of the 10 translators added elements related to "Tatsutahime":

- 【秋をつかさどる】龍田姫【が旅立ちにあたって】 *[aki wo tsukasadoru] Tatsutahime [ga tabidachi ni atatte]* ("[Autumn goddess] Tatsutahime [embarks on her journey]") [KTGR]
- 【秋も終りに近づき秋の女神の】龍田姫【がお帰りになる】 *[aki mo owari ni chikazuki aki no megami no] Tatsutahime [ga okaeri ni naru]* ("[As autumn nears its end, the autumn goddess] Tatsutahime [returns home]") [OKMR]
- 竜田姫【が旅にあって】 *Tatsutahime [ga tabi ni atte]* ("Tatsutahime [is on a journey]") [TKOK]
- 立田姫【は秋の神だが】 *Tatsutahime [wa aki no kami da ga]* ("Tatsutahime [is the god of autumn]") [KNK]
- 【帰り道についた】龍田姫【が道中の無事を願って】 *[kaerimichi ni tsuita] Tatsutahime [ga dōchū no buji wo negatte]* ("[As she reached her way home,] Tatsutahime [prays for a safe journey]") [KMCY]
- 【秋も終りに近づき】竜田姫【がお帰りになる際に】 *[aki mo owari ni chikazuki] Tatsutahime [ga okaeri ni naru sai ni]* ("[As autumn nears its end,] Tatsutahime [returns home]") [KSJ]
- 【もはや秋の終りで】龍田姫【が帰り道にお着きになった】 *[mohaya aki no owari de] Tatsutahime [ga kaerimichi ni otsuki ni natta]* ("[With autumn already at its end,] Tatsutahime [has arrived on her journey home]") [OZW]

In the translations by KBT, MTD, and K&A, no additional elements were added around "Tatsutahime."

For the context of "the god to whom offerings are made," additional elements appeared in 5 translations:

- 【旅中】（供え物をささげる）【道祖】神 *[tabi naka] (sonaemono wo sasageru) [dōso] kami* ("[During the journey] (offering a gift) [to the road] god") [MTD]
- 【姫が道中の安全を祈って】手向け（をなさる）神 *[hime ga dōchū no anzen wo inotte] tamuke (wo nasaru) kami* ("[The goddess prays for safety during the journey] as she offers to the god") [OKMR]
- 【それすら暮れて行かれる折には】【お】手向け（なさる）【道の】神【様】 *[sore sura kurete ikareru ori ni wa] [o]tamuke (nasaru) [michi no] kami[sama]* ("[At the time of her departure as the day ends,] the offering to the god [of the road]") [KNK]
- 【旅の安全を祈って】手向け（られる）神 *[tabi no anzen wo inotte] tamuke (rareru) kami* ("[Praying for a safe journey,] the god receives the offering") [KSJ]
- 【道の】（神様）【にそれを】（供えていらっしゃる）＊ *[michi no] (kamisama) [ni sore wo] (sonaete irassharu)* ("To the god [of the road,] (she is offering) [that]")＊ [OZW]

K&A, KMCY, KTGR, KBT, and TKOK did not add elements in these contexts. It can be inferred that more emphasis is placed on providing additional information related to "Tatsutahime," "offerings," and "gods" than other elements. The differences between the original and contemporary translations suggest that "Tatsutahime" is the "autumn god" or a personification of autumn, the purpose of "offering" by Tatsutahime is for "safe travels," and the god receiving the offering is a road god, a travel god, or *dōsojin* (a deity protecting travelers).

# 考察 Discussion {#sec-discussion}

## 追加率からみる翻訳アプローチと翻訳実践とのずれ Gap between translation approaches and practices

現代語訳における追加率の予測モデリングの結果、いずれの翻訳アプローチにおいても、相当の比例の追加要素が含まれえていることが再現できた。訳者の間の変動より、歌による変動のほうが大きいと考えられる。注釈書では、多くの語の解釈が注釈によって詳しく解説されていながらも、追加率が低下しているとはいえなかった。訳者の目線がテキストを重視するにせよ、作者の意図を重視するにせよ、読者の読み易さを重視するにせよ、基本的に追加せざるをえない要素があることがあると考えられる。

ただし、中では、それぞれの訳を具体的に確認すると、 OZW が語順の入れ替えを許容するなり、TKOK の訳が著者の本意を重視するなりの方針は確実にその実践に反映されている。個別の歌を精査することで明確な差が見えてくるものの、大局的にその差が傾向としかいえなかった。それらの要素は、つまり、翻訳の目線、訳者の違いに左右されないものであり、その性質を明確する余地が残っている。現代語訳によるノンリテラル要素の可視化が十分考えられる。

The statistical modeling of addition rates in contemporary translations shows that a substantial proportion of additional elements is present, regardless of the translation approach. It appears that variations between poems contribute more to the addition rate than variations between translators. Despite the detailed explanations of many words in annotation books, the addition rate has not significantly decreased. Whether translators focus on the text itself, the poet's intent, or making the translation more accessible to readers, there seem to be elements that inevitably require additions.

Closer examination of individual translations reveals clear reflections of each translator's approach. For instance, OZW allows for changes in word order, while TKOK’s translations emphasize the author's intent. While analyzing specific poems uncovers distinct differences, these differences, when viewed collectively, tend to emerge as general trends rather than significant variations. These factors seem to go beyond the personal viewpoint and style of the translator, leaving room to further clarify the nature of these elements. The non-literal elements in contemporary translations could potentially be visualized more effectively.

## 現代語訳における「欠落」の多くは序詞、枕詞 Many "omissions" in contemporary translations involve *jokotoba* and *makurakotoba*

差分によるノンリテラル情報の抽出の際に、間接的な訳が望ましいと考えられるが、訳されない語の存在がないことが望ましくない。対訳文同士の不一致率が高い場合、なんらかの形で訳に含めている可能性はいなめないが翻訳において、欠落した要素が多いと考えられる。このような歌・訳の対がいくつか見られた。

これらの対訳対を考察したところ、 10 人の現代語訳に共通して欠落がみられたのは「序詞」「枕詞」「まわりくどい言い回し」の３点であった。訳者の幾人かは意識的に「序詞」「枕詞」を訳さないで放置していることが観測された。たとえば、@matsuda1968Shinshaku の現代語訳では、4 首は現代語訳の方がもとの歌より短くなっている。MTD (173) と MTD (665) の訳においては、枕詞「ひさかたの」「みつしほの」は省略されている。MTD (684) の MTD (697) の訳においては、枕詞も序詞も省略されている。これらの歌は当然不一致率も高い。特に、MTD (697) はもとの和歌よりもずっと短い^[KSJ (404) もまた極端に短く、序詞がやはり省略されている。]。MTD (697) では大和の枕詞「敷島の」が省略されている。元の歌は、「頃も」と「衣」が掛詞になっているが、その「衣」に掛かっていく序詞も省略されている。

このように、現代語文と歌の差分では、枕詞と序詞などについてのノンリテラル要素の抽出が難しいという一面が伺える。

When extracting non-literal information through translation differences, it is preferable for indirect translations to be included, but it becomes problematic when certain words are entirely absent. A high unmatch rate between the original and the translation may indicate that some elements are incorporated in some form, but it is also likely that many elements have been omitted. Several such poem-translation pairs have been identified.

Upon reviewing these pairs, three common omissions were observed across the 10 contemporary translations: *jokotoba* (prefatory phrases), *makurakotoba* (pillow words), and complex expressions. Some translators consciously chose to omit *jokotoba* and *makurakotoba* entirely. For example, in MTD’s translations, four of them are noticeably shorter than the original poems. In MTD (#173) and MTD (#665), the *makurakotoba* "hisakata no" and "mitsushio no" are omitted. In MTD (#684) and MTD (#697), both *makurakotoba* and *jokotoba* are omitted. Naturally, these omissions result in a high unmatch rate. Notably, MTD (#697) is much shorter than the original poem^[KSJ (#404) is also significantly shorter, with the *jokotoba* similarly omitted.]. In MTD (#697), the *makurakotoba* "Shikishima no," referring to "Yamato" (a proper noun), is omitted. In the original poem, there is a *kakekotoba* (pun) on "koromo" (meaning either "time" or "clothes"), but the *jokotoba* linked to "clothes" is also omitted.

Thus, extracting non-literal elements such as *makurakotoba* and *jokotoba* from the differences between contemporary translations and the original poems proves to be a challenging task.

::: {fig-mtd-697}
```
mode=2; level=3; elements of poem=16; elements of translation=6;
bag (E=1, F=0, G=0, U=15, T=1, AddRate=83.33%, UnmatchRate=93.75%);
alignment (E=1, F=0, G=0, U=15, T=1, AddRate=83.33%, UnmatchRate=93.75%)
>| しきしまのやまとにはあらぬからころもころもへずしてあふーーよしーーーもがな [697]
>| ーーーーーーーーーーーーーーーーーー絶え間なくーー会いたいものだなあーーー [MTD]
```

697 番歌の @matsuda1968Shinshaku による現代語訳：アライメントの結果を書き換えている；「しきしまのやまとにはあらぬからころも」が省略されている。
Contemporary translation of Poem #697 by @matsuda1968Shinshaku: The alignment has been revised; the *jokotoba* "Shikishima no Yamato ni wa aranu kara koromo" has been omitted.
:::

```{python}
#| include: false

op697 = '''
01:000697:0001 A00 CH-JP-0000-00-0100 11 敷嶋 敷島 しきしま 敷島 しきしま
01:000697:0002 A00 BG-08-0061-07-0100 61 の の の の の
01:000697:0003 A00 BG-01-2590-01-0500 11 やまと 大和 やまと 大和 やまと
01:000697:0003 A10 CH-29-0000-00-2800 11 やまと 大和 やまと 大和 やまと
01:000697:0003 A20 CH-JP-0000-00-0300 11 やまと 大和 やまと 大和 やまと
01:000697:0004 A00 BG-08-0061-05-0100 61 に に に に に
01:000697:0005 A00 BG-08-0065-07-0100 65 は は は は は
01:000697:0006 A00 BG-02-1200-01-0102 47 あら 有り あり 有ら あら
01:000697:0007 A00 BG-03-1200-02-0800 74 ぬ ず ず ぬ ぬ
01:000697:0007 A10 BG-09-0010-01-0100 74 ぬ ず ず ぬ ぬ
01:000697:0008 B00 BG-01-4220-06-0800 02 唐衣 唐衣 からころも 唐衣 からころも
01:000697:0008 C00 BG-01-2590-02-0600 02 唐 唐 から 唐 から
01:000697:0008 C01 BG-01-4220-02-0200 02 衣 衣 ごろも 衣 ごろも
01:000697:0009 A00 BG-01-1610-01-0401 02 ころ 頃 ころ 頃 ころ
01:000697:0010 A00 BG-08-0065-08-0100 65 も も も も も
01:000697:0011 A00 BG-02-1600-01-0200 47 へ 経 ふ 経 へ
01:000697:0012 A00 BG-03-1200-02-0800 74 す ず ず ず ず
01:000697:0012 A10 BG-09-0010-01-0100 74 す ず ず ず ず
01:000697:0013 A00 BG-08-0064-38-0100 64 して して して して して
01:000697:0014 A00 BG-02-1556-01-0206 47 逢 逢ふ あふ 逢ふ あふ
01:000697:0014 A10 BG-02-3510-01-0100 47 逢 逢ふ あふ 逢ふ あふ
01:000697:0015 A00 BG-01-1020-02-0100 02 よし 由 よし 由 よし
01:000697:0015 A10 BG-01-3081-01-0800 02 よし 由 よし 由 よし
01:000697:0015 A20 BG-01-3081-04-1200 02 よし 由 よし 由 よし
01:000697:0016 A00 BG-03-1330-01-1400 69 もかな もがな もがな もがな もがな
01:000697:0016 A10 BG-03-3012-03-2700 69 もかな もがな もがな もがな もがな
01:000697:0016 A20 BG-08-0069-20-0100 69 もかな もがな もがな もがな もがな
'''
ct697 = '''
1 matsuda 0697 1 55 00 00 BG-03-1600-02-140-A 絶え間なく たえまなく 絶え間なく
1 matsuda 0697 3 55 00 00 BG-02-1240-04-010-A -- たえる 絶える
1 matsuda 0697 3 55 00 00 BG-01-1610-03-010-A -- ま 間
1 matsuda 0697 3 55 00 00 BG-09-0010-01-050-A -- ない ない
1 matsuda 0697 0 47 21 04 BG-02-1556-01-020-A 会い あう 会う
2 matsuda 0697 2 47 21 04 BG-02-3510-01-010-A 会い あう 会う
1 matsuda 0697 0 74 53 01 BG-03-3012-03-020-A たい たい たい
2 matsuda 0697 2 74 53 01 BG-09-0050-03-010-A たい たい たい
1 matsuda 0697 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0697 0 74 55 01 BG-09-0050-01-030-A だ だ だ
1 matsuda 0697 0 69 00 00 BG-04-3200-03-030-A なあ なあ なあ
2 matsuda 0697 2 69 00 00 BG-08-0069-11-040-A なあ なあ なあ
1 matsuda 0697 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op697, translation=ct697, mode=2, level=3)
```

```{bash}
#| include: false

awk '$1 ~ /01:000346/ && $2 ~ /[ABD]0/ {printf "%s", $5}' ./data/hachidaishu/hachidai.db
echo ""
awk -v translator="okumura" '$3 ~ /0346/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
```

```{python}
#| include: false

op346 = '''
01:000346:0001 A00 BG-01-2000-01-0102 14 わ 我 わ 我 わ
01:000346:0002 A00 BG-08-0061-02-0100 61 か が が が が
01:000346:0003 A00 BG-01-1911-03-0100 02 齢 齢 よはひ 齢 よはひ
01:000346:0004 A00 BG-01-2000-02-0300 14 君 君 きみ 君 きみ
01:000346:0005 A00 BG-08-0061-02-0100 61 か が が が が
01:000346:0006 B00 BG-03-1600-09-1500 02 やちよ 八千世 やちよ 八千世 やちよ
01:000346:0006 C00 BG-01-1950-04-0900 19 八千 八千 はっせん 八千 はっせん
01:000346:0006 C01 BG-01-2610-01-0400 02 世 世 よ 世 よ
01:000346:0007 A00 BG-08-0061-05-0100 61 に に に に に
01:000346:0008 A00 BG-02-1250-03-1100 47 とり 取る とる 取り とり
01:000346:0008 A10 BG-02-3061-04-0100 47 とり 取る とる 取り とり
01:000346:0008 A20 BG-02-3700-04-0100 47 とり 取る とる 取り とり
01:000346:0009 A00 BG-02-1556-05-0100 47 そへ 添ふ そふ 添へ そへ
01:000346:0009 A10 BG-02-1580-02-0700 47 そへ 添ふ そふ 添へ そへ
01:000346:0010 A00 BG-08-0064-16-0100 64 て て て て て
01:000346:0011 A00 BG-02-1240-01-1300 47 とゝめ 留む とどむ 留め とどめ
01:000346:0011 A10 BG-02-1512-01-0400 47 とゝめ 留む とどむ 留め とどめ
01:000346:0012 A00 BG-02-1515-03-0100 47 をき 置く おく 置き おき
01:000346:0013 A00 BG-09-0010-03-0100 74 て つ つ て て
01:000346:0014 A00 BG-08-0064-26-0100 64 は ば ば ば ば
01:000346:0015 A00 BG-02-3060-01-0101 47 思ひ 思ふ おもふ 思ひ おもひ
01:000346:0016 A00 BG-02-1210-01-0304 47 て 出づ いづ 出で いで
01:000346:0016 A10 BG-02-1530-01-0101 47 て 出づ いづ 出で いで
01:000346:0016 A20 BG-02-1540-04-0601 47 て 出づ いづ 出で いで
01:000346:0017 A00 BG-08-0061-05-0100 61 に に に に に
01:000346:0018 A00 BG-02-3420-01-0100 47 せよ す す せよ せよ
'''
ct346 = '''
1 okumura 0346 0 14 00 00 BG-01-2000-01-020-A 私 わたし 私
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 02 00 00 BG-01-5800-02-050-A 命数 めいすう 命数
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 14 00 00 BG-01-1730-03-030-A あなた あなた あなた
2 okumura 0346 2 14 00 00 BG-01-1731-02-030-A あなた あなた あなた
3 okumura 0346 2 14 00 00 BG-01-2000-02-010-A あなた あなた あなた
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 02 00 00 BG-01-5800-03-020-A 長寿 ちょうじゅ 長寿
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 22 00 00 BG-01-1741-01-030-A 上 うえ 上
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 02 00 00 BG-03-1661-01-020-A さら さら さら
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 47 21 06 BG-02-1700-02-040-A 沿え そう 沿う
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 0 47 12 04 BG-02-1240-01-020-A 残し のこす 残す
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 0 48 08 04 BG-02-1515-03-010-A おき おく おく
1 okumura 0346 0 74 58 03 BG-09-0030-03-030-A ましょ ます ます
1 okumura 0346 0 74 70 01 BG-09-0010-02-010-A う う う
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 57 00 00 BG-03-1000-02-010-A その その その
1 okumura 0346 0 22 00 00 BG-01-1000-03-040-A 分 ぶん 分
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 43 00 00 BG-05-0070-01-010-A お お お
1 okumura 0346 0 47 06 04 BG-02-5810-04-010-A 生き いきる 生きる
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 47 17 01 BG-02-1220-01-030-A なる なる なる
1 okumura 0346 0 22 00 00 BG-01-5620-04-110-A とき とき とき
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 65 00 00 BG-08-0065-07-010-A は は は
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 55 00 00 BG-04-3140-01-040-A どうぞ どうぞ どうぞ
1 okumura 0346 0 14 00 00 BG-01-2000-01-020-A 私 わたし 私
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 47 12 04 BG-02-3050-03-070-A 思い出し おもいだす 思い出す
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 1 48 19 09 BG-02-3770-05-030-A 下さい くださる 下さる
1 okumura 0346 2 48 19 09 BG-02-3770-05-020-A -- くれる くれる
1 okumura 0346 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op346, translation=ct346, mode=3, level=3, gap_penalty=0.01,u=10,g=20,e=50)
```

さて、和歌と現代語訳の間にある回りくどい表現についても、どうにかして一致させたいと願うかもしれないが、残念ながら、その願いを叶えることは技術的に難しい。例えば、OKMR (346) は、奥村の現代語訳は和歌の語をほとんど使わず、あえてつぎのように回りくどい表現を使っている。：

- 「とりそへて」=「さらにそえて」
- 「とどめおきて」=「のこしておきましょう」

整列法は、このような歌をうまくアライメントできなかった。ある歌ことばと回りくどい言い方が同等の意味を持つことばを辞書に用意し、二者間の一致を実現させることは難しいと推察できよう。基本的に歌ことばと、そのまわりくどい言い方の一部との対応が可能になっているが、まわりくどい表現全体としての対応ができていない。この問題を語の対応の課題だと述べたものの、前述一対多の訳について言及したように一対多の訳と同様に、まわりくどい表現は元の歌ことばに情報を付随して生成されることが多いため、まわりくどい表現で対応で一致しない要素（つまり、訳のあまりもの）は、ノンリテラル要素を調べる目的からすれば、むしろ貴重なものなのである。

It may seem desirable to align the complex expressions found in the original poem with those in the contemporary translation, but achieving this is technically challenging. For example, in OKMR (#346), Okumura’s contemporary translation uses very few words from the original poem, instead opting for the following complex expressions:

- とりそえて *torisoete* = さらにそえて *sarani soete* ("additionally")
- とどめおきて *todome okite* = のこしておきましょう *nokoshite okimashō* ("let's leave it")

The alignment method struggles to handle expressions like this effectively. Creating a dictionary that pairs a single poetic word with a complex expression of equivalent meaning and achieves a perfect match is difficult. While it is sometimes possible to align certain poetic words with parts of complex expressions, it is rarely feasible to align the entire expression. This issue has been described as a problem of word alignment, and as previously mentioned in relation to one-to-many translations, complex expressions often add additional information to the original poetic words. As a result, the unmatched elements from these complex expressions (i.e., the leftover parts of the translation) are valuable when examining non-literal elements.

## 現代語の追加の多くは掛詞 Many additions in contemporary translations involve kakekotoba (pun)

MTD (#629) は、どの語も原文とは整列法においてほとんど一致しなかった。この歌は「あやなし」「まだき」などの古語、「なくに」のような現代語には使われない語法が含まれている。これらの語は、現代語と分類語彙表番号で対応づけることができない。
また「名のたつ」と「たつたがは」の掛詞も存在する。

追加率の平均値上位 10 首のうち、ほかにも 705 番歌、669 番歌、617 番歌など追加率の高かった和歌がある。705 番歌は「身」と「雨」に「降（経）る」の掛詞が含まれている。669 番歌と617番歌は、それぞれ「海藻目」と「ながめ」の掛詞がある。掛詞の役割を明確するには、訳での補足が求められており、現代語・古代語の差分で残る要素が多いと考えてよい。

MTD (#629) shows that most words did not align well with the original poem using the alignment method. This poem includes archaic words such as あやなし *ayanashi* ("without reason") and まだき *madaki* ("early"), along with grammatical constructions like なくに *naku ni* (negation with interjection nuance), which are no longer used in contemporary Japanese. These terms cannot be mapped to their modern equivalents using WLSP codes. Additionally, the poem contains a *kakekotoba* (pivot word) involving 名の立つ *na no tatsu* ("to have a rumor") and 立田川 *Tatsutagawa* ("Tatsuta River").

Among the top 10 poems with the highest average addition rates, other poems such as Poem #705, Poem #669, and Poem #617 also have high addition rates. Poem #705 features a *kakekotoba* involving 身 *mi* ("body") and 雨 *ame* ("rain"), with ふる (降る/経) *furu* serving a dual meaning: "(rain) to fall" and "(body) to age." Poem #669 and Poem #617 contain *kakekotoba* involving 海松目/見る目 *mirume* (a pun on "seaweed" and "to meet") and 眺め/長雨 *nagame* (a pun on "gaze/reverie" and "long rain"), respectively. To clarify the role of *kakekotoba*, supplemental information is often required in translations, and many elements likely remain unaligned when comparing contemporary and classical Japanese.

```{bash}
#| include: false
#| label: tatsuda-629

awk '$1 ~ /01:000629/ && $2 ~ /[ABD]0/ {printf "%s", $5}' ./data/hachidaishu/hachidai.db
echo ""
awk -v translator="matsuda" '$3 ~ /0629/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
```

::: {fig-mtd-629}

```
mode=2; level=3; elements of poem=15; elements of translation=60;
bag (E=1, F=2, G=6, U=6, T=9, AddRate=85.00%, UnmatchRate=40.00%);
alignment (E=1, F=0, G=6, U=8, T=7, AddRate=88.33%, UnmatchRate=53.33%)
args: translator:matsuda; poem No.0629; weight:(U=-1, G=10, F=13, E=17); gap penalty: 0.01

#  Without any reason,
1| ーーーーーーーーあやなくーーーてーーーーーーーーーーーーーーーーーーーーーーーーーー　[629]
1| わけもなくもう無実の評判が立ってしまったいずれ二人の恋は遂げられないではいられないも  [MTD]
#  soon rumor has spreaded, the River Tatsuta, without crossing, [I cannot] stop,
2| ーーーーーーーーーーーーまたきなき名のー立田河わたらてやまーーんーー物ーーーーーーー　[629]
2| のではあるがわけもなくもう無実の評判が立っーーーーーてしまったーいずれ二人の恋は遂げ  [MTD]
#  It is not possible...
3| ーーならーーなーーーーーーーくーーにーーーーーーーーーーーーーーーーーーーーーーーー  [629]
3| られないではいられないものではあるがーーーーーーーーーーーーーーーーーーーーーーーー　[MTD]
```

629 番歌の @matsuda1968Shinshaku による現代語訳：アライメントの結果を書き換えている Contemporary translation of Poem #629 by @matsuda1968Shinshaku: The alignment results have been modified.
:::

```{python}
#| include: false

op629 = '''
01:000629:0001 A00 BG-01-3072-03-1100 51 あやなく 文無し あやなし 文無く あやなく
01:000629:0002 A00 BG-08-0064-16-0100 64 て て て て て
01:000629:0003 A00 BG-03-1660-03-1100 55 またき 夙 まだき 夙 まだき
01:000629:0004 B00 BG-01-3440-07-0700 02 なき名 無き名 なきな 無き名 なきな
01:000629:0004 C00 BG-03-1200-02-0100 51 無い 無い ない 無い ない
01:000629:0004 C01 BG-01-3102-02-0100 28 名 名 めい 名 めい
01:000629:0005 A00 BG-08-0061-07-0100 61 の の の の の
01:000629:0006 D00 CH-29-5250-01-0400 11 立田河 立田河 たつたがは 立田河 たつたがは
01:000629:0006 E00 CH-29-0000-00-1800 11 立田 立田 たつた 立田 たつた
01:000629:0006 E01 BG-08-0071-01-0100 71 の の の の の
01:000629:0006 E02 BG-01-5250-01-0100 02 川 川 かわ 川 かわ
01:000629:0007 A00 BG-02-1503-01-0201 47 わたら 渡る わたる 渡ら わたら
01:000629:0007 A10 BG-02-1521-04-0100 47 わたら 渡る わたる 渡ら わたら
01:000629:0007 A20 BG-02-1521-12-0100 47 わたら 渡る わたる 渡ら わたら
01:000629:0008 A00 BG-08-0064-17-0100 64 て で で で で
01:000629:0009 A00 BG-02-1502-03-0100 47 やま 止む やむ 止ま やま
01:000629:0010 A00 BG-03-3012-03-2600 74 ん む む む む
01:000629:0010 A10 BG-09-0010-02-0102 74 ん む む む む
01:000629:0011 A00 BG-01-1000-03-0201 02 物 物 もの 物 もの
01:000629:0011 A10 BG-01-4000-01-0800 02 物 物 もの 物 もの
01:000629:0012 A00 BG-09-0010-02-0700 74 なら なり なり なら なら
01:000629:0012 A10 BG-09-0050-01-0100 74 なら なり なり なら なら
01:000629:0013 A00 BG-03-1200-02-0800 74 な ず ず な な
01:000629:0013 A10 BG-09-0010-01-0100 74 な ず ず な な
01:000629:0014 A00 BG-08-0071-05-0100 71 く く く く く
01:000629:0015 A00 BG-08-0061-05-0100 61 に に に に に
'''
ct629 = '''
1 matsuda 0629 0 02 00 00 BG-01-1113-01-030-A わけ わけ わけ
2 matsuda 0629 2 02 00 00 BG-01-3070-01-030-A わけ わけ わけ
1 matsuda 0629 1 65 00 00 BG-08-0065-08-010-A も も も
1 matsuda 0629 2 65 00 00 BG-04-1130-01-200-A -- も も
1 matsuda 0629 0 51 50 07 BG-03-1200-02-010-A なく ない ない
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 55 00 00 BG-03-1650-03-010-A もう もう もう
2 matsuda 0629 2 55 00 00 BG-03-1992-07-030-A もう もう もう
1 matsuda 0629 0 02 00 00 BG-03-1010-02-060-A 無実 むじつ 無実
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 02 00 00 BG-01-3134-01-210-A 評判 ひょうばん 評判
2 matsuda 0629 2 02 00 00 BG-01-3142-02-010-A 評判 ひょうばん 評判
3 matsuda 0629 2 02 00 00 BG-01-3422-04-080-A 評判 ひょうばん 評判
1 matsuda 0629 0 61 00 00 BG-08-0061-02-010-A が が が
1 matsuda 0629 0 47 13 05 BG-02-1513-01-010-A 立っ たつ 立つ
2 matsuda 0629 2 47 13 05 BG-02-1521-06-020-A 立っ たつ 立つ
3 matsuda 0629 2 47 13 05 BG-02-3330-11-020-A 立っ たつ 立つ
4 matsuda 0629 2 47 13 05 BG-02-3391-02-110-A 立っ たつ 立つ
1 matsuda 0629 0 64 00 00 BG-08-0064-16-010-A て て て
1 matsuda 0629 0 48 21 05 BG-02-1502-02-040-A しまっ しまう しまう
2 matsuda 0629 2 48 21 05 BG-09-0010-03-050-A しまっ しまう しまう
1 matsuda 0629 0 74 54 01 BG-09-0010-04-010-A た た た
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 14 00 00 BG-01-1000-01-110-A いずれ いずれ いずれ
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 16 00 00 BG-01-1950-13-020-A 二人 ふたり 二人
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 17 00 00 BG-01-3020-11-030-A 恋 こい 恋
2 matsuda 0629 2 17 00 00 BG-02-3060-03-070-A 恋 こい 恋
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-3420-07-010-A 遂げ とげる 遂げる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-1200-02-010-A い いる いる
2 matsuda 0629 2 47 06 02 BG-02-1210-03-010-A い いる いる
3 matsuda 0629 2 47 06 02 BG-02-1530-07-010-A い いる いる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 17 01 BG-02-1200-01-010-A ある ある ある
1 matsuda 0629 0 64 00 00 BG-08-0064-04-010-A が が が
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 02 00 00 BG-01-1113-01-030-A わけ わけ わけ
2 matsuda 0629 2 02 00 00 BG-01-3070-01-030-A わけ わけ わけ
1 matsuda 0629 1 65 00 00 BG-08-0065-08-010-A も も も
1 matsuda 0629 2 65 00 00 BG-04-1130-01-200-A -- も も
1 matsuda 0629 0 51 50 07 BG-03-1200-02-010-A なく ない ない
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 55 00 00 BG-03-1650-03-010-A もう もう もう
2 matsuda 0629 2 55 00 00 BG-03-1992-07-030-A もう もう もう
1 matsuda 0629 0 02 00 00 BG-03-1010-02-060-A 無実 むじつ 無実
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 02 00 00 BG-01-3134-01-210-A 評判 ひょうばん 評判
2 matsuda 0629 2 02 00 00 BG-01-3142-02-010-A 評判 ひょうばん 評判
3 matsuda 0629 2 02 00 00 BG-01-3422-04-080-A 評判 ひょうばん 評判
1 matsuda 0629 0 61 00 00 BG-08-0061-02-010-A が が が
1 matsuda 0629 0 47 13 05 BG-02-1513-01-010-A 立っ たつ 立つ
2 matsuda 0629 2 47 13 05 BG-02-1521-06-020-A 立っ たつ 立つ
3 matsuda 0629 2 47 13 05 BG-02-3330-11-020-A 立っ たつ 立つ
4 matsuda 0629 2 47 13 05 BG-02-3391-02-110-A 立っ たつ 立つ
1 matsuda 0629 0 64 00 00 BG-08-0064-16-010-A て て て
1 matsuda 0629 0 48 21 05 BG-02-1502-02-040-A しまっ しまう しまう
2 matsuda 0629 2 48 21 05 BG-09-0010-03-050-A しまっ しまう しまう
1 matsuda 0629 0 74 54 01 BG-09-0010-04-010-A た た た
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 14 00 00 BG-01-1000-01-110-A いずれ いずれ いずれ
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 16 00 00 BG-01-1950-13-020-A 二人 ふたり 二人
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 17 00 00 BG-01-3020-11-030-A 恋 こい 恋
2 matsuda 0629 2 17 00 00 BG-02-3060-03-070-A 恋 こい 恋
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-3420-07-010-A 遂げ とげる 遂げる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-1200-02-010-A い いる いる
2 matsuda 0629 2 47 06 02 BG-02-1210-03-010-A い いる いる
3 matsuda 0629 2 47 06 02 BG-02-1530-07-010-A い いる いる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 17 01 BG-02-1200-01-010-A ある ある ある
1 matsuda 0629 0 64 00 00 BG-08-0064-04-010-A が が が
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op629, translation=ct629, mode=2, level=3)
```

## 翻訳で開示できるノンリテラル要素の類型化

拡張意味単位からヒントともたった 3 つの観点で訳における追加要素を考察したところ、以下の類型化を提案できる。 

1. コーパスレベルでの共出現語に由来した追加要素
  - 共出現語の直接的な追加：「紅葉」など
  - 共出現語に対する補足、つまり二次的・間接的な追加：「幣」の「色とりどり」「撒く」など
2. 構文面での言語変化のギャップを埋める追加要素
  - 分類語彙表番号で一致と認定できない助詞の変化：「と」の訳し方
  - 動詞のハダカの形の増長：「手向ける」の訳し方
3. 対象語の意味志向をめぐる追加要素
  - コーパスレベルの共出現語の意味志向について余分に行っている補足：「神」をめぐる情報の補足

可視化システムを構築する際にこれらの要素の区別が重要である。まず、「木の葉」に補足しての「紅葉」は、センテンスレベルではノンリテラルであるが、コーパスレベルでは共出現語であり、よってリテラルであるといえる。差分による可視化でもアクセスできることが確認できたが、その他 word association measure でも十分抽出できる。そのため、差分による可視化の必要性を低くなる。
つぎに、構文の時代変化のギャップを埋めるための追加要素は、原文の語に由来するノンリテラル情報とは捉えられないため、除外する手続きを踏まなければならない。そして、共出現の語の集団的傾向性に関連する追加要素は、おそらく word association measure  では抽出できない。そこが差分による可視化の独自な利点と考えられる。

最後に、本稿では触れなかった拡張意味単位の第 4 のレベルである談話韻律の視点について補足する。談話韻律に相当する感情面の評価と、語の社会言語学的な属性は、 訳の追加要素では分からない情報と考えている。これらの属性を直接な補足と追加で明示化することはない。一部は現代語にある connotative term で言い換えられており、これら機能が相当する語の入れ替えであっても、その語自体が説明として直接成立しない。よって、これらの評価は、ほかの方法を求めるべきである。

Based on the concept of extended meaning units, we analyzed additional elements in translations from three perspectives and propose the following categorization:

1. Additional elements derived from co-occurring words at the corpus level:
   - Direct additions of co-occurring words: e.g., *momiji* (autumn leaves)
   - Supplementary or secondary/indirect additions to co-occurring words: e.g., "colorful" or "scattering" in reference to *nusa* (ritual paper)

2. Additional elements that fill gaps caused by language change, particularly grammatical shifts:
   - Changes in grammatical structures that cannot be matched using WLSP codes: e.g., the translation of *to* (particle)
   - Extensions of bare verb forms: e.g., the translation of *tamukeru* (to dedicate)

3. Additional elements related to the semantic preference of target words:
   - Further supplementation of words based on their semantic preference at the corpus level: e.g., additional information surrounding *kami* (god)

Distinguishing these elements is essential when constructing a visualization system. For instance, supplementing "autumn leaves" (*momiji*) to "leaves" (*konoha*) may be considered non-literal at the sentence level but literal at the corpus level, as it represents co-occurring words. This can be identified through difference-based visualization, though word association measures are also effective. As a result, the necessity for difference-based visualization in this case is reduced.

Next, additional elements that bridge gaps caused by grammatical shifts over time should be excluded, as they do not represent non-literal information derived from the original text. 

Moreover, elements related to the collective semantic preference of co-occurring words may not be easily captured through word association measures, which is where difference-based visualization provides unique advantages.

Lastly, this paper did not cover the fourth level of extended meaning units—discourse prosody—in detail. Emotional values related to discourse prosody and the sociolinguistic characteristics of words are considered elements that cannot be captured through additional elements in translation. These attributes are not explicitly conveyed through direct supplementation or additions. In some cases, connotative terms in contemporary Japanese may paraphrase these aspects, but even when such terms are functionally equivalent, they do not provide direct explicitation. Therefore, alternative methods should be considered to evaluate these elements.

## 翻訳の知識としての信憑性 Credibility of Knowledge in Translation

本稿では触れていないが、10 人の翻訳と原文の差分による可視化のシステムは、10 人の個々の歌に対する知見を総合するという意味で、ある種のメタ分析と見てよい。

しかし、現代語訳に含める知識の可視化は、どこまで歌ことばのノンリテラル情報にアクセスできるか、可視化としてどの程度妥当で、信頼できるかは、本稿では触れていない。たとえば、翻訳において、過剰に意味を付けることは解釈として妥当性と整合性を失う。本来のテキストのシンプルな意味や意図が、過剰な意味付けによって曖昧になり、読者がテキストを正しく理解することが難しくなりうる。そのような翻訳を可視化に応用すると、可視化自体の意味がなくなる。その可能性は考慮すべき一環であり、いかに訳者の訳語の中からロバストな部分を見出すかは翻訳に基づく可視化の重要な課題である。

Although this paper does not address the credibility in detail, the system for visualizing differences between the 10 translations and the original text can be seen as a form of meta-analysis, in the sense that it systematically synthesizes the insights of the 10 individual translators regarding each poem.

However, the paper does not explore how much the knowledge included in contemporary translations allows access to the non-literal aspects of the poetic language, or to what extent the translation is valid and reliable. For example, adding excessive interpretation in translation can undermine both validity and coherence. The original text’s simple meaning or intent may become ambiguous due to over-interpretation, making it difficult for readers to accurately understand the text. If such translations are applied to visualization, the visualization itself loses its credibility. This is a concern that must be considered. Finding robust elements within the translators’ choices is therefore a critical challenge for translation-based visualization.

## 翻訳研究の知見による解釈の必要性 The Need for Interpretation through Translation Studies Insights

本研究は、翻訳研究として位置づけるものではない、翻訳における要素の追加や、原文における要素の喪失などの現象は、翻訳研究における仮説と理論によって解釈する余地は大いにあると考えられる。

例えば、翻訳普遍性仮説 (translation universal hypothesis; cf., @Chesterman2004Hypotheses; @Edina2016Translation) における長さ増加の普遍性 (law of lenghtening, @Vinay1958Comparative) 、明示化の普遍性 (law of expicitation, @Baker1996Challenges; @Blum-Kulka1986Shifts) からしては、現代語訳の追加要素の存在が不思議なものではなく、むしろ翻訳における普遍的な現象である。特に明示化の普遍性は、本稿のいうノンリテラル要素の開示に関連性が強い。翻訳における明示化について、@Blum-Kulka1986Shifts では、翻訳者がソーステキストにはない Cohensive marker^[According to @Nunan1993Introducing [p. 21], cohensive markers are “words and phrases which enable the writer or speaker to establish relationship across sentence or utterance boundaries, and which help to tie the sentences in a text together”.] をターゲットテキストで示すことが示唆されている。一方で、@Baker1996Challenges [p. 180] は、この問題を物事を暗黙的なままにしておくのではなく、明確に説明する傾向があるというように、より広く捉えられるようになった。「明示化」は、もともとは談話標識の訳文における増加傾向を指しており、本研究における要素の追加の一部の解釈としてありうる。とはいえ、すべての現象についてこの仮説で解釈されることが難しい^[実際、翻訳普遍性は、結局いずれも反例が存在するため、確率的な傾向、あるいは、普遍性とすることが妥当でであるとされてる [cf., @Pym2008Toury; @Tymoczko1998Computerized; @Chesterman2004Hypotheses; @Chesterman2010Why]。とりもなおさず、一般性といいつつ例外が認めているわけである。]。
例えば、語の解釈にあたる要素の追加が談話標識の追加ではなかったが、分析事例においてはかなりの追加要素の割合を占めている。やはり、すべての要素の追加が翻訳普遍性に帰結できない。

その他テキストの翻訳ではないが、翻訳の認知処理の研究では、例えば「リテラル翻訳仮説」(literal translation hypothesis)^[@Chesterman2011Reflections によれば、this hypothesis claims that when processing a given text chunk, translator tend to start from a literal version of the target text, and then work towards a freer version.] にも触れておくべきである。この仮説に基づき、認知処理と認知負荷の観点からのリテラル翻訳の可能性の度合い (translation literality) の操作化 [@@Carl2017Measuring] が 1. the word-order similarity of the source and the target text and 2. the number of possible different translation renderings のように考えている。いずれも、テキストとしての追加率、不一致率と異なった視点になっている。その中の 2 点目が筆者らのノンリテラル要素の可視化に関連する可能性があり、検討すべき metics である。

また、翻訳研究からの検討について、単位の一致の問題について、従来 translation equivalence [e.g., @Nida1969Theory] や translation unit [@Koller1979Einfuehrung, @Malmkjaer1998Unit] に関する議論が多かった。それらの視座から分析単位の影響を考察しなければならず、検討の余地は大いにある。

This paper does not primarily position itself within translation studies, but phenomena such as the addition of elements in translation or the omission of elements from the original text can be interpreted through various hypotheses and theories in the field.

For example, the translation universal hypothesis (cf. @Chesterman2004Hypotheses; @Edina2016Translation) introduces concepts like the law of lengthening (cf. @Vinay1958Comparative) and the law of explicitation (cf. @Baker1996Challenges; @Blum-Kulka1986Shifts), which help explain why additional elements appear in contemporary translations. These phenomena are seen as universal within translation. The law of explicitation, in particular, is highly relevant to the non-literal elements discussed in this paper. @Blum-Kulka1986Shifts suggests that translators often introduce cohesive markers absent from the source text when translating into the target text^[According to @Nunan1993Introducing [p. 21], cohesive markers are “words and phrases which enable the writer or speaker to establish relationships across sentence or utterance boundaries, and which help to tie the sentences in a text together.”]. Meanwhile, @Baker1996Challenges [p. 180] expanded the definition of explicitation, describing it as a broader tendency to explain things explicitly, rather than leaving them implicit. Originally, explicitation referred to an increase in discourse markers in translations, and this concept can help interpret some of the added elements discussed in this paper. However, not all phenomena fit into this hypothesis^[Translation universals tend to allow for exceptions, making them more probabilistic tendencies rather than strict universals [cf. @Pym2008Toury; @Tymoczko1998Computerized; @Chesterman2004Hypotheses; @Chesterman2010Why]. While they claim universality, exceptions are recognized.].

For example, while not all added elements involve discourse markers, they still account for a significant proportion of the additional elements observed in the analyzed cases. Thus, not all added elements can be attributed solely to translation universals.

In addition to this, research focusing on the cognitive aspects of translation, such as the literal translation hypothesis^[According to @Chesterman2011Reflections, this hypothesis claims that when processing a given text chunk, translators tend to start with a literal version of the target text, then work towards a freer version.], offers additional insights. This hypothesis suggests that translation literality can be operationalized through 1) word-order similarity between the source and target texts, and 2) the number of potential translation renderings available for a given text [cf. @Carl2017Measuring]. These factors provide a different perspective from the addition and unmatch rates discussed in this paper. The second point, in particular, may provide useful metrics for visualizing non-literal elements and is worth further exploration.

Moreover, translation studies have long discussed the issue of analytical units, focusing on translation equivalence [e.g., @Nida1969Theory] and translation units [cf. @Koller1979Einfuehrung; @Malmkjaer1998Unit]. The impact of these analytical units requires careful consideration and offers significant possibilities for further investigation.

## 方法論の改善余地 Room for Methodological Improvement

本稿のように、完全にルールベースドによる一致率の計算であり、対応づけの一貫性の簡素さの面では優れると考えられる一方で、整列法に関しては動的計画法によるアライメントには課題を残している。古語と現代語では、片方が低リソース言語ではあるが、ニューラルベースドな手法でのアライメントや、マニュアルによるアライメントも視野に入れるべきである。例えば、@Palladino2022Using, @Camilleri2024Evaluating のように、@Palladino2022Using で提案された Ugarti プラットフォーム を介したアライメントで、一対多の対応の分析、訳し方の積集合と分岐パターン、非対応の品詞情報の分析など、より精緻なコントロールが期待される。

While this paper’s rule-based approach to calculating the agreement rate offers advantages in simplicity and consistency, challenges remain, particularly in alignment using dynamic programming methods. Although historical Japanese from certain periods qualifies as a low-resource language, it would be valuable to explore neural-based alignment methods alongside manual alignment. For instance, as suggested by @Palladino2022Using and @Camilleri2024Evaluating, the Ugarti platform introduced by @Palladino2022Using offers greater precision. This platform enables detailed analysis of one-to-many and many-to-many correspondence patterns in translations, as well as part-of-speech analysis for non-aligned elements.

## As an application using the WLSP semantic category

本稿における（不）一致率・追加率の計算では、言語処理のアライメントモデルではなく安定的な分類番号を用いた。とくにバッグ法は、句や語の入れ替えに関係せず、意味の一致を検出できる。意味の分類体系が、同一の意味の語を階層的に対応づけることの有用性が古語研究で再確認できた。本研究では、まだ旧分類語彙表番号を用いているが、現在 @Asahara2022CHJWLSP によって古語への分類語彙番号が付与されていることによって広げられる研究の可能性が十分期待できるであろう。ただし、分類語彙表番号は、2024年現時点において概念レベルまでであって、類義語、同義語、同語異表記のメタコードとして一致の検出への対応が研究者各自で目標にそった追加的付与が求められている。本稿で採用している意味付与もまた、その修正を重ねていく必要がある。この点において、意味体系の作り方に関して検討する余地があると考えている。

In this paper, the calculation of the unmatch and addition rates did not rely on an alignment model from natual language processing but instead used a stable semantic classification metacode system, WLSP. The bag method, in particular, can detect semantic agreements without being influenced by word order changes. The utility of a hierarchical classification system that groups words with the same meaning was reaffirmed in the study of old Japanese. While this study still employs the old-version WLSP codes, the potential for expanded research is promising with the assignment of classification codes to classical Japanese by @Asahara2022CHJWLSP in the Corpus of Historical Japanese. However, as of 2024, the WLSP codes are assigned only at the group level, meaning the CHJ-WLSP cannot currently be used as direct token identifiers. Researchers will need to apply additional tagging to detect semantic agreement, including identifiers for synonyms, homonyms, and orthographic variants, depending on their research goals. The WLSP codes used in this paper will also require ongoing refinement. There remains significant potential to further explore how to build a more effective semantic category code system.

## 翻訳一般性仮説の観点から見る現代語訳の操作

翻訳における言い換え、追加、省略について、翻訳研究の観点からしばしば、翻訳一般性（普遍性）の仮説で解釈されている。@Chesterman2004Hypotheses と @Edina2016Translation に基づいて、翻訳において潜在的にかかわりうる翻訳一般性を以下に整理している：

- 単純化 (cf. law of simplication)：ソース言語の言語面、あるいは、情報面の翻訳における単純化 [@Baker1996Challenges]
- 標準化・慣習化 (cf. law of standardization / conventionalization)^[その逆として、ソース干渉の定理 (law of interference) が提起されている。それは、翻訳において外国語・外国文化を翻訳において伝わるようにする傾向を指す [@Tully2014Translation, p. 295]。]
  - ソース言語の外国的特徴 (foreign feature) をターゲット言語のの文化へと修正し [@Tully2014Translation, p. 295]、
  - 翻訳のプロセスにおいてターゲット言語における典型的なパターンを踏襲し、ないしはそれを強調する [@Baker1993Corpus，p. 176]
  - ソーステキストのテーマがターゲットテキストのレパートリーに変換される傾向がある [@Toury1995Descriptive, p. 268] 
- 長さ増加の定理 (law of lenghtening)：ターゲットテキストのがソーステキストより長い傾向 [@Vinay1958Comparative]
- 明示化の定理 (law of expicitation)：@Blum-Kulka1986Shifts では、翻訳者がソーステキストにはない Cohensive marker^[According to @Nunan1993Introducing [p. 21], cohensive markers are “words and phrases which enable the writer or speaker to establish relationship across sentence or utterance boundaries, and which help to tie the sentences in a text together”.] をターゲットテキストで示すことが示唆されている。@Baker1996Challenges [p. 180] は、この問題を「翻訳では『物事を暗黙的なままにしておくのではなく、明確に説明する』傾向がある」とより広く捉えられるようになった。ただし、ここで明示化とは、翻訳文や書き下し文で使用される品詞（接続詞、副詞、関係代名詞の使用など）の追加で原文の情報を明示化することを指す [@Jia2022Myth; @Puurtinen2004Corpusbased; @Palumbo2009Key]。^[明示化の反対に、暗示化 (law of implicitation) もあり、暗示化とは、暗示のプロセスは「原文では明確に明示されている情報を暗示的にする」ことである [@Bednar2015Social, p: 3]。]
- 重複削減の定理 (reduction of repetition)：翻訳において、原文に存在する重複が減少する [@Baker1993Corpus]

本稿では、現代語訳の追加要素の存在について、長さ増加の普遍性、明示化の普遍性からしては、それが不思議なものではなく、むしろ翻訳における普遍的な現象である。
ただし、追加要素が、最終的に本稿の最終目的である歌ことばのノンリテラル的情報の可視化につながっていくかいなかについて、単純な問題ではない。

- 明示化のルールは、語の説明的補足よりも、翻訳研究ではわかりやすくするための文法的・機能的要素の追加が注目されている。つまり、個々の歌ことばの明示化のための要素ではなく、文の意味の明示化のための要素が主眼になっている。歌ことばのノンリテラル要素の可視化においては、文法的機能的な要素が古今和歌集の翻訳の多くを占めることは望ましくないとしている。
- 実際、明示化に見えたことは、通時的な変化や、文化的なギャップである可能性もあり [@Mauranen2008Universal p. 39; @Yamamoto2019Analysis, p. 68]  、ノンリテラル要素の可視化においては、文化的ギャップを埋める明示化のほうが望ましい。
- 文体的に明瞭な表現にする、いわゆる言語の様式（言い換え）の平易化を介した明示化と、翻訳の操作でノンリテラル的な要素の提示による明示化の区別も重要である。後者は情報の詳細化につながるため、本稿においては後者が望ましい。

ケーススタディの例では、文法的・機能的要素、様式の平易化、通時的変化でない、語の明示化の要素とみられるものも多く観測されていたため、一応、ノンリテラル要素の抽出として価値があると考えている。

一方で、翻訳における省略の現象に関連する普遍性については、単純化と、暗示化と、重複の削除^[重複の削除は、前節で説明した現象を包括しているため、前節を参照されたい。] があると思われる。
単純化というのは、

1. 翻訳において表現が欠落するか、
2. 情報が欠落するか、または
3. 語彙の豊富さ・密度が減るか、

といった 3 つの側面がある。本稿の目的とかかかるのは、表現の欠落と情報の欠落である。表現が欠落することは、必ずしも情報の欠落を意味しているというわけではないが、語の追加もまた情報の追加を意味しない。この点については、暗示化と関連している。暗示化は、つまり、情報をターゲットテキストの語彙的要素・文法的要素に隠すことであり、情報量を削らない。本稿の議論では、現代語訳と原文の情報量が同等であることを前提にしていることに注意されたい。^[古語の意味は、筆者らが不可知・不可視であると捉える立場に立ち、訳者ができれば情報の欠落なく訳していると仮定している。]
この場合、表現の追加・省略は、訳者が強調したい情報が明らかにし、重要でないと思われている情報が背景にする、いわゆる注意力の配分の問題であると考えられる。追加要素の分析の価値が見出される。ただし、本稿の前提が強めの仮説であることを認めざるをえない、欠落の情報があり暗示化することも確認されていることは、つまり可視化において背景化された情報が不可視のままを意味している。翻訳に基づくノンリテラル可視化の課題のひとつと考えられる。

翻訳の標準化・慣習化の普遍性も古今和歌集の現代語訳において、追加と省略、とりわけ言い換え操作の解釈として考えられる。したし、「古今和歌集の注釈書における現代日本語訳」というのは、極めて特殊な例であると考えられる。同言語内の通時的変種間の翻訳であるため、いわゆる外国的な性質の保留はつまり古風的に訳すことになり、しかし、注釈書にある翻訳であるため文学的に訳す必要がない。標準化・慣習化はこのケースでは、どのような現象につながるかは不明であり、翻訳の操作の内実について検討する余地がある。

このように、現代語訳における追加と省略は、一部は翻訳普遍性仮説で説明することができた。すべての現象についてこの仮説で解釈されることが難しい^[実際、その普遍性は、これらの一般性定理は、結局いずれも反例が存在するため、確率的な傾向、あるいは、普遍性とすることが妥当でであるとされてる [cf., @Pym2008Toury; @Tymoczko1998Computerized; @Chesterman2004Hypotheses; @Chesterman2010Why]。とりもなおさず、一般性といいつつ例外が認めているわけである。
] が翻訳を用いて語の非字義的な要素の可視化を目指す本稿では、翻訳普遍性の仮説から価値と課題と両方がみられた。

<!-- 仮説への批判: -->
<!-- 贝克对翻译英语语料库的研究（TEC，Laviosa，1997，1998）局限于英语作为目标语言或源语言，而忽视了作者、体裁和源语言的起源（Martin，2017；Tsai，2020）。 -->
<!-- Pym (2010，第 78 页) 认为，普遍性要求某种语言现象只出现在翻译文本中，而在其他文本中不出现。他认为，这些语言普遍性应该属于翻译文本特征的分类之一。另一方面，实证研究结果（例如Puurtinen，2004 年；Saldanha，2004 年；Becher，2011 年）指出，并非所有翻译都存在此类固有特征，因此研究人员不得不认为，所揭示的现象不可能与所有类型的文本及其翻译背景相关（Tymoczko，1998 年）。 -->
<!-- Tymoczko (1998)等人指出了相关的缺陷。每当需要生成或检验关于普遍性的假设时，就会建立翻译语料库。然而，对于什么应该或不应该算作翻译以纳入该语料库，却并不清楚。例如，我们需要回答一些棘手的问题来决定这一重大步骤，包括询问如果翻译是由目标语言的母语人士完成的并且是最近出版的，是否应该纳入。问题可能还涉及它们是否可以归类为好或坏，或者它们是否由受过训练的专业人士、业余爱好者、团体、粉丝或个人完成，并包含改编或版本。在构建这样的语料库时，需要明确在何处划清纳入项目的界限。 -->

# 結論 Conclusion {#sec-conclusions}

本論文では、古今集の現代語訳から原文のノンリテラル要素の可視化の材料として有用である根拠を示すために、古今集の現代語訳 10 種類における追加要素の分析を行った。

具体的に、古今和歌集の現代語訳の概要について説明し、20 世紀における和歌の現代語訳の翻訳アプローチを、注釈書における訳者の記している内容に基づた整理を行った。訳者の翻訳の意識は、コミュニケーションモデルの視点から、歌人の作意 (source) を重視する、テキストの文字通りの意味 (signal) を重視する、読者 (destination) を重視する、と明確でないもの 4 種類に分類できた。

それらの主観的な翻訳意識・翻訳アプローチが訳における追加と一致の客観的に指標に反映されているかいついて、 @Yamamoto2019Analysis で行った追加率の計算手順を明示的にし、より明確な設定と更新データを用いた再計算を行った。古語と現代語訳の語レベルの非一致率、現代語訳における追加率の計算と統計モデリングにより、翻訳アプローチにかかわらず現代語訳における情報の追加が普遍的であり、訳者間の追加率の変動が歌間の追加率の変動より小さいことを示した。

追加要素が十分ノンリテラル要素として成立するかを検討するために、298 番「タツタ」歌の現代語訳の事例を 10 つ同時にアライメントとして提示し、対象語のコーパスレベルの共出現語、共出現構文パターン、共出現語の意味志向がセンテンスレベルの現代語訳でどのように処理されているかを調査した。その結果、コーパスレベルの共出現傾向をもつ単位の場合、センテンスレベルでの処理が 10 人の間で安定的な処理が見られた。コーパスレベルで共出現傾向にない要素の追加がよりバリエーションを示している。とりわけ注意すべき現象は、コーパスレベルの共出現語が訳の推論に用いられることと、コーパスレベルの共出現語の意味志向に関連する語が訳においてより多く補足的説明をもつことであった。一方で、構文面の追加は、言語変化のギャップを埋めるためのものであった。

以上により、和歌の現代語訳が、たとえ直訳・逐語訳に拘っているとしても、和歌辞典とは異なる解釈材料として、和歌のノンリテラル情報を補足説明するために利用できることを示した。同時に、言語変化のギャップを埋めるための要素の除外や、翻訳における信頼性の高い要素の取り立て方の工夫の重要性を示唆している。

In this paper, we analyzed the additional elements in 10 different contemporary translations of the *Kokinshū* to demonstrate their usefulness in visualizing the non-literal elements of the original text.

We specifically outlined the background of contemporary translations of the *Kokinshū* and categorized the various translation approaches of the 20th century based on commentary provided by the translators. These approaches can be grouped into four categories from a communication model perspective: emphasis on the poet’s intent (source), emphasis on the literal meaning of the text (signal), emphasis on the reader (destination), and approaches that were not clearly defined.

To determine whether these subjective awarenesses of translation approaches were reflected in the objective measures of additions and agreement, we recalculated the addition rates using a clearer methodology and updated data, following the procedure established in @Yamamoto2019Analysis. Statistical modeling of the unmatch rates between the original poems and the contemporary translations, along with the addition rates, revealed that information was universally added regardless of the translation approach, and that variations in addition rates between translators were smaller than variations between individual poems.

To assess whether the added elements qualify as non-literal elements, we aligned the contemporary translations of Poem #298 "Tatsuta" across 10 translations and examined how co-occurring words at the corpus level, co-occurring grammatical patterns, and the semantic preferences of these words were handled in the sentence-level translations. The results showed that for units with a strong co-occurrence tendency at the corpus level, sentence-level processing was relatively consistent across the 10 translators. In contrast, elements that did not exhibit a co-occurrence tendency at the corpus level showed greater variation in the additional elements. Notable findings included the use of co-occurring words at the corpus level to inform inference in translation, as well as the tendency to provide supplementary explanations for words related to the semantic preferences of co-occurring words. Meanwhile, additions related to grammatical patterns were primarily used to bridge gaps caused by linguistic changes.

This study demonstrates that even contemporary translations of classical Japanese poetry, which may adhere strictly to literal or word-for-word translation, can serve as valuable interpretive tools, distinct from dictionaries, to supplement non-literal information embedded in poetic language. It also highlights the importance of excluding elements added to address linguistic gaps and emphasizes the need to carefully select reliable elements in translation for further study.

# 附録 Appendix {.appendix .unnumbered}

## 追加率のモデル Statistcal model for addition rate {.appendix .unnumbered}

$$
\begin{aligned}
&\text{[Likelihood]} \\
\text{Addition Rate}_i &\sim \operatorname{Beta}(\mu_i \phi_i, (1 - \mu_i) \phi_i) \\
\ \\
&\text{[} \mu \text{ part of beta distribution]} \\
\mu_i &= \operatorname{logit}^{-1}(\eta_i) = \frac{1}{1 + e^{-\eta_i}} \\
\eta_i &=  \alpha_{\text{translator}[i]} + \gamma_{\text{poem}[i]} + \beta_{\text{translation focus}[i]} \\
\ \\
&\text{[} \phi \text{ part of beta distribution]} \\
\log(\phi_i) &= \gamma^{\phi}_{\text{poem}[i]} \\
\ \\
& \text{[Group-specific intercepts]} \\
\alpha_{j} &\sim \mathcal{N}(\mu_{\alpha_j}, \sigma_{\text{translator}}), \text{ for } j \text{ in translator} 1, 2, \dots, 10 \\
\gamma_{j} &\sim \mathcal{N}(0, \sigma_{\text{poem}}), \text{ for } j \text{ in poem} 1, 2, \dots, 1000 \\
\gamma^{\phi}_{j} &\sim \mathcal{N}(\mu_{\gamma^{\phi}_{j}}, \sigma^{\phi}_{\text{poem}}), \text{ for } j \text{ in poem} 1, 2, \dots, 1000 \\
\ \\
& \text{[Prior for fixed coefficients]} \\
\beta_{j} &\sim \text{Student-t}(3, 0, 2.5), \text{ for } j \text{ in translation focus} 1, 2, 3, 4\\
\ \\
& \text{[Prior for population-level intercepts]} \\
\mu_{\alpha_{j}}, \mu_{\gamma^{\phi}_{j}} &\sim \text{Student-t}(3, 0, 2.5) \\
\ \\
& \text{[Prior for hyperparameter]} \\
\sigma_{\text{translator}}, \sigma_{\text{poem}}, \sigma^{\phi}_{\text{poem}} &\sim \text{Student-t}(3, 0, 2.5)
\end{aligned}
$$

ここ^[
モデルの書き方として Centered Parameterization にしているが、`brms` での実装が `Non-Centered Parameterization` になっている点に注意されたい。]では：

- $\text{Addition Rate}_i$ は追加率であり、ベータ分布に従うと仮定する。
- $\mu_i \phi_i, (1 - \mu_i) \phi_i$ はそれぞれベータ分布のシェープパラメータに相当する。
- $\mu_i$ はベータ分布の平均値パラメータであり、線形予測子 $\eta_i$ をロジスティック変換することで得られる。
- $\beta_{\text{traslation focus}[i]}, \text{traslation focus}=1,2,3,4$ は4つの翻訳アプローチの固定効果項であり、翻訳アプローチの種類ごとに異なる効果をモデル化する。
- $\alpha_{\text{traslator}[i]}, translator=1,2,\dots,10$ は訳者のランダム効果項（ランダム切片）であり、 
- $\gamma_{\text{poem}[i]}, \text{poem}=1,2,\dots,1000$ は詩（PoemID）のランダム効果項（ランダム切片）である。
- $\phi_i$ はベータ分布の精度パラメータであり、詩（PoemID）のランダム効果項 $\gamma^{\phi}_{\text{poem}[i]}$ でモデル化する。
- $\mu_{\alpha_j}$, $\mu_{\gamma^{\phi}_{j}}$ はそれぞれ $\mu$ パートと $\phi$ パートの population-level の切片である。

事前分布の設定について、基本的に`brms`のデフォルト設定に従う：
- 切片 $\mu_{\alpha_j}$, $\mu_{\gamma^{\phi}_{j}}$ と翻訳アプローチごとの固定効果 $\beta_{\text{traslation focus}}$ のは Student-t 分布の事前分布に従うと仮定する（`brms` のデフォルト事前分布）。
- $\sigma_{\text{translator}}$, $\sigma_{\text{poem}}$, $\sigma^{\phi}_{\text{poem}}$ はそれぞれ、訳者および詩歌、精度パラメータに対するランダム効果項の標準偏差であり、Student-t 分布に従うと仮定する（`brms` のデフォルト事前分布）。

デフォルト設定が次表を参照する：

Here^[Note that while the model is written in Centered Parameterization, its implementation in `brms` uses Non-Centered Parameterization.]:

- $\text{Addition Rate}_i$ refers to the addition rate and is assumed to follow a beta distribution.
- $\mu_i \phi_i$ and $(1 - \mu_i) \phi_i$ correspond to the shape parameters of the beta distribution.
- $\mu_i$ is the mean parameter of the beta distribution, obtained by applying a logistic transformation to the linear predictor $\eta_i$.
- $\beta_{\text{translation focus}[i]}$, where $\text{translation focus} = 1, 2, 3, 4$, represents the fixed effect for the four translation approaches, modeling a distinct effect for each translation approach.
- $\alpha_{\text{translator}[i]}$, where $\text{translator} = 1, 2, \dots, 10$, represents the random effect term (random intercept) for the translators.
- $\gamma_{\text{poem}[i]}$, where $\text{poem} = 1, 2, \dots, 1000$, represents the random effect term (random intercept) for the poems (PoemID).
- $\phi_i$ is the precision parameter of the beta distribution and is modeled by the random effect term $\gamma^{\phi}_{\text{poem}[i]}$ for the poems (PoemID).
- $\mu_{\alpha_j}$ and $\mu_{\gamma^{\phi}_{j}}$ are the population-level intercepts for the $\mu$ part and the $\phi$ part, respectively.

Regarding the prior distributions, we generally follow the default settings in `brms`:
- The intercepts $\mu_{\alpha_j}$, $\mu_{\gamma^{\phi}_{j}}$, and the fixed effects $\beta_{\text{translation focus}}$ for each translation approach are assumed to follow Student-t prior distributions (the default prior distribution in `brms`).
- $\sigma_{\text{translator}}$, $\sigma_{\text{poem}}$, and $\sigma^{\phi}_{\text{poem}}$ represent the standard deviations of the random effect terms for the translators, poems, and precision parameters, respectively, and are assumed to follow Student-t distributions (the default prior distribution in `brms`).

Refer to the following table for the default priors:

```{R}
#| label: tbl-model-configs
#| tbl-scap: デフォルト事前分布
#| warining: false

formula |> get_prior(
  formula, data=data, family = Beta(),
  prior= prior
  ) |> 
  kable()
```

モデルの詳細：

```{R}
#| label: model-info

model |> summary()
```

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- &\text{[Likelihood]} \\ -->
<!-- \text{Addition Rate}_i &\sim \operatorname{Beta}(\mu_i \phi_i, (1 - \mu_i) \phi_i) \\ -->
<!-- \ \\ -->
<!-- &\text{[} \mu \text{ part of beta distribution]} \\ -->
<!-- \mu_i &= \operatorname{logit}^{-1}(\eta_i) = \frac{1}{1 + e^{-\eta_i}} \\ -->
<!-- \eta_i &= + u_{\text{translator}_i} + u_{\text{poem}_i} + \text{\textbf{Translation focus}}_i \boldsymbol{\beta} \\ -->
<!-- \text{\textbf{Translation focus}} &= (\text{Text-focused}\; \text{Translator-focused}\; \text{Reader-focused}\; \text{Others}) \\ -->
<!-- \boldsymbol{\beta} &= (\beta_{0}\; \beta_{1}\; \beta_{2}\; \beta_{3})^{\intercal} \\ -->
<!-- \ \\ -->
<!-- &\text{[} \phi \text{ part of beta distribution]} \\ -->
<!-- \log(\phi_i) &= u_{\phi_{\text{poem}_i}} \\ -->
<!-- \ \\ -->
<!-- & \text{[Translator- and Poem-specific random intercepts]} \\ -->
<!-- u_{\text{translator}_i} &\sim \mathcal{N}(\mu_{\text{translator}}, \sigma_{\text{translator}}^2) \\ -->
<!-- u_{\text{poem}_i} &\sim \mathcal{N}(\mu_{\text{poem}}, \sigma_{\text{poem}}^2) \\ -->
<!-- u_{\phi_{\text{poem}_i}} &\sim \mathcal{N}(\mu_{\phi_{\text{poem}}}, \sigma_{\phi_{\text{poem}}}^2) \\ -->
<!-- \ \\ -->
<!-- &\text{[Priors]} \\ -->
<!-- \beta_{0} &\sim \text{Student-t}(3, 0, 2.5) \\ -->
<!-- \beta_{1}, \beta_{2},\beta_{3} &\sim \operatorname{Uniform}(0, 1) \\ -->
<!-- \sigma_{\text{translator}}, \sigma_{\text{poem}}, \sigma_{\phi_{\text{poem}}} &\sim \text{Student-t}(3, 0, 2.5) -->
<!-- \end{aligned} -->
<!-- $$ -->


<!-- - $\text{Addition Rate}_i$ は追加率であり、ベータ分布に従うと仮定する。 -->
<!-- - $\mu_i \phi_i, (1 - \mu_i) \phi_i$ はそれぞれベータ分布の形状パラメータに相当する。 -->
<!-- - $\mu_i$ はベータ分布の平均値パラメータであり、線形予測子 $\eta_i$ をロジスティック変換することで得られる。線形予測子 $\eta_i$ において、 -->
<!--   - $\boldsymbol{\beta}$ は翻訳アプローチの固定効果項である。 $\beta_{1},\beta_{2},\beta_{3},\beta_{4}$ で構成される。 -->
<!--   - $u_{\text{translator}_i}$ は訳者のランダム効果項（ランダム切片）であり、 $u_{\text{poem}_i}$ はランダム効果項（ランダム切片）である。 -->
<!-- - $\phi_i$ はベータ分布の精度パラメータであり、詩 (PoemID) のランダム効果項 $u_{\phi_{\text{poem}_i}}$ で予測される。 -->
<!-- - 固定効果項 $\boldsymbol{\beta}$ の各要素は Student-t 分布の事前分布を用いる（`brms`のデフォルト事前分布）。 -->
<!-- - $\sigma_{\text{translator}}$, $\sigma_{\text{poem}}$, $\sigma_{\phi_{\text{poem}}}$ はそれぞれ、訳者および詩歌、精度パラメータに対するランダム効果項の標準偏差であり、Student-t 分布に従うと仮定される（`brms`のデフォルト事前分布）。 -->


<!-- $$\text{AdditionRate}_i \sim \text{Beta}(\mu_i \cdot \phi_i, (1 - \mu_i) \cdot \phi_i)$$ -->
<!-- $$\mu_i = \text{logit}^{-1}(\eta_i) = \frac{1}{1 + e^{-\eta_i}}$$ -->
<!-- $$\eta_i = \beta_0 + \beta_{\text{focus}} \cdot \text{focus}_i + u_{\text{translator}_i} + u_{\text{poem}_i}$$ -->
<!-- $$\phi_i = \phi_0 + u_{\phi_{\text{poem}_i}}$$ -->
<!-- $$\beta_0, \beta_{\text{focus}}, \phi_0 \sim \text{Student-t}(3, 0, 2.5)$$ -->
<!-- $$u_{\text{translator}_i} \sim \mathcal{N}(0, \sigma_{\text{translator}}^2)$$ -->
<!-- $$u_{\text{poem}_i} \sim \mathcal{N}(0, \sigma_{\text{poem}}^2)$$ -->
<!-- $$u_{\phi_{\text{poem}_i}} \sim \mathcal{N}(0, \sigma_{\phi_{\text{poem}}}^2)$$ -->
<!-- $$\sigma_{\text{translator}}, \sigma_{\text{poem}}, \sigma_{\phi_{\text{poem}}} \sim \text{Student-t}(3, 0, 2.5)$$ -->

<!-- ここで: -->

<!-- - $\text{Addition Rate}_i$ は追加率であり、ベータ分布に従う。 -->
<!-- - $\mu_i$ はベータ分布の平均値であり、線形予測子 $\eta_i$ をロジスティック変換することで得られる。 -->
<!-- - $\phi_i$ はベータ分布の精度パラメータであり、詩歌 ($\text{PoemID}$) ごとに異なるランダム効果 $u_{\phi_{\text{poem}_i}}$ を持つと仮定される。 -->
<!-- - $\mu_i \cdot \phi_i, (1 - \mu_i) \cdot \phi_i$ はそれぞれベータ分布の形状パラメータに相当する。 -->
<!-- - $\eta_i$ は線形予測子であり、翻訳アプローチの固定効果 ($\beta_{\text{focus}}$)、訳者のランダム効果 ($u_{\text{translator}_i}$)、および詩歌のランダム効果 ($u_{\text{poem}_i}$) を含む。 -->
<!-- - $\phi_i$ は詩歌レベルでのランダム効果を持つ精度パラメータであり，$\phi_0$ という切片と詩歌のランダム効果の和として表現される。 -->
<!-- - $\beta_0$ は切片であり、追加率の平均を示す。 -->
<!-- - $\beta_{\text{focus}}$ は翻訳アプローチの回帰係数であり、翻訳アプローチが追加率に与える固定効果を評価する。 -->
<!-- - $\phi_0$ は精度パラメータ $\phi_i$ の切片であり、Student-t 分布に従うと仮定される。 -->
<!-- - $u_{\text{translator}_i}$ は訳者のランダム効果であり、訳者間の変動を制御する。これは正規分布に従うと仮定される。 -->
<!-- - $u_{\text{poem}_i}$ は詩歌のランダム効果であり、詩歌間の変動を制御する。これは正規分布に従うと仮定される。 -->
<!-- - $u_{\phi_{\text{poem}_i}}$ は精度パラメータ $\phi_i$ の詩歌ごとのランダム効果であり、正規分布に従うと仮定される。 -->
<!-- - $\sigma_{\text{translator}}$, $\sigma_{\text{poem}}$, $\sigma_{\phi_{\text{poem}}}$ はそれぞれ、訳者および詩歌、精度パラメータに対するランダム効果の標準偏差であり、Student-t 分布に従うと仮定される。 -->

## 「タツタ」の概要 {#sec-app-tatsuta .appendix .unnumbered}

八代集にある「たつた」は以下に示す。

```{bash}
#| label: tatsuta
#| include: false

tatsuta=$(sh ./scripts/query_poem.sh たつた)
echo "$tatsuta" > ./cache/tatsuta.txt
tatsuta_hachidai=$(echo "$tatsuta" | grep -E "^0.:000... \| ")
echo "Document frequency = "$(echo "$tatsuta_hachidai" | wc -l)
echo "$tatsuta_hachidai"
```

```{bash}
#| label: tatsuta-kokinshu

tatsuta_kokin=$(cat ./cache/tatsuta.txt | grep -E "^01:000... \| ") 
echo "Document frequency = "$(echo "$tatsuta_kokin" | wc -l)
echo "$tatsuta_kokin"
```

```{bash}
#| label: content-word-count

echo "High frequency content collocates of tatsuta:"
cat ./cache/tatsuta.txt | grep -vE "\|" | grep -vE "たつた" | awk '$4 <= 60' | awk '{ 
      suffix = ""
      if ($2 ~ /^[CE]/) { suffix = suffix "+" }
      if ($2 !~ ".0.") { suffix = suffix "*" }
      print $0 suffix
  }' | awk '{print $3 "|" $6 $10}' | sort | uniq -c | sort -nr | awk '$1 >= 5'|\
  awk '{printf "%4d. %s\n", NR, $0}'
```

```{bash}
#| label: function-word-count

echo "High frequency function collocates of tatsuta:"
cat ./cache/tatsuta.txt | grep -vE "\|" | grep -vE "たつた" | awk '$4 > 60' | awk '{ 
      suffix = ""
      if ($2 ~ /^[CE]/) { suffix = suffix "+" }
      if ($2 !~ ".0.") { suffix = suffix "*" }
      print $0 suffix
  }' | awk '{print $3 "|" $6 $10}' | sort | uniq -c | sort -nr | awk '$1 >= 5'|\
  awk '{printf "%4d. %s\n", NR, $0}'
```

```{bash}
#| label: alignment-results

sh ./scripts/pipe_examples.sh
```
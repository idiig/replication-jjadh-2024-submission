---
title: 古今和歌集の現代語訳における追加率と追加要素の分析
author:
  - name: Xudong Chen
    corresponding: false
    roles: []
    id: jc
    orcid: 0000-0002-4542-2878
    email: xchen@shs.ens.titech.ac.jp
    affiliation:
      - name: Tokyo Institute of Technology
        city: Tokyo
        country: Japan
        url: 'https://www.titech.ac.jp/english/'
        isni: 0000000121792105
        ror: 0112mx960
  - name: Bor Hodošček
    corresponding: false
    roles: []
    id: jc
    orcid: 0000-0003-2246-8774
    email: hodoscek.bor.hmt@osaka-u.ac.jp
    affiliation:
      - name: Osaka University
        city: Osaka
        country: Japan
        url: 'https://www.osaka-u.ac.jp/en'
        isni: 0000000403733971
        ror: 035t8zc32
  - name: Hilofumi Yamamoto
    corresponding: true
    roles: []
    id: jc
    orcid: 0000-0001-6876-139X
    email: yamagen@lia.titech.ac.jp
    affiliation:
      - name: Tokyo Institute of Technology
        city: Tokyo
        country: Japan
        url: 'https://www.titech.ac.jp/english/'
        isni: 0000000121792105
        ror: 0112mx960
date: 2024/09/01
abstract: | 
  筆者らは、古今和歌集の歌ことばのノンリテラル情報を可視化するシステムを開発してきたが、それに用いた現代語訳や追加要素の詳細な分析は行われていなかった。本研究の目的は、古今和歌集の現代語訳10種類が、ノンリテラル要素の可視化に適しているかどうかを分析することである。まず、現代語訳について概観し、訳者の翻訳意識を作意中心・テキスト中心・読者中心・不明の4種に分類した。次に、直訳語を持たない歌ことばの割合（不一致率）と、現代語訳における追加要素の割合（追加率）を計算し、どの訳も多くの追加要素を含むことを確認した。さらに、具体例を示し、コーパスレベルの共出現傾向に基づく推論が現代語訳にどのように反映されているかを分析した。これにより、現代語訳がノンリテラル情報の可視化に適用できることを示した。
    Previous research has developed a system for visualizing non-literal information in the Kokinshū’s poetic words by adding elements in translations found in annotation books. However, detailed analysis of these translations and the added elements has not been conducted. This study aims to evaluate whether the ten contemporary Japanese translations of the Kokinshū used in prior studies are suitable for visualizing non-literal elements. First, we review these translations and categorize the translators’ approaches as poet-focused, text-focused, reader-focused, or unclear. We then calculate the unmatch rate (the proportion of poetic words without direct equivalents) and the addition rate (the proportion of added elements) to see how elements were incorporated. Finally, we provide case analyses of specific examples, showing how corpus-level co-occurrence tendencies influenced the addition of elements to clarify meanings. Our findings show that despite varied approaches, the translations contain similar levels of added elements, suggesting that contemporary translations can effectively visualize the non-literal aspects of the Kokinshū’s original text.
# plain-language-summary: |
key-points:
  - a
  - b
citation:
  container-title: Journal of Japanese Association for Digital Humanities
  volume: 0
  issue: 0
  doi: 10.17928/jjadh.0.0_0
keywords:
  - 歌ことば
  - 現代語訳
  - ノンリテラル情報
license: CC BY
copyright:
  holder: 'Xudong Chen, Bor Hodošček, Hilofumi Yamamoto'
  year: 2024
funding: 'This work was supported by JSPS KAKENHI Grant Number JP18K00528 and JP23KJ0910, JP23K00545.'
format:
  html:
    code-links:
      - text: Data Import Code
        icon: file-code
        href: 'https://github.com/idiig/replication-test/tree/main'
    theme: default
    toc: true
    toc-title: 目次
    toc-location: right-body
    number-sections: true
    html-math-method: katex
    fig_caption: true
    cap-location: margin
    reference-location: margin
    citation-location: document
    code-fold: true
    fig-path: artifacts/figures
    fig-format: svg
    fig-width: 6
    fig-height: 3.71
  pdf:
    toc: true
    toc-title: 目次
    number-sections: true
    fig_caption: true
    fig-path: artifacts/figures
    fig-format: svg
    fig-width: 6
    fig-height: 3.71
    pdf-engine: xelatex
    citation-location: document
  docx:
    toc: true
    toc-title: 目次
    number-sections: true
    fig_caption: true
    # fig-path: artifacts/figures
    fig-format: png
    fig-width: 6
    fig-height: 3.71
    citation-location: document
execute:
  echo: false
  freeze: auto
  message: false
bibliography: references.bib
crossref:
  fig-title: Figure
  tbl-title: Table
  title-delim: ':\quad'
  fig-prefix: Figure
  tbl-prefix: Table
  sec-prefix: Section
  eq-prefix: Eq.
---

```{R}
#| label: libraries
#| message: false

library(fitdistrplus)
library(tidyverse)
library(knitr)
library(kableExtra)
library(rstatix)

library(brms)
library(tidybayes)
library(scales)
library(ggdist)
library(ggplot2)
library(ggpubr)
library(ggridges)
library(ggokabeito)

library(glossr)
```

```{R}
#| label: themes
theme_set_b <- function() {
  theme_void() +
    theme(
      strip.background = element_rect(
        color = "white", 
        fill = "white"
      ),
      panel.grid.major.y = element_line(
        color = "gray80",
        linetype = "solid"
      ),
      strip.text = element_text(
        color = "black",
        size = rel(1),
        angle = 90,
        vjust = 0.5,
        hjust = 1
      ),
      axis.text.y = element_text(
        color = "black", 
        hjust = 0
      ),
      strip.text.y.left = element_text(
        angle = 180
      ),
      axis.title.x = element_text(
        size = rel(1.3)
      ),
      axis.title.y = element_text(
        size = rel(1.3),
        angle = 90,
        vjust = 0.5
      ),
      legend.position = "bottom",
      legend.title = element_text(
        size = rel(1),
        face = "bold"
      )
    )
}
```

```{r}
#| label: output-kable-function

# Define a function to create a kable table
# Require kableExtra and knitr
create_kable_table <- function(data, cols) {
  # Check if the output format is HTML
  if (knitr::is_html_output()) {
    # Replace '\n' with '<br>' for line breaks in HTML
    cols <- gsub("\n", "<br>", cols)
    data |> kable(col.names = cols, escape = FALSE, format = "html") %>%
      kable_styling()
    
  # Check if the output format is LaTeX
  } else if (knitr::is_latex_output()) {
    # Replace '\n' with '\\' for line breaks in LaTeX
    cols <- gsub("\n", "\\\\", cols)
    data |> kable(col.names = cols, escape = FALSE, format = "latex") %>%
      kable_styling(latex_options = "hold_position")
    
  # Default case: create a regular table without line breaks
  } else {
    data |> kable(col.names = cols)
  }
}
```

# はじめに

## 目的と結論の概要

本稿の目的は、和歌の現代語訳が、直訳や逐語訳であっても、訳者の意図が異なっても、ノンリテラル要素を補足する解釈材料として利用できるかを検討することである。この目的を達成するため、原文との不一致率と訳文における追加率を計算し、さらに具体的な事例を通じて追加要素の分析を行った。

具体的には、和歌の現代語訳におけるノンリテラル要素の可視化とその応用可能性について検討した。古今和歌集の口語訳の歴史的な変遷を俯瞰し、20世紀における注釈書10種類の現代語訳に見られる翻訳アプローチを分類した。また、古語と現代語訳の語レベルの不一致率と現代語訳における追加率を計算し、翻訳アプローチにかかわらず、現代語訳にノンリテラル要素が追加されていることと、原文要素の欠落が避けられている傾向を確認した。これにより、現代語訳が直訳や逐語訳にとどまらず、原文の理解を補足する役割を果たしている可能性が示された。さらに、具体的な現代語訳の事例を提示し、対象語のコーパスレベルの共出現語、共出現語の全体的な志向性がセンテンスレベルの現代語訳それぞれに反映されているかどうかを検討した。以上の結果から、現代語訳をノンリテラル情報の可視化への応用が現実的であることを示した。

## 背景

和歌に見られるノンリテラル要素の概要を説明し、現代語訳を用いたこれらの要素の可視化に関する問題や課題について述べる。これまでの研究において素材の分析が十分に行われていなかった点を指摘し、翻訳および関連研究の紹介を通して、その意義を再確認する。

### 和歌と和歌におけるノンリテラル要素

古今和歌集仮名序に見られるように、歌人は「心に思ふもの」を自然界の物事に託して表現することが多く、直接的に明言することは稀である。和歌のことば（以下「歌ことば」）を字義通りに理解したとしても、その「心に思ふもの」には直接アクセスすることはできない。例えば、古今集の恋の歌を例にとると、

> 初雁の鳴きこそわたれ世の中の人の心の秋しうければ（古今・恋五・貫之）

この歌を字義通りに解釈すれば、各語の意味は理解できるかもしれないが、「心に思ふもの」を読み取ることは難しい^[初雁が鳴いて渡ってくるのだが、人の心の秋が来るのが悲しいので（筆者訳）]。しかし、歌ことば辞典で「秋【あき】」[@katagiri1983Uta, 3] を調べると、リテラルな意味では意図的に表現しない、あるいは客観的に表現できない情報が含まれていることに気づく。

> 秋【あき】 […]「秋」と「飽」を掛け、過ぎ去ってゆく秋と過ぎ去ってゆく愛を惜しむことが多かった。【脚注】[雁の]「鳴く」を人が「泣く」と同列にしか把握しない […][@katagiri1983Uta, 3]

@katagiri1983Uta[3] によると、恋人の心が「飽き（秋）」て、歌人が「泣（鳴）」いている「失恋」の物語と解釈することができる。このように、「秋」という表現から読み取る「飽きる恋」の情報は、原文の文脈（周辺語）ではノンリテラルであり、語の字義通りの意味だけでは受け取れない。和歌の深い意味を引き出すためには、表面的な字義を超えたノンリテラルな解釈が求められることがわかる。

### 現代語訳の追加要素に基づく歌ことばのノンリテラル要素の可視化 

筆者らはこれまで、古今和歌集の10種類の現代日本語訳を基に、歌ことばのノンリテラル要素を可視化するシステムを開発してきた [@Yamamoto2005Mathematical; @Yamamoto2006Extraction; @Chen2024Translationbased]。このシステムは、古語と現代語訳を比較し、浮かび上がる補足要素によってノンリテラル情報を可視化している。この手法は、@kondo2001Ngrama と @kondo2011Heian によって「引き算」とも呼ばれている。ただし、引き算で残る現代語訳の追加要素がどのような性質を持ち、ノンリテラル要素として扱えるかについては、より詳細な検討が必要である。
翻訳における要素の追加について、@Koller1979Einfuehrung [p. 249] は、翻訳者の「介入 (Eingriff)」であり、原作を尊重し、価値を変えない形で、読者の不足する背景知識やデノテーション・コノテーション情報、言語内的、社会文化的、間テキスト的な情報 (intertextual information) を補うことが含まれると指摘している [@Koller1979Einfuehrung, p. 249]。これにより、翻訳は注釈や辞書と同様に、ノンリテラル情報を解釈するための有効な資料となる。
しかし、翻訳の追加要素は、読者の理解力を過大評価または過小評価した結果として現れる場合もある [@Nida1964Science, p. 155; @Koller1979Einfuehrung, pp.249--250]。そのため、訳者による翻訳の追加要素のバリエーションを無視することはできない。古今和歌集の歌ことばを解釈する資料として現代語訳が有用であると @Chen2024Translationbased でも言及されているが、そのバリエーションについては十分な説明が行われていない。和歌の口語訳の背景や訳者毎の翻訳アプローチを再検討する必要がある。
本稿では、これまで使用してきた10種類の現代語訳について、その成立背景や追加要素の量的および質的な分析を行う。翻訳における追加要素が読者の理解力を反映して生成されたものである可能性を考慮し、異なる訳者が和歌のノンリテラル要素をどの程度表現できたかを検討する。訳者の翻訳アプローチを整理し、その違いを明らかにすることで、翻訳の普遍的な課題と限界を考察する。
この分析により、ノンリテラル要素の可視化システムの根拠をより明確にし、その改善の方向性を示すことができる。次節では、材料について説明を行う。

# データ：古今集、注釈と現代語訳 {#sec-materials}

本節では、材料として使用する古今集の概要を説明し、和歌、古今集、注釈書、そしてその現代語訳の歴史的背景について概観する。

## 古今集

和歌は「歌」と称されるように、もともと宮廷で声を上げて詠まれるものであり、当時の話しことばが基礎となっている。古今集は、その名が示す通り、古代の歌と当時の歌を集めたものであり、『万葉集』に収められた7世紀から8世紀の和歌も含まれている。これには、山部赤人、柿本人麻呂、額田王など、和歌史において重要な歌人の作品が仮名で記録されている。

また、古今集は、後に続く勅撰和歌集（二十一代集）の先駆けとして成立し、和歌の基本的な形式を確立した。編者である紀貫之による「仮名序」は、和歌の理論書としても位置付けられており、後の和歌文学や日本文学全般において重要な資料となっている。「源氏物語」「土佐日記」「伊勢物語」などの古典作品に多くの和歌が引用されていることからも、古今集は文学研究の基本資料としての役割を果たしている。また、話しことばの特徴を持つことから、日本語の歴史的変遷を知る上でも貴重な資料である。

## 古今集の注釈と現代日本語訳

古今集は、日本古典文学の中で多くの注釈書を生み出しており、それ自体が一つの研究分野として確立されている [@kubota1960Kokin, 319]。これらの注釈書に含まれる現代語訳は、主に読者が和歌を理解しやすくするために書かれており、翻訳家の目的は和歌の解釈を伝えることにある。ここでは、近代以前と近代以降の注釈の歴史を簡単に概観し、特に明治以降に注釈書に掲載された現代語訳について考察する。

近代（1868年）以前には、多くの古今集の注釈書が出版されており、1600年から1868年の間に70以上の注釈書が存在している [@kojima1989Kokin, 447--450]。表 @tbl-annotation に、近代以前の代表的な注釈書を5つ示す。

北村季吟の『八代集抄』は、古今集を含む8つの勅撰和歌集^[八代集とは、古今集、後撰集、拾遺集、後拾遺集、金葉集、詞花集、千載集、新古今集の8つの勅撰和歌集を指す。]を対象とした注釈書であり、108巻（50冊）にも及ぶ大著である。契沖（1640--1701）の『古今和歌集余材抄』は、初の本格的な古今集の研究書であり [@ozawa1971Kikon, p.36]、その後の注釈の基礎を築いた。賀茂真淵（1697--1767）の『古今和歌集打聴』は、契沖の研究を継承しつつも、古今集以前の歌、特に万葉集に焦点を当てている。

本居宣長の『古今和歌集遠鏡』は、すべての和歌を当時の口語に翻訳する試みであったが^[本居の意図は、古今集を注釈することではなく、和歌の価値を広く伝えることにあった。そのため、他の現代語訳と同等に扱うことはできない。@Shiozawa1993Motoori によれば、宣長の翻訳が江戸時代の口語表現をどのように反映しているかは不明であり、実際に使われていた語彙や意味の検証が必要であるため、本研究では対象外とする。]、その目的は他の注釈書とは異なっている。香川景樹（1768--1843）の『古今和歌集正義』は、従来の注釈書を強く批判し、新しい視点を提示している [@ozawa1971Kikon, p. 36; @matsuda1968Shinshaku, p. 58]。これらの注釈書は、後の注釈書に大きな影響を与え続けている。

現代においても、古今集の注釈書は重版や改訂を重ね、30以上の注釈書が存在している。

<!-- | Author                       | Year   | Annotation book title                         | -->
<!-- | Author 著者                   | Year 発行年  | Annotation book title  注釈書名       | -->
<!-- | ---------------------------- | ------ | --------------------------------------------- | -->
<!-- | Kitamura Kigin 北村季吟        | 1682   | *Hachidaishūshō* 八代集抄                   | -->
<!-- | Keichū 契沖                    | 1692   | *Kokinwakashū Yozaishō* 古今和歌集余材抄    | -->
<!-- | Kamo no Mabuchi 賀茂真淵       | 1784   | *Kokinwakashū Uchigiki* 古今和歌集打聴      | -->
<!-- | Motoori Norinaga 本居宣長       | 1793?  | *Kokinwakashū Tōkagami* 古今和歌集遠鏡     | -->
<!-- | Kagawa Kageki 香川景樹         | 1832   | *Kokinwakashū Seigi* 古今和歌集正義         | -->

<!-- 近代前（1600--1868）の古今集の代表的な注釈書 Representative annotation books of *Kokinshū* before modern times (1600--1868) -->

```{r}
#| label: tbl-annotation
#| tbl-cap: "近代前（1600--1868）の古今集の代表的な注釈書 Representative annotation books of *Kokinshū* before modern times (1600--1868)"

main.title <- "近代前（1600−1868）の古今集の代表的な注釈書"
subtitle <- expression(paste("Representative annotation books of ", italic("Kokinshū"), " before modern times (1600−1868)"))
cols <- c("著者\nAuthor", "発行年\nYear", "注釈書名\nAnnotation Book Title")

# Create the data frame without italic
data_annotation <- data.frame(
  Author = c("Kitamura Kigin 北村季吟", "Keichū 契沖", "Kamo no Mabuchi 賀茂真淵", 
             "Motoori Norinaga 本居宣長", "Kagawa Kageki 香川景樹"),
  Year = c(1682, 1692, 1784, "1793?", 1832),
  AnnotationBook = c(
    "Hachidaishūshō 八代集抄",
    "Kokinwakashū Yozaishō 古今和歌集余材抄",
    "Kokinwakashū Uchigiki 古今和歌集打聴",
    "Kokinwakashū Tōkagami 古今和歌集遠鏡",
    "Kokinwakashū Seigi 古今和歌集正義"
  )
)

# Create the text table with bilingual column names
tab <- ggtexttable(
  data_annotation, rows = NULL, 
  cols = cols,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = 0,
      x = 0,
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 0, 0), ncol = 3, nrow = nrow(data_annotation), byrow = TRUE)),
      x = as.vector(matrix(c(0, 0, 0), ncol = 3, nrow = nrow(data_annotation), byrow = TRUE)),
      ),
    )
)

# Add footnote and save the table as an SVG file
tab <- tab |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle, face = "plain", size = 11) |>
  tab_add_title(text = main.title, face = "bold", size = 16, padding = unit(0.5, "line")) |>
  tab_add_hline(at.row = 8, row.side = "bottom", linewidth = 3, linetype = 1)

# Save the table as an SVG file with a specified width of 150mm
invisible(svg("figures/table-1.svg", width = 200 / 25.4, height = 100 / 25.4))
grid::grid.draw(tab)
invisible(dev.off())

# Output
create_kable_table(data_annotation, cols)
```

## 20世紀の注釈における現代語訳とデータの概要

21世紀に入っても、現代語訳を含む多くの注釈書が出版されているが、これまでの可視化システムの研究では、近代以降に出版された古今集の現代語訳に焦点を当ててきた [@tbl-CT-data]。これらの現代語訳は本研究の対象であり、データとしても使用されている。

データフォーマットは、@Hodoscek2022Developmenta による space-delimited format に準拠しており、トークンタイプの識別子（メタコード）として旧分類語彙表番号を使用している。データセットの特徴として、多義語には複数の分類語彙表番号が付与され、複合語についてはその下位分解も同時に提供されている。これにより、様々な基準でフレキシブルな分析が可能となっている。

ただし、これらの注釈書から文字化されたデータには、和歌の現代語訳に関する著作権、校訂著作権、翻刻著作権などが含まれるため、すべてのデータを公開することはできない。

<!-- |     | Abbr. | Reference          | Manuscript  | Token count | Type count | Document count | -->
<!-- |     | Abbr. 略号 | Annotation book 注釈書  | Manuscript 底本  | Token count トークン数 | Type count タイプ数 | Document count 文書数 | -->
<!-- |-----|-------|--------------------|-------------|------------:|-----------:|---------------:| -->
<!-- | 1   | KNK   | @kaneko1933Kokin        | Teika 定家 | 42,439      | 3,356      | 1,000          | -->
<!-- | 2   | KBT   | @kubota1960Kokin          | Teika 定家 | 32,210      | 2,701      | 1,000          | -->
<!-- | 3   | MTD   | @matsuda1968Shinshaku     | Teika 定家 | 31,860      | 3,007      | 1,000          | -->
<!-- | 4   | OZW   | @ozawa1971Kikon           | Teika 定家  | 36,173      | 3,384      | 1,000          | -->
<!-- | 5   | TKOK  | @takeoka1976Kokin         | Teika 定家  | 29,844      | 2,861      | 1,000          | -->
<!-- | 6   | OKMR  | @okumura1978Kokin         | Teika 定家  | 32,321      | 3,153      | 1,000          | -->
<!-- | 7   | KSJ   | @kyusojin1979Kokin        | Teika 定家  | 34,050      | 2,770      | 1,000          | -->
<!-- | 8   | KMCY  | @komachiya1982Kokin       | Teika 定家  | 30,869      | 2,692      | 1,000          | -->
<!-- | 9   | K&A   | @kojima1989Kokin          | Teika 定家  | 33,867      | 2,955      | 1,000          | -->
<!-- | 10  | KTGR  | @katagiri1998Kokinhyoshaku| Teika 定家  | 36,362      | 2,882      | 1,000          | -->
<!-- |     | Total |                           |             | 339,995     | 8,252      | 10,000         | -->

<!-- : 古今和歌集の短歌の20世紀の現代語訳 10 種：トークン・タイプ数の集計においては、複合表現の場合、その下位分解をカウントしていない Summary of 10 modern Japanese translations of *Kokin Wakashū* from the 20th century: Token and type counts exclude decomposition of compound expressions. {#tbl-CT-data} -->

```{r}
#| label: tbl-CT-data
#| tbl-cap: "古今和歌集の20世紀の現代語訳 10 種 10 contemporary Japanese translations of *Kokin Wakashū* from the 20th century."
#| message: false

# Main title and subtitle for the table
main.title <- "古今集の 20 世紀の現代語訳 10 種"
subtitle <- expression(paste("10 contemporary Japanese translations of ", italic("Kokinshū"), " from the 20th century"))
footnote <- paste0(
  "トークン・タイプ数の集計においては、複合表現の場合、その下位分解をカウントしていない。",
  " Token and type counts exclude decomposition of compound expressions."
) |> 
 strwrap(width = 80) |> 
 paste(collapse = "\n")
cols = c(
  "略号\nAbbreviation", "注釈書\nAnnotation Book", "底本\nManuscript", 
  "トークン数\nToken Count", "タイプ数\nType Count", "文書数\nDocument Count"
  )

# Create the data frame with formatted numbers
data_summary <- data.frame(
  Abbr = c("KNK", "KBT", "MTD", "OZW", "TKOK", "OKMR", "KSJ", "KMCY", "K&A", "KTGR", "Total"),
  AnnotationBook = c(
    "金子 (1933)", "窪田 (1960)", "松田 (1968)", "小沢 (1971)", 
    "竹岡 (1976)", "奥村 (1978)", "久曽神 (1979)", "駒井 (1982)", 
    "小島・新井 (1989)", "片桐 (1998)", ""
    ),
  Manuscript = c(
    "Teika 定家", "Teika 定家", "Teika 定家", "Teika 定家", 
    "Teika 定家", "Teika 定家", "Teika 定家", "Teika 定家", 
    "Teika 定家", "Teika 定家", ""
    ),
  TokenCount = c(42439, 32210, 31860, 36173, 29844, 32321, 34050, 30869, 33867, 36362, 339995),
  TypeCount = c(3356, 2701, 3007, 3384, 2861, 3153, 2770, 2692, 2955, 2882, 8252),
  DocumentCount = c(1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10000)
)

# Create the text table with bilingual column names
tab <- data_summary |>
  mutate(
    TokenCount = formatC(TokenCount, format = "d", big.mark = ","),
    TypeCount = formatC(TypeCount, format = "d", big.mark = ","),
    DocumentCount = formatC(DocumentCount, format = "d", big.mark = ",")
    ) |>
  ggtexttable(
    rows = NULL, 
    cols = cols,
    theme = ttheme(
      base_size = 5,
      colnames.style = colnames_style(
        fill = "white",
        hjust = c(0, 0, 0, 1, 1, 1),
        x = c(.1, .1, .1, .9, .9, .9),
        ),
      tbody.style = tbody_style(
        fill = "white",
        hjust = as.vector(matrix(c(0, 0, 0, 1, 1, 1), ncol = 6, nrow = nrow(data_summary), byrow = TRUE)),
        x = as.vector(matrix(c(.1, .1, .1, .9, .9, .9), ncol = 6, nrow = nrow(data_summary), byrow = TRUE)),
        ),
      )
  )

# Add title, subtitle, and footnote, as well as horizontal lines
tab <- tab |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>  
  tab_add_title(text = subtitle, face = "plain", size = 14) |>
  tab_add_title(text = main.title, face = "bold", size = 16, padding = unit(0.5, "line")) |>
  tab_add_footnote(text = footnote, size = 6) |>
  tab_add_hline(at.row = 13, row.side = "bottom", linewidth = 3, linetype = 1)

# Save the table as an SVG file with a specified width of 200mm
invisible(svg("figures/table-2.svg", width = 200 / 25.4, height = 125 / 25.4))
grid::grid.draw(tab)
invisible(dev.off())

# Output
create_kable_table(data_summary, cols)
```

```{python}
#| label: read-raw-db

from typing import List

def poem_mode(poem: str, mode: int = 2) -> List[str]:
    """
    Function to filter and output data based on the given mode.

    Mode 1: Original output.
    Mode 2: Filter rows where the decomposition code starts with 'A' or 'B' or 'D' and the first digit of the number part is '0'.
    Mode 3: Filter rows where the decomposition code starts with 'A' or 'C' or 'E' and the first digit of the number part is '0',
            and filter out decompositions of multi-sense words (i.e., if a 'B' or 'D' row is found, skip its 'C' or 'E' blocks).

    :param poem: A string block with multiple lines of input data representing the poems.
    :param mode: Mode to determine the filtering behavior:
        - 1: Original output.
        - 2: Basic sense, ignore decomposition ('A', 'B', 'D' with '0' in decomposition code).
        - 3: Basic sense, consider decomposition ('A', 'C', 'E' with '0' in decomposition code), and filter multi-sense decompositions.
    :return: Filtered list of strings based on the mode.
    """
    if mode == 1:
        # If mode is 1, return the original poem string split by lines
        return poem.strip().splitlines()

    # Split the input string by lines and further split each line by whitespace for other modes
    data = [line.split() for line in poem.strip().splitlines()]
    result = []

    skip_decompositions = False  # Flag to skip decompositions related to 'B' or 'D' rows

    for row in data:
        decomposition_code = row[1]  # Second column represents the decomposition code
        first_char = decomposition_code[0]  # Get the first character of the decomposition code (A, B, C, D, or E)

        # Ensure the first character is one of 'A', 'B', 'C', 'D', or 'E'
        assert first_char in ['A', 'B', 'C', 'D', 'E'], f"Unexpected decomposition code: {decomposition_code}"

        # Explanation of decomposition code first_digit:
        # 0: Basic sense (primary meaning)
        # Other integers: Other senses (secondary meanings or further decompositions)
        first_digit = decomposition_code[1]  # Get the first digit of the numeric part (0 for basic sense)

        if mode == 2 and first_char in ['A', 'B', 'D'] and first_digit == '0':
            # Mode 2: Basic sense, ignore decomposition (A, B, D)
            result.append(" ".join(row))
        elif mode == 3:
            if skip_decompositions and first_char in ['C', 'E']:
                # Skip 'C' or 'E' decompositions after 'B' or 'D' multi-sense lines
                continue
            elif first_char in ['B', 'D'] and first_digit != '0':
                # If we encounter a multi-sense row (first digit != '0'), we set the flag to skip its decompositions
                skip_decompositions = True
            else:
                skip_decompositions = False  # Reset the flag if we're not in a multi-sense situation

            if first_char in ['A', 'C', 'E'] and first_digit == '0':
                # Mode 3: Basic sense, consider decomposition (A, C, E)
                result.append(" ".join(row))

    return result
  

def translation_mode(translation: str, mode: int = 2) -> List[str]:
    """
    Function to filter and output translation data based on the given mode, with an added functionality to number each token
    and remove punctuation based on the POS column (6th column).

    Mode 1: Original output.
        - Returns the translation data with numbering, as is.

    Mode 2: Ambiguity set to 1, ignore decomposition.
        - Filters rows where the first column is 1 (ambiguity set to 1) and the fourth column is 0 or 1 (decomposition ignored),
          and skips the current row if the next row's fourth column is 3.

    Mode 3: Ambiguity set to 1, consider decomposition.
        - Filters rows where the first column is 1 (ambiguity set to 1) and the fourth column is 0, 2, or 3 (decomposition considered),
          and skips the current row if the next row's fourth column is 3.

    Additionally, each token will be numbered based on the decomposition field (4th column) and punctuation will be removed
    based on the POS column (6th column):
        - If the POS column is 76 or greater, the line is considered a punctuation and will be skipped.
        - The number will be added at the end of each line.

    :param translation: A string block with multiple lines of input data, representing the translations.
    :param mode: Mode to determine the filtering behavior.
        - 1: Original output
        - 2: Ambiguity set to 1, ignore decomposition
        - 3: Ambiguity set to 1, consider decomposition
    :return: Filtered list of strings with numbered tokens based on the mode.
    """
    # First, remove punctuation and add global numbering to the tokens
    numbered_data = []
    for line in translation.strip().splitlines():
        clean_line = _remove_punctuation(line)
        if clean_line:  # Skip the line if it's a punctuation
            numbered_data.append(_add_token_numbering(clean_line))

    # If mode is 1, return the data directly without any filtering
    if mode == 1:
        return numbered_data

    # Now apply the mode filtering for mode 2 and 3
    result = []
    for i, row in enumerate(numbered_data):
        row_fields = row.split()
        ambiguity = int(row_fields[0])
        decomposition = int(row_fields[3])

        # Apply filtering based on mode
        if mode == 2 and ambiguity == 1 and decomposition in [0, 1]:
            result.append(row)  # Ambiguity set to 1, ignore decomposition
        elif mode == 3 and ambiguity == 1 and decomposition in [0, 1, 3]:
            # Check if the current row's fourth column is 1, and if the next row's fourth column is 3
            if decomposition == 1 and i + 1 < len(numbered_data) and int(numbered_data[i + 1].split()[3]) == 3:
                continue  # Skip current row if the next row's fourth column is 3
            result.append(row)  # Ambiguity set to 1, consider decomposition

    return result


def _add_token_numbering(line: str) -> str:
    """
    Internal function to add numbering to each line based on the decomposition field (4th column).

    :param line: A single line of the translation data.
    :return: The line with numbering added to the end of the line.
    """
    row = line.split()
    decomposition_field = row[3]  # The decomposition field (4th column)

    # Static variable to hold the token counter across function calls
    if not hasattr(_add_token_numbering, "token_counter"):
        _add_token_numbering.token_counter = 0

    # Check the decomposition field and update the token counter accordingly
    if decomposition_field != "0" and decomposition_field != "1":
        row.append(str(_add_token_numbering.token_counter))
    else:
        _add_token_numbering.token_counter += 1
        row.append(str(_add_token_numbering.token_counter))

    return " ".join(row)


def _remove_punctuation(line: str) -> str:
    """
    Internal function to remove lines that are considered punctuation based on the POS column (6th column).

    :param line: A single line of the translation data.
    :return: The original line if it is not punctuation, otherwise an empty string.
    """
    row = line.split()
    pos_column = int(row[4])  # POS column is the 5th column
    polysemy_colomn = row[0]  # Polysemy coloum is first column

    # POS 76 and greater are considered punctuation, so we skip them
    # When polysemy_colomn is N, the row is un validated, so we skip them
    if pos_column >= 76 or polysemy_colomn == "N":
        return ""  # Return an empty string to indicate this line is punctuation and should be skipped

    return line
```

# 方法 {#sec-methods}

現代語訳からノンリテラル要素を効率的に抽出できるかを、次の2つのステップで確認する。まず、訳者の翻訳アプローチを明らかにし、ノンリテラル情報の扱いについての記述を精査する。次に、それぞれの翻訳実践が、訳者の翻訳アプローチをどの程度反映しているかを調査する。つまり、注釈書における現代語訳の方針に関する文献調査を行い、訳者が翻訳の際にどこに重点を置いているかを分類する。次に、原文要素の不一致率と訳文における追加率を算出し、要素の追加が翻訳アプローチによる差があるかどうかを統計的に検証する。また、追加された要素がノンリテラル要素として認められるかどうか、事例分析によって検討する。具体的な方法については、次節で詳述する。

## 文献調査による翻訳アプローチの分類

本節では、20世紀の古今集注釈書における現代語訳の執筆方針について文献調査を行い、整理する。@Yamamoto2005Mathematical [p. 102] では、訳者の理論的考えを踏まえつつ、それぞれの現代語訳を実際に観察し、「逐語訳 (word-for-word)」「作者の意思の尊重 (intention-oriented)」「字句を補う (supplement for words)」「語順・語法を変える (word change)」「不詳 (not mentioned)」のように分類しているが、「作者の意思の尊重 (intention-oriented)」は翻訳の目標・フォーカスであり、その他は具体的な訳し方である、分類の視座が統一されていない。そのため、基準の統一た分類が必要である。ここでは、@Yamamoto2005Mathematical で採用された @Schramm1954Process のコミュニケーションモデルの観点から翻訳の力点の置き方の分類を行う (@fig-schramm-schema)。

現代語訳のコミュニケーションモデルは、2つのサブプロセスを含んでいる。翻訳者が、10世紀のサブプロセスの受信者でありながら、20世紀のサブプロセスの発信者である。2つのサブプロセスの経験野をコミュニケートする役割を果たしている。

このモデルの考え方に基づき、翻訳アプローチを3つに分類する：

1. 歌人本位のアプローチ (Poet-focused approach): 10世紀のサブプロセスの中のソースである歌人の作意をハイライトする。
2. 原文本位のアプローチ (Text-focused approach): 10世紀のサブプロセスにおけるシグナルであるテキストの文字通りの意味をハイライトする。
3. 読者本位のアプローチ (Reader-focused approach): 20世紀のサブプロセスの中のデスティネーションである読者の理解をハイライトする。

そのほかには、翻訳においては、訳自体のもつ読み物としての文学性、つまり20世紀の中のシグナルを重視するアプローチも想定できるが、注釈における訳であるため訳の面白さや文学性への重点的なが考えにくい。ここでは触れないようにする。

::: {#fig-schramm-schema layout-nrow=2}

![コミュニケーションモデル Communication model](figures/fig-process-comm.svg){#fig-schramm-schema-orig width=100%}

![翻訳アプローチの分類とコミュニケーションモデルにおける位置づけ Classification of Translation Approaches Based on the Communication Model](figures/fig-schema-op-ct-tikz.svg){#fig-schramm-schema-adap width=100%}

**コミュニケーションモデルから見る翻訳アプローチの分類 Classification of Translation Approaches Based on the Communication Model**

:::

## 追加率・不一致率の計算

本稿では、訳における追加率は情報の補足の量を操作するものとし、原文における不一致率は原文の情報の欠落の量を操作するものとする。ノンリテラル情報の抽出は、追加率の高く、不一致率の低い訳が望ましい。そのため、追加率を客観的に調査し、このずれを明確にする必要がある。

追加率と不一致率の計算方法として、要素の順序や重複を考慮しない集合演算（バッグ法）と、要素の順序や重複を考慮するアライメント（整列法）を用いる。手順は、@Yamamoto2005Mathematical と @Yamamoto2019Analysis でも説明されているが、詳細な手順は示されていなかったため、本稿では計算のプロセスをより明確にする。
@Yamamoto2005Mathematical と @Yamamoto2019Analysis のアプローチでは、語の複数の意味をメタコードで同時に保持し、不一致率の計算を行っている。デフォルトの分類語彙表番号、または複合語において一致語がある場合、その下位分解やその他の意味の一致可能性については考慮しない。このアプローチのメリットは、複合表現の一致を優先し、多義語のいずれかの意味が一致する可能性を計算に含めることにある。
計算において、重要な前提は、翻訳者が100%の情報を翻訳に含めようとする努力を行っていると見なすことである。そのため、現代語に形式的に一致する語がない場合でも、原文のいずれかの要素と1対1で対応していると仮定し、追加率からその分を差し引く^[これを純粋なアノテーション (pure annotation) と呼ぶ]。しかし、歌ことばに対応する語が明らかに存在しない場合、それは情報の欠落を訳者が認識していることを意味し、逐語訳の前提が理論的であることを示す。また、対応単位が変動するため、訳語の数のカウントが変わり、訳者ごとの追加率の比較が直感的でなくなることもある。
本稿では、追加率の計算手順を明確化し、結果の再現性を補足する。計算の調整は、当初の結論に影響を与えない。本稿の計算では、デフォルトの分類語彙表のメタコードと分解された最小単位を統一した上で実施する。^[計算スクリプトは、他の選択肢も提供している。]

#### 旧分類語彙表番号（旧 WLSP 番号）に基づく一致の層づけ {.unnumbered}

歌ことばと現代語訳の「一致・不一致」は、以下のように4つのレベルに層づけされる。これは、二語のメタコード（旧 WLSP 番号）の最長共通部分列 (Longest Common Subsequence, LCS) [@Sankoff1972Matching; @Traum2000Generation] の長さによって決定される。

$$
\text{match}(s,t) \in
\begin{cases}
U, & \text{if } \text{LCS}(s,t) < 10 \\
G, & \text{if } 10 \leq \text{LCS}(s,t) < 13 \\
F, & \text{if } 13 \leq \text{LCS}(s,t) < 17 \\
E, & \text{if } \text{LCS}(s,t) \geq 17 \\
\end{cases}
$$

ここで、$s$ はソーステキスト（和歌）の語のメタコード、$t$ はターゲットテキスト（現代語訳）の語のメタコードを表し、$\text{LCS}(s,t)$ は $s$ と $t$ のメタコードの最長共通部分列の長さを示す。具体的な分類例を以下に示す。

1. **Unmatch** ($\text{match}(s,t) \in U$; $\text{LCS}(s,t)=4$):
   - $s=$ `[BG-0]1-5520-20-0401` 梅 (plum)
   - $t=$ `[BG-0]8-0061-07-010-A` の (of, genitive case)
   
2. **Group match** ($\text{match}(s,t) \in G$; $\text{LCS}(s,t)=11$):
   - $s=$ `[BG-01-5520-]20-0401` 梅 (plum)
   - $t=$ `[BG-01-5520-]19-115-A` 秋萩 (autumn bush clover)

3. **Field match** ($\text{match}(s,t) \in F$; $\text{LCS}(s,t)=11$):
   - $s=$ `[BG-01-2030-01-]0300` 神 (god)
   - $t=$ `[BG-01-2030-01-]030-A` 仏 (Buddha)

4. **Exact match** ($\text{match}(s,t) \in E$; $\text{LCS}(s,t)=17$):
   - $s=$ `[BG-01-5520-20-040]1` 梅 (plum)
   - $t=$ `[BG-01-5520-20-040]-A` 梅 (plum)

```{python}
#| label: match-string

from difflib import SequenceMatcher

def LCS(s: str, t: str) -> int:
    """
    Calculate the length of the longest common subsequence (LCS) between two strings.

    This is an internal function that uses a sequence matching algorithm to determine
    the longest common subsequence between the two input strings.

    :param s: The first input string.
    :param t: The second input string.
    :return: The length of the longest common subsequence between the two strings.
    """
    seq_matcher = SequenceMatcher(None, s, t)
    match = seq_matcher.find_longest_match(0, len(s), 0, len(t))
    return match.size


def match_category(s: str, t: str) -> str:
    """
    Classify the match between two strings into one of four categories based on the LCS (Longest Common Subsequence) length.

    The function calculates the LCS length between two strings and classifies the match into one of four categories:
    - 'U': [U]nmatch, when LCS length is less than 10.
    - 'G': [G]roup match, when LCS length is between 10 and 12.
    - 'F': [F]ield match, when LCS length is between 13 and 16.
    - 'E': [E]xact match, when LCS length is 17 or greater.

    :param s: The first input string to compare.
    :param t: The second input string to compare.
    :return: A string representing the match category ('U', 'G', 'F', or 'E') based on the LCS length.
    """
    # Calculate LCS length using the internal function
    lcs_length = LCS(s, t)

    # Categorize based on the LCS length
    if lcs_length < 10:
        return "U"
    elif 10 <= lcs_length < 13:
        return "G"
    elif 13 <= lcs_length < 17:
        return "F"
    else:
        return "E"
```

#### バッグ法による不追加率の計算 {.unnumbered}

バッグ法を用いた追加率の計算は、現代語訳における和歌原文の追加要素を、順序関係を考慮せず、2つのテキストを集合と見なし、一致語の数から算出する。ソーステキスト（和歌）$S=(s_i)_{i \in \mathbb{Z}^{+}}$ とターゲットテキスト（現代語訳） $T=(t_i)_{i \in \mathbb{Z}^{+}}$ が与えられた場合、ターゲットテキストにおける追加率は以下の式で計算される。

$$
\begin{align}
\text{Addition Rate}(S,T) &= 1 - \frac{1}{|T|}\text{agreement}_{S}\\
\text{agreement}_{S}(S,T) &= \sum_{s_i \in S} \mathbb{I} \left( \exists t_j \in T \text{ such that } \text{match}(s_i, t_j) \notin U \right)
\end{align}
$$

$\text{agreement}_{S}$ は、ソーステキストにおいて一致語をもつトークンの数であり、$\frac{1}{|T|}\text{agreement}_{S}$ を一致率（バッグ法）と定義する。分母はターゲットテキストのトークン数 $|T|$ である。$s_i$, $t_j$ はそれぞれソーステキストの $i$ 番目と、ターゲットテキストの $j$ 番目のトークンを意味する。追加率は、1から一致率を引くことで計算される。$\mathbb{I}$ は指示関数（indicator function）で、条件が真（$s_i$ が訳で一致語をもつ）の場合は1を、偽（$s_i$ が訳で一致語をもたない）の場合は0を返す。^[ここでの一致率の計算は、$\mathbb{I}$ 内の条件で調整できる。今回は、メタコードが $E, F, G$ のいずれかのレベルで一致する場合を一致と定義している。]

この計算において重要なのは、ソーステキストの語について、一致語があるかどうかをソーステキストの視点から判断することである。たとえターゲットテキストで複数の語がソーステキストの一語に対応しても、それらを一語と見なし、他の語を追加要素とする。この理由は、処理の一貫性を保つためである。たとえば、「散る」を「散り乱れる」と訳した場合、どこまでを一語と見なすかは曖昧であるため、「乱れる」を追加要素として扱う。つまり、計算では一対一の対応を前提としている。^[なお、本稿のデータベースは、次の3つの基準を使った計算方法を提供している：短単位のみの計算、多義性を無視し複合単位を優先する計算、多義性の複合単位の構成要素をそのまま残す計算。今回は短単位を基準として計算を行う。]

不一致率についても同様に、ソーステキストに存在する要素のうち、ターゲットテキストで一致語が存在しない割合として計算する。この場合、分母はソーステキストのトークン数 $|S|$ となる。

$$
\begin{align}
\text{Unmatch Rate}(S,T) &= 1 - \frac{1}{|S|}\text{agreement}_{S}
\end{align}
$$

バッグ法で算出された追加率をもとに、訳者の主観的な翻訳アプローチがどの程度影響を与えているかを統計的に検証する。また、不一致率については、初歩的な記述統計を用いて確認する。

```{python}
#| label: count-match-bag

def match_count_bag(poem_lines: List[str], translation_lines: List[str]) -> dict:
    """
    Calculate the total match count between the poem and translation for Exact (E), Field (F), and Group (G) matches.

    The function compares each element in the poem with the elements in the translation.
    The match is counted with priority: Exact (E) > Field (F) > Group (G), meaning if an E match is found,
    it will not check for F or G, and similarly for F before G.

    :param poem_lines: A list of strings representing the poem data (already filtered).
    :param translation_lines: A list of strings representing the translation data (already filtered).

    :return: A dictionary containing the total match counts for 'E', 'F', and 'G' categories.

    Example Usage:
    --------------
    poem_data = [
        "01:000001:0001 A00 BG-01-1630-01-0100 02 年 年 とし 年 とし",
        "01:000001:0002 A00 BG-08-0061-07-0100 61 の の の の の"
    ]

    translation_data = [
        "1 katagiri 0001 1 51 50 07 BG-03-1940-01-010-A 早く はやい 早い 1",
        "1 katagiri 0001 2 51 50 07 BG-03-1660-03-010-A -- はやい 早い 1"
    ]

    match_counts = match_count(poem_data, translation_data)
    print(f"Match counts: {match_counts}")
    """

    # Initialize counters for E, F, G matches
    match_counts = {"E": 0, "F": 0, "G": 0}

    # Calculate total match count based on poem as the source
    for poem_line in poem_lines:
        s = poem_line.split()[2]  # BG ID string from poem
        assert len(s) == 18, f"Invalid BG ID string: {s}"

        found_match = False

        # First, search for E match
        for translation_line in translation_lines:
            t = translation_line.split()[7]  # BG ID string from translation
            assert len(t) == 19, f"Invalid BG ID string: {t}"

            if match_category(s, t) == "E":
                match_counts["E"] += 1
                found_match = True
                break  # Stop once an E match is found

        # If no E match is found, search for F match
        if not found_match:
            for translation_line in translation_lines:
                t = translation_line.split()[7]
                if match_category(s, t) == "F":
                    match_counts["F"] += 1
                    found_match = True
                    break  # Stop once an F match is found

        # If no F match is found, search for G match
        if not found_match:
            for translation_line in translation_lines:
                t = translation_line.split()[7]
                if match_category(s, t) == "G":
                    match_counts["G"] += 1
                    break  # Stop once a G match is found

    # Assert to ensure that the total matches (E + F + G) equal the number of poem lines
    total_matches = match_counts["E"] + match_counts["F"] + match_counts["G"]
    assert total_matches <= len(poem_lines), f"Total matches {total_matches} exceed the number of poem lines {len(poem_lines)}"

    return match_counts
```

#### 整列法による追加率・不一致率の計算 {.unnumbered}

整列法による計算は、まずアライメント（整列）を推定し、次に整列された2語の一致数をもとに追加率を求める方法である。集合としてではなく、シーケンスとして順序を考慮する計算方法を用いる。

本稿では、分類語彙表番号を用いた動的計画法（Dynamic Programming）に基づきアライメントを行う。動的計画法を用いて2つのシーケンス間のアライメントを計算するスコア関数は、以下のように定義される。

$$
\text{S}_{\text{DP}}(i, j) =
\begin{cases}
0 & \text{if } i = 0 \text{ or } j = 0 \\
\max
\begin{cases}
\text{S}_{\text{DP}}(i-1, j) - \text{gap} \\
\text{S}_{\text{DP}}(i-1, j-1) + \text{weight}(s_i, t_j) \\
\text{S}_{\text{DP}}(i, j-1) - \text{gap}
\end{cases} & i > 0 \text{ and } j > 0
\end{cases}
$$

このスコア関数 $\text{S}_{\text{DP}}(i,j)$ は、ソーステキストのシーケンス $S$ とターゲットテキストのシーケンス $T$ の部分列の位置 $i$ および $j$ までの最適なアライメントスコアを再帰的に計算するものである。重み付け関数 $\text{weight}(s,t)$ は、LCS の値をそのまま使用し、Unmatch の場合は $-1$ のペナルティを与える（次式参照）。

$$
\text{weight}(s,t) =
\begin{cases}
-1, & \text{if } \text{match}(s,t) \in U \\
10, & \text{if } \text{match}(s,t) \in G \\
13, & \text{if } \text{match}(s,t) \in F \\
17, & \text{if } \text{match}(s,t) \in E \\
\end{cases}
$$

ギャップ（空白）の挿入には、ペナルティ (gap penalty) として $0.01$ を設定する。^[和歌の翻訳では、語の対応が遠くなることが多いため、ギャップペナルティを $0.01$ とすることで遠くの語の対応を許容している。] この手法により、最も適したアライメントを探索する。整列後の例は以下の通りである。

```
>| 立田姫ーー手向けるーーーー神のあれ　ばこそーーーーーーー秋の木の葉の幣ーーーと散るーーーらめー [298]
>| 竜田姫は、手向けをするべき神があるのでーーそのつかさどる秋の木の葉が幣のように散るのであろうよ [KBT]
```

整列されたシーケンス $S^{\prime}$ と $T^{\prime}$ を用いて、一致率と追加率を計算する。整列法による一致率と追加率の計算式は以下の通りである。

$$
\begin{align}
\text{Addition Rate}^{\prime}(S,T) &= 1-\frac{1}{|T|}\text{agreement}^{\prime}_{S}\\
\text{Unmatch Rate}^{\prime}(S,T) &= 1-\frac{1}{|S|}\text{agreement}^{\prime}_{S}\\
\text{agreement}^{\prime}_{S}(S,T) &= \sum_{s_i \in S^{\prime}} \mathbb{I} \left(\text{match}(s_i^{\prime}, t_i^{\prime}) \notin U \right)
\end{align}
$$

ここで、prime ($\prime$) 記号がついているものは整列後のテキストを指す。指示関数 $\mathbb{I}$ は、アライメントで2語が一致する場合に1を返し、不一致の場合は0を返す。ギャップが含まれるアライメントは計算対象としない。また、一致率・不一致率・追加率の計算では、分母を整列前のソーステキストのトークン数に設定する。

動的計画法は、語順の変更や句の並び替えに対して弱いため、語順や句順が大きく異なる訳では、アライメントが適切に行えない場合がある。また、整列法は、アライメントされた2語が完全に一致するという厳しい前提があり、実際の翻訳状況とは異なることが多い。そのため、整列法で計算された追加率は、統計的な分析には用いず、個別のケーススタディで説明を行う。

```{python}
#| label: weight-function

def weight(s: str, t: str, u: int = -1, g: int = 10, f: int = 13, e: int = 17) -> int:
    """
    Calculate the weight based on the match category between two strings.

    The function first classifies the match category using the `match_category` function.
    It allows custom weight values for each match category (U, G, F, E).
    - 'U' (Unmatch) returns the weight for unmatch (default is -1).
    - 'G' (Group match) returns the weight for group match (default is 10).
    - 'F' (Field match) returns the weight for field match (default is 13).
    - 'E' (Exact match) returns the weight for exact match (default is 17).

    :param s: The first input string to compare.
    :param t: The second input string to compare.
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).
    :return: An integer weight based on the match category.
    """
    category = match_category(s, t)

    if category == "U":
        return u
    elif category == "G":
        return g
    elif category == "F":
        return f
    else:  # "E"
        return e
```

```{python}
#| label: alignment

def alignment(poem_lines: List[str], translation_lines: List[str], gap_penalty: float = 0.01, u: int = -1, g: int = 10, f: int = 13, e: int = 17) -> str:
    """
    Align the poem and translation sequences using dynamic programming and return the alignment in a formatted output.

    :param poem_lines: A list of strings representing the poem data (already filtered).
    :param translation_lines: A list of strings representing the translation data (already filtered).
    :param gap_penalty: Float representing the penalty for inserting gaps (default is 0.01).
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).

    :return: A formatted string representing the aligned sequences, including matching category and token information.
    """

    # Get the size of the poem and translation
    poem_size = len(poem_lines)
    translation_size = len(translation_lines)

    # m: number of poem lines, n: number of translation lines
    m, n = poem_size, translation_size

    # Initialize the DP (Dynamic Programming) table and traceback table
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    traceback = [[(0, 0)] * (n + 1) for _ in range(m + 1)]

    # Fill DP table with gap penalties for alignment
    for i in range(1, m + 1):
        dp[i][0] = dp[i - 1][0] + gap_penalty  # Penalty for gaps in translation
        traceback[i][0] = (i - 1, 0)  # Record traceback
    for j in range(1, n + 1):
        dp[0][j] = dp[0][j - 1] + gap_penalty  # Penalty for gaps in poem
        traceback[0][j] = (0, j - 1)  # Record traceback

    # Fill the DP table with alignment scores based on the weight function
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            match_weight = dp[i - 1][j - 1] + weight(poem_lines[i - 1], translation_lines[j - 1], u=u, g=g, f=f, e=e)
            gap_poem = dp[i - 1][j] + gap_penalty  # Gap in translation
            gap_translation = dp[i][j - 1] + gap_penalty  # Gap in poem

            dp[i][j] = max(match_weight, gap_poem, gap_translation)

            # Track the source of the best alignment decision (match, gap in poem, gap in translation)
            if dp[i][j] == match_weight:
                traceback[i][j] = (i - 1, j - 1)
            elif dp[i][j] == gap_poem:
                traceback[i][j] = (i - 1, j)
            else:
                traceback[i][j] = (i, j - 1)

    # Traceback step to retrieve the optimal alignment path
    aligned_poem = []
    aligned_translation = []

    i, j = m, n
    while i > 0 or j > 0:
        prev_i, prev_j = traceback[i][j]
        if i > 0 and j > 0 and (prev_i, prev_j) == (i - 1, j - 1):
            aligned_poem.append(poem_lines[i - 1])
            aligned_translation.append(translation_lines[j - 1])
        elif i > 0 and (prev_i, prev_j) == (i - 1, j):
            aligned_poem.append(poem_lines[i - 1])
            aligned_translation.append("-")  # Gap in translation
        else:
            aligned_poem.append("-")  # Gap in poem
            aligned_translation.append(translation_lines[j - 1])
        i, j = prev_i, prev_j

    # Reverse the alignments to reflect the original sequence
    aligned_poem.reverse()
    aligned_translation.reverse()

    # Initialize output
    output = []

    # Process each aligned pair for final output
    for pair_id, (op_token, ct_token) in enumerate(zip(aligned_poem, aligned_translation), 1):

        # Extract necessary fields for poem and translation tokens
        op_fields = op_token.split() if op_token != "-" else ["-"] * 9  # Handle gaps with placeholder
        ct_fields = ct_token.split() if ct_token != "-" else ["-"] * 12  # Handle gaps with placeholder

        assert len(op_fields) == 9, f"Invalid op_fields length: {len(op_fields)}. Fields: {op_fields}"

        # Unpack poem fields
        (
            token_identifier_op,  # AnthologyID:PoemID:SequentialID
            polysemy_decomposition_op,
            bg_id_op,
            pos_op,
            surface_op,
            lemma_kanji_op,
            lemma_kana_op,
            conjugation_kanji_op,
            conjugation_kana_op
        ) = op_fields

        # Unpack translation fields
        (
            polysemy_ct,
            # Explanation for polysemy_ct:
            # 1=non-polysemy
            # 2=polysemy
            translator,
            poem_id,
            polysemy_decomposition_ct,
            # Explanation for polysemy_decomposition_ct:
            # 0=default sense(non-polysemy and simplex);
            # 1=defaut sense(compound);
            # 2=potential sense; 3=decomposition of compound
            pos_ct,
            pos_b_ct,
            pos_c_ct,
            bg_id_ct,
            surface_ct,
            lemma_kana_ct,
            lemma_kanji_ct,
            seq_id_ct
        ) = ct_fields

        # Handle potential sense and decomposition flags
        potential_sense_op = "" if (polysemy_decomposition_op == "-" or polysemy_decomposition_op[1] == "0") else "*"
        potential_sense_ct = "" if (polysemy_decomposition_ct == "-" or (polysemy_ct == "1" and polysemy_decomposition_ct != "2")) else "*"
        decomposition_op = "+" if (polysemy_decomposition_op[0] == "C" or polysemy_decomposition_op[0] == "E") else ""
        decomposition_ct = "+" if polysemy_decomposition_ct == "3" else ""

        # Determine match category based on score (Exact, Field, Group)
        category = match_category(bg_id_op, bg_id_ct) if (op_token != "-" and ct_token != "-") else "-"
        match_value = category

        # Sequential ID for poem
        seq_id_op = int(token_identifier_op.split(":")[-1]) if token_identifier_op != "-" else "-"

        # Padding
        padding_width_op = 7 - 1 * len(surface_op) if surface_op != "-" else 7
        if padding_width_op < 0:
            padding_width_op = 0
        padding_width_ct = 7 - 1 * len(lemma_kanji_ct) if lemma_kanji_ct != "-" else 7
        if padding_width_ct < 0:
            padding_width_ct = 0

        # Format the final aligned output with appropriate columns and alignment
        output.append(
            f"{pair_id:>2} {match_value:>2} {pos_op:>2} {bg_id_op:>18} {surface_op:>{padding_width_op}} {seq_id_op:>2} {potential_sense_op:>1} "
            f"{decomposition_op:>1} <-> {decomposition_ct:<1} {potential_sense_ct:<1} {seq_id_ct:<2} {lemma_kanji_ct:<{padding_width_ct}} {bg_id_ct:<18}"
        )

    # Prepare the formatted output with headers and alignment
    translator = translation_lines[0].split()[1]
    poem_id = translation_lines[0].split()[2]
    header = (
        f"args: translator:{translator}; poem No.{poem_id}; weight:(U={u}, G={g}, F={f}, E={e}); gap penalty: {gap_penalty}\n"
        " +------- pair No.\n"
        " |  +---- matching level (E=Exact, F=Field, G=Group)\n"
        " |  |  +- pos No.\n"
        " |  |  |  OP decomposition (+) ----------+     +--------------- CT decomposition\n"
        " |  |  |  OP potential sense (*) ------+ |     | +------------- CT potential sense\n"
        " |  |  |  OP token No. --------------+ | |     | | +----------- CT token No.\n"
        " |  |  |  OP token ---------------+  | | |     | | |  +-------- CT token\n"
        " |  |  |  OP WLSP code ---+       |  | | |     | | |  |       + CT WLSP code\n"
        " |  |  |                  |       |  | | |     | | |  |       |"
    )
    output = [header] + output

    return "\n".join(output)
```

```{python}
#| label: count-match-alignment

def match_count_alignment(alignment_output: str) -> dict:
    """
    Count the occurrences of match categories (E, F, G) in the alignment output.

    This function counts only the E (Exact), F (Field), and G (Group) matches in the alignment output.
    It does not calculate or track unmatched (U) tokens.

    :param alignment_output: A string representing the alignment output, where each line represents a pair.

    :return: A dictionary with counts of E, F, and G matches.
    """
    # Initialize the counters for each match category
    counts = {"E": 0, "F": 0, "G": 0}

    # Extract the total number of OP tokens from the header
    lines = alignment_output.strip().splitlines()

    # Iterate through the lines and count occurrences of E, F, G
    for line in lines:
        # Skip lines that do not contain match category information
        if len(line.strip()) == 0 or line.strip().startswith('+'):
            continue

        # Extract the match category from the line (2nd field)
        match_category = line.split()[1].strip()

        # Count E, F, G and skip lines with "-"
        if match_category == "E":
            counts["E"] += 1
        elif match_category == "F":
            counts["F"] += 1
        elif match_category == "G":
            counts["G"] += 1

    return counts
```

```{python}
#| label: count-macth

def match_count(match_counts: dict, level: int = 1) -> int:
    """
    Calculate the total match count based on the specified match level.

    The match count is calculated by summing the appropriate categories of matches
    based on the selected level of strictness:

    - Level 1: Only count Exact (E) matches.
    - Level 2: Count Exact (E) and Field (F) matches.
    - Level 3: Count Exact (E), Field (F), and Group (G) matches.

    :param match_counts: A dictionary with counts of E, F, G, and U matches.
    :param level: Integer representing the matching strictness level (default is 1).
        - Level 1: Only count Exact matches (E).
        - Level 2: Count Exact (E) and Field (F) matches.
        - Level 3: Count Exact (E), Field (F), and Group (G) matches.

    :return: An integer representing the total match count.
    """

    # Ensure the level is valid
    assert level in [1, 2, 3], "Invalid level. Must be 1, 2, or 3."

    # Calculate the total match count based on the level
    if level == 1:
        total_match_count = match_counts["E"]
    elif level == 2:
        total_match_count = match_counts["E"] + match_counts["F"]
    else:  # level == 3
        total_match_count = match_counts["E"] + match_counts["F"] + match_counts["G"]

    return total_match_count
```

```{python}
#| label: pipe

def pipe(poem: str, translation: str, mode: int = 3, level: int = 3, gap_penalty: float = 0.01, u: int = -1, g: int = 10, f: int = 13, e: int = 17):
    """
    A complete pipeline function that processes poem and translation data, computes match counts,
    alignment results, and rates (addition and unmatch rates), and writes results to a CSV file.

    :param poem: The poem data as a string.
    :param translation: The translation data as a string.
    :param mode: The mode to filter the poem and translation (default is 3).
    :param level: The strictness level for calculating match counts (default is 3).
    :param gap_penalty: Gap penalty for alignment (default is 0.01).
    :param u: Weight for unmatch (default is -1).
    :param g: Weight for group match (default is 10).
    :param f: Weight for field match (default is 13).
    :param e: Weight for exact match (default is 17).
    """

    # Process the poem and translation using poem_mode and translation_mode
    poem_lines = poem_mode(poem, mode)
    translation_lines = translation_mode(translation, mode)

    # Calculate poem and translation sizes
    poem_size = len(poem_lines)
    translation_size = len(translation_lines)

    # Info
    translator = translation_lines[0].split()[1]
    poem_id = translation_lines[0].split()[2]

    # Calculate match counts using the bag method
    match_count_bag_ = match_count_bag(poem_lines, translation_lines)
    exact_match_bag = match_count_bag_["E"]
    field_match_bag = match_count_bag_["F"]
    group_match_bag = match_count_bag_["G"]
    unmatch_bag = poem_size - exact_match_bag - field_match_bag - group_match_bag
    total_match_bag = match_count(match_count_bag_, level)

    # Calculate alignment and match counts from alignment
    alignment_output = alignment(poem_lines, translation_lines, gap_penalty=gap_penalty, u=u, g=g, f=f, e=e)
    match_count_alignment_ = match_count_alignment(alignment_output)
    exact_match_alignment = match_count_alignment_["E"]
    field_match_alignment = match_count_alignment_["F"]
    group_match_alignment = match_count_alignment_["G"]
    unmatch_alignment = poem_size - exact_match_alignment - field_match_alignment - group_match_alignment
    total_match_alignment = match_count(match_count_alignment_, level)

    # Calculate addition and unmatch rates
    addition_rate_bag = 1 - total_match_bag / translation_size if translation_size > 0 else 0
    addition_rate_alignment = 1 - total_match_alignment / translation_size if translation_size > 0 else 0
    unmatch_rate_bag = unmatch_bag / poem_size if poem_size > 0 else 0
    unmatch_rate_alignment = unmatch_alignment / poem_size if poem_size > 0 else 0

    # Format the statistics according to the required structure
    statistics = (
        f"mode={mode}; level={level}\n"
        f"OP={poem_size}; CT={translation_size};\n"
        f"bag (E={exact_match_bag}, F={field_match_bag}, G={group_match_bag}, U={unmatch_bag}, T={total_match_bag}, "
        f"AddRate={addition_rate_bag:.2%}, UnmatchRate={unmatch_rate_bag:.2%});\n"
        f"alignment (E={exact_match_alignment}, F={field_match_alignment}, G={group_match_alignment}, U={unmatch_alignment}, "
        f"T={total_match_alignment}, AddRate={addition_rate_alignment:.2%}, UnmatchRate={unmatch_rate_alignment:.2%})"
    )
    
    # Print alignment output and formatted statistics
    print("statistics:", statistics)
    print(alignment_output)
```


## 翻訳アプローチによる追加率の差の統計モデリング

読者本位や歌人本位の訳文は、解釈や推論の追加が多く含まれる可能性が高く、ノンリテラル要素を多く抽出できると考えられる。しかし、訳者が主観的に読者本位・歌人本位のアプローチを意識しても、翻訳実践と翻訳アプローチの間にずれが生じることがある。各訳者が自身の翻訳アプローチにどれほど一貫しているかを、現代語訳の追加率と翻訳アプローチの関連の視点から検証する。翻訳アプローチによる追加率の差が統計的に見られない場合、和歌の翻訳実践に必然的に要素の追加が伴うことを意味すると考えている。先行研究 [@Yamamoto2005Mathematical; @Yamamoto2019Analysis] では、グループ・フィールド・同義レベルの一致率や、理論的・実験的追加率などの指標を計算しているが、翻訳者別の追加率の平均と標準偏差のみが提示されている。それぞれの値は訳者の意図・アプローチに沿った結果か、現代語訳において常なる結果かを調査する必要がある。

データの更新や計算手順の変更により、結果に変化が生じるため、新たに計算した追加率を対象に統計分析を行う。具体的には、翻訳アプローチ（`Focus`）が追加率（`Addition Rate`）に与える影響を検討するため、ベータ分布に基づく回帰モデルを採用する。ここでは、前述のバッグ法によって算出された追加率を応答変数として用いる。ベータ分布を用いる理由は、応答変数が $(0, 1)$ の範囲にあり、二項分布の代替として適しているためである。また、訳者（`Translator`）と歌（`Poem ID`）の変動を統制するためにランダム効果をモデルに含めている。モデルの詳細については補足資料を参照されたい。

モデルの推定には Markov Chain Monte Carlo (MCMC) 法を使用し、4 つのチェーンそれぞれで 2000 回のイテレーションを行い、そのうち 1000 回をウォームアップ (burn-in) とする。`R` (`{r} version$version.string`) [@RCoreTeam2024Language] のパッケージ `brms` (`{r} packageVersion("brms")`) [@Burkner2017Brms] を使用してモデルを実装し、事後分布の収束は $\hat{R}$ 指標および有効サンプルサイズ (ESS) により評価する。モデルの推定結果として、各アプローチの追加率の事後分布をサンプリングし、中央値と 95% の信用区間 (CrI) を報告する。なお、信用区間には事後最狭信用区間 (Highest Posterior Density Interval) を用いる。また、アプローチ間の追加率の差についても、事後分布を示す。

事後分布の可視化と解釈は、@Yu2020Tradeeffect の手法を参考とする。2 群の差の事後分布の 95% CrI が 0 をカバーしているかを確認する。また、2 群の差が 0 より大きい確率も観測する。具体的には、95% CrI が 0 をカバーしていない場合には 2 群の間に差があると判断し、0 をカバーしている場合でも、差が 0 より大きい確率が 95% より大きい、または 5% より小さい場合には、傾向ありと認める。

```{R}
#| label: data-process
#| message: false

data <- read.csv("artifacts/calc_results.csv") |>
  mutate(
    Translator = as.factor(Translator),
    Focus = case_when(
      Translator %in% c(
        "kaneko",
        "kubota",
        "katagiri"
      ) ~ "Text-focused",
      Translator %in% c(
        "okumura",
        "takeoka"
      ) ~ "Poet-focused",
      Translator %in% c(
        "ozawa",
        "kyusojin"
      ) ~ "Reader-focused",
      Translator %in% c(
        "matsuda",
        "kojimaarai",
        "komachiya"
      ) ~ "Others",
    ),
    Focus = factor(
      Focus,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    ),
    Translator = factor(
      Translator,
      levels = c(
        "kaneko",
        "kubota",
        "katagiri",
        "okumura",
        "takeoka",
        "ozawa",
        "kyusojin",
        "matsuda",
        "kojimaarai",
        "komachiya"
      )
    )
  ) |>
  select(
    Translator,
    PoemID,
    Focus,
    AdditionRate,
    UnmatchRate
  )

translator_labels <- c(
  "kaneko" = "KNK",
  "kubota" = "KBT",
  "katagiri" = "KTGR",
  "okumura" = "OKMR",
  "takeoka" = "TKOK",
  "ozawa" = "OZW",
  "kyusojin" = "KSJ",
  "matsuda" = "MTD",
  "kojimaarai" = "K&A",
  "komachiya" = "KMCY"
  )
```


```{r}
#| label: beta-model
#| cache: true
#| messge: false

# backend
options(
    mc.cores = parallel::detectCores(),
    brms.backend = "cmdstanr"
)

# Global setting
chains <- 4
iter <- 2000
warmup <- 1000
bayes_seed <- 1234

# Formula
formula <- bf(
  AdditionRate ~ a + b, 
  a ~ 1 + (1 | Translator) + (1 | PoemID),
  b ~ 0 + Focus,
  phi ~ 1 + (1 | PoemID),
  nl = TRUE
)

prior = c(
  prior(student_t(3, 0, 2.5), nlpar = b),
  prior(
    student_t(3, 0, 2.5),
    class = b,
    coef = Intercept,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    group = Translator,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    group = PoemID,
    nlpar = a
  ),
  prior(
    student_t(3, 0, 2.5),
    class = Intercept,
    dpar = phi
  ),
  # Default prior for standard deviation of phi parameter in PoemID group
  prior(
    student_t(3, 0, 2.5),
    class = sd,
    dpar = phi,
    group = PoemID
  )
)

# Model
model <- data %>%
  brm(
    data = .,
    formula = formula,
    family = Beta(), 
    prior = prior, 
    chains = chains,
    iter = iter,
    warmup = warmup,
    seed = bayes_seed,
    silent = 2,
    adapt_delta = 0.9,
    control = list(max_treedepth = 12),
    file = "./artifacts/model_beta_bayes",
    save_model = TRUE
  )
```

## 「立田」歌の事例分析

現代語訳の和歌には、何らかの言い換えや追加が行われることがあるが、その要素の性質や内容が必ずしも明確ではない。これらの要素の性質を明らかにするため、アライメントにおける一致を確認しつつ、コーパス言語学の観点から分析を行う。本稿では、@Sinclair1996Search の拡張意味単位モデルを参考にし、和歌の原文に見られるコーパスレベルの傾向が、対訳文のセンテンスレベルでどのように処理されているかを明らかにする。
拡張意味単位モデルは、コロケーション（collocation; 他の語の共出現関係）[@Sinclair1970English, p. 15]、コリゲーション（colligation; 構文パターンや文法的要素との共出現関係）[cf., @Firth1968Selected, p. 183; @Sinclair1996Search, p. 11; @Sinclair2003Reading, p. 171]、意味的志向（semantic preference; 特定の意味の語群との共出現関係）[@Sinclair2003Reading, p. 178]、そして談話韻律（discource prosody; 拡張意味単位全体の評価・態度・語用論的意味）[@Sinclair2004Trust, p. 174]の 4 つのレベルで対象言語単位を記述する。このモデルにおいて、コロケーションから談話韻律へと進むにつれて、直接的な観測が難しくなり、明示的ではなくなる [@Stubbs2001Words, pp. 87--88]。
和歌の性質とデータの量が少ないため、すべての拡張意味単位を正確に捉えることは困難である。したがって、本稿では、拡張意味単位の 4 つのレベルを 4 つの視座として、それぞれ共出現の語、構文パターン、語の意味的まとまりについて、10 人の翻訳者がどのように処理しているかを分析する。

@Yamamoto2005Mathematical では、現代語訳の紹介に歌枕「立田」の歌 298 番をとりあげている。本稿でも同じ歌をとりあげ、それが 10 人の翻訳、異なる翻訳の方針でどのように処理されているか、前掲の 3 つの視座から分析する。

コロケーションのレベルで確認すると、八代集全体における 54 首において、
「立田」の文脈に頻出する内容語 ^[形態素解析システム Chasen を用いたため、Chasen の ID が 60 以前のもの]には「山」（30；うち共出現語として 15 あり、「立田山」の複合表現として 15 ある）「紅葉づ」（17）「川」（「立田川」の複合表現として 15 ある）「秋」（15）「見る」（12）「紅葉葉」（9）「錦」（9） があげられる。
頻度5以上の語には、「神無備」（5）「姫」（うち「立田姫」の複合表現として 8 ある） など神に関連する語と、「散る」（8）「流る」（5）「吹く」（6）「紅葉」（5）「黄葉」（5） など、落葉に関連する語が存在している。^[詳細は補足資料を参照されたい。]

共出現する構文パターンとして、動詞の終止形で終わる歌の少なさ（古今集 12 首の中で 1 首のみ）が観測される。また、古今集の中では、係り結びは 9 首観測されており、
余韻の残し方に特徴があると考えられる。これら終わり方の構文パターンが、翻訳における処理について考察する。

共出現する語の性質は、内容語のコロケーションは基本的に、「立田川」「立田（の）山」など地名を構成する「山」「川」のグループのほか、秋の「神」に関連する関連語のグループが明瞭に見える。神聖なる場所の歌枕の性質が伺える。

298 番歌の訳における追加要素のバリエーションを示しながら、以上のコーパスレベル・大局レベルの要素が 298 番歌のセンテンスレベルで組み込まれるか、どのように組み込まれているかを確認し、ノンリテラル要素と捉えられるかを論じる。

<!-- ::: {.callout-note} -->
<!-- ### 拡張意味単位モデルの視座 -->

<!-- 意味の拡張単位モデルでは、意味の単位を以下の五つの要素に分けている [@Sinclair1996Search]。 @Sinclair1996Search は *true feeling* から「(not) [EXPRESS] [one's] *true feeling*」といった意味の拡張単位を抽出している例とりあげているので、この例で要素について @tbl-EUoM にまとめ説明する: -->

<!-- | 要素                | 説明                                                    | 例                                                                                          | 方法                                | -->
<!-- |:--------------------|:--------------------------------------------------------|:--------------------------------------------------------------------------------------------|:------------------------------------| -->
<!-- | コア（core）        | 拡張意味単位における不変の成分                            | *true feeling*                                                                              | 検索語・フレーズとして使用。         | -->
<!-- | コロケーション（collocation） | コアと語の共出現                                      | 高頻度共出現語 (*their*, *express*, *hide*, *reveal*) + *true feeling*                      | span $\pm$ 4、出現率50%以上。       | -->
<!-- | 類連結（colligation）     | コアと構文・パターンとの共出現                | 所有格形容詞 (*thier/his/her/our*) + *true feeling*                                        | コンコーダンスによる観測・帰納。    | -->
<!-- | 意味的志向（semantic preference） | コアと特定の意味の語群との共出現                        | **(not)EXPRESS** (*express/hide/reveal/conceal*) + *true feeling*                          | コンコーダンスによる観測・帰納。    | -->
<!-- | 談話韻律（discourse prosody）    | 拡張意味単位全体の評価・態度・語用論的意味               | 否定語 + **EXPRESS** -> 「客観的・主観的できない」（reluctance/inability）                        | コンコーダンスによる観測・帰納。    | -->

<!-- : 拡張意味単位の要素、説明、事例、操作例 {#tbl-EUoM} -->

<!-- 1. コア（core）は拡張意味単位における不変の成分である [@Sinclair2004Trust, p. 204]。*true feeling* がこの例におけるコアであり、検索語として使用されている。^[@Sinclair1996Search の例では、コアは実際には検索語に相当するものである。] -->
<!-- 2. コロケーション（collocation）：コアと語の共出現関係である [@Sinclair1970English, p. 15]。*true feeling* のコンテキストでは、*their*, *express*, *hide*, *reveal* などがあげられる。@Sinclair1996Search では、コンテキストのウィンドーは 4 に、閾値は 50% の出現率に設定されている。^[@Koller1979Computer はにすべきであるとしている。] -->
<!-- 3. 類連結（colligation）はコアと構文・パターンとの共出現関係である [cf., @Firth1968Selected, p. 183; @Sinclair1996Search, p. 11; @Sinclair2003Reading, p. 171]。例えば、*true feeling* の前方共出現に *thier/his/her/our* が多く、それらの性質は所有格形容詞であるため、所有格形容詞が *true feeling* の類連接と認める。この類連接は直接の観測ができないため、コンコーダンス・コロケーションリストによる観測・帰納に基づく。 -->
<!-- 4. 意味的志向（semantic preference）はコアと特定の意味の語群（semantic set）との共出現関係 [@Sinclair2003Reading, p. 178]。例えば、*express/hide/reveal/conceal* など **EXPRESS** まとは **EXPRESS** の否定のグループが常に *true feeling* のコンテキストに生起している。この意味的志向も類連接同様、コンコーダンス・コロケーションリストによる観測・帰納に基づく。 -->
<!-- 5. 談話韻律（discourse prosody）は拡張意味単位全体の評価・態度・語用論的意味 [@Sinclair2004Trust, p. 174]である。**EXPRESS**の左には*less/not*などの否定が頻繁に出現するため、*true feeling* については「客観的・主観的に表現できない」（reluctance/inability）といったネガティブな談話韻律が推測される。これも同様、コンコーダンス・コロケーションリストによる観測・帰納による。 -->

<!-- コア、コロケーションから談話韻律へと、直接な観測ができなくなり、明示的でなくなっていく [@Stubbs2001Words, pp. 87--88]。 -->

<!-- 和歌の性質とデータの量の少なさからして、確実に拡張意味単位を捉えることが難しいことがある。よって、本稿では単純に拡張意味単位の 4 つのレベルを 4 つの視座とみて、この 4 つの視座のうち、共出現の語、共出現の構文パターン、共出現の語の意味的まとまりで考えられる志向性から、分類された 10 人の翻訳でどのように処理されているかを分析する。 -->

<!-- 視座とする以上、いくつかのアダプテーションについて述べる。まず、拡張意味単位の本来の分析では要素の順序とコンテキスト・ウィンドーの設定はあるが、本稿では意味単位の共出現について順序の設定を考慮しない。57577の制限の中で、語の順番の入れ替えが多く、コアを中心とする線形配列が望ましくない。つぎに、出現率の閾値の設定はしない。テキストの数が少なく、大規模コーパスのようにロバストな結果として出すよりも、傾向を重視する。 -->
<!-- ::: -->

# 結果 {#sec-results}

## 現代語訳の整理と分類 
注釈書の前書きや導入部に記されている翻訳アプローチに関する意識と認識に基づき、10 人の翻訳者のアプローチをコミュニケーションの主体に対する視座の置き方によって、以下の 3 類に分類した。

1. **テキストの字義を重視する方針**: @kaneko1933Kokin, @kubota1960Kokin, @katagiri1998Kokinhyoshaku 

2. **作者の意図を重視する方針**: @okumura1978Kokin, @takeoka1976Kokin 

3. **読者の理解を重視する方針**: @ozawa1971Kikon, @kyusojin1979Kokin 

ただし、@matsuda1968Shinshaku, @kojima1989Kokin, @komachiya1982Kokin は、明確に翻訳アプローチについての記述がなかった。 

テキストの字義を重視する翻訳アプローチは、逐語訳に最も忠実である。一方、作者の意図や感受性を重視するアプローチおよび読者の理解を重視するアプローチでは、語や語順の入れ替えや、語句の補いを一定程度許容していることが示唆されている。 

### Text-focused approach: KNK, KBT, KTGR {.unnumbered}

原文の字義通りの解釈を重視する訳のグループは、原文に忠実な翻訳を行い、可能な限り語順や意味を変えずに訳すことに重点を置くものである。例えば、@kaneko1933Kokin は「逐語訳」を徹底し、語の追加や削除を避け、慎重に翻訳を行っていると述べている。また、@kaneko1933Kokin は、歌の意味を損ねたり調子を誤ったりすることを恐れ、鏡花水月の訳法^[あからさまに説明せず、ただその姿を眼前に思い浮かべるようにする漢文の表現法] にしたがい、一字一語の変更を許さない慎重な翻訳方針を採っている。文体面では、例えば「くずをれる」といった古風な言葉をあえて用いるなど、本居宣長の『遠鏡』に似た翻訳調を採用している。

@kubota1960Kokin も、現代語訳の方針として逐語訳にこだわり、語順の変更や新しい語の追加を避けていると述べている。同様に、@katagiri1998Kokinhyoshaku も逐語訳を行い、和歌の省略や過度な補足を避け、可能な限り忠実に現代語訳を実施していると述べている。

### Poet-focused approach: OKMR, TKOK {.unnumbered}

歌人の作意を重視する訳のグループは、表面的な意味よりも原文の意図と感受性を重視するグループである。@okumura1978Kokin [p. 7] は「口語訳は、原歌の言葉遣いや言い回しを尊重し、一首の意味を厳密に解釈するよりも、基本的な作意をまず感じ取ってもらうことに重点を置いた」と述べている。原文の意図の理解を重視し、逐語訳よりも作意を優先して翻訳を行っている。@takeoka1976Kokin [p. 21] は、訳（口語訳）は原文の「筋」の紹介や解説の類ではなく、作者の認識の仕方や感じ方をあらゆる面から明らかにしたのち、それを現代語に存在する同じ、あるいは極力それに近い認識の仕方や感じ方の表現に忠実に置き換えることを指している。つまり、表面的には原歌の同義語に拘るものの、原歌における歌人の感受性の保持に重点を置いている。

具体的な現代語訳の方針として、@takeoka1976Kokin [pp. 11-–12] は次のような独自の理論を提案している。

$$
S=\left[\left(a+b+c+\dots+n\right)\times X \right]\times Y
$$

$S$ は翻訳された歌であり、$a, b, c, \dots, n$ のそれぞれは歌における語、$X$ は訳に含まれる要素であり、$Y$ は訳に効果的に加えられた要素である。$a, b, c, \dots, n$ それぞれの一般的普遍的意義は辞書で理解でき、それぞれの $+$ の仕方に相当するものは文法書を参照すれば理解できるとしている。@takeoka1976Kokin [p. 11] は、$Y$ は通常は 0 の値であるが、和歌にはいくつか効果的な要素が含まれる時、翻訳者は $Y$ に何らかの値、例えば終助詞（わ、ね、よ）を付け加える。したがって、現代語訳作成のための重要な変数は $X$ となる。その $X$ は、語句の分割、対応する適切な現代語、語順、助詞・接続詞を含めた訳語、文の構造、話の流れ（談話）、場面の7つに分類されるとしている。このように、歌の筋よりも作者の意図を細部まで還元することを強調していると解釈できる。^[契沖の「古今和歌集余材抄」以来の7種の注釈書の注を統合した初めてのものである。竹岡はこの注釈書にて文学研究に分析的アプローチを組み込んでいる。竹岡は賀茂真淵、香川景樹の仕事を分析に根拠がないとして同意できないとする一方で、契沖、本居宣長、富士谷成章（1738–79）らの注釈を評価している。加えて、特に古典文法、語彙の観点から7種すべての古注間の違いについて慎重に議論している。]

### Reader-focused approach: OZW, KSJ {.unnumbered}

読者の理解を重視する訳のグループは、原文に忠実であることよりも、読者の内容の理解や解釈を読者に伝えることを重視している。そのため、語順を変えたり、新しい語を加えることもある。
@ozawa1971Kikon は原作の語順・語法を変更することをいとわず、読者が理解しやすいように内容を優先した翻訳を行っている。 @ozawa1971Kikon [p. 46] は「口語訳はそれだけ独立しても意味がよくわかるように努めたので、時には原作の語順・語法を変えている」と述べており、逐語訳よりも内容の理解の方に力点が置かれている。@kyusojin1979Kokin は、平易な口語訳を採用し、必要に応じて語句を補っており、解釈を重視した翻訳を行っている。現代語訳の方針としては「歌意は、歌句に基づく平易な口語訳としたが、必要と思われる場合は字句を補った」と述べている [@kyusojin1979Kokin, p.6]。

### その他のアプローチ: KMCY, MTD, K&A {.unnumbered}

現代語訳の方針について、@komachiya1982Kokin、@matsuda1968Shinshaku、@kojima1989Kokin は明確に述べていない。

うち、@matsuda1968Shinshaku の現代語訳は、他の10名の共同執筆者によって作成されている。この注釈書の冒頭で述べられている解説によれば、現代語訳はこれまでの研究に基づいて作成されたとしているが、10名の共著者の間で翻訳の共通認識や作成方針については明確に述べられていない。また、松田は古今集の和歌について、歌人の感情だけでなく、選者の編集意識も解釈に含めようとしていると述べている [@matsuda1968Shinshaku, p. 9]。

@kojima1989Kokin の特色の一つは、注釈に江戸期（1600–1868）だけでなく、それまでの注釈書では無視されてきた中世期（1392–1600）に作られた注釈も取り入れていることである [pp. 481–482]。また、万葉集の和歌と用語を対比して引用している [@kojima1989Kokin, p. 480]。各歌の注釈は、「歌番号」「大意」「語句の注」「参考事項」の順で述べられており、他の注釈本と比べて量的にはさほど違いはないが、付録には多様な資料が含まれており、その分量は本全体の30%を占めている。

### まとめ {.unnumbered}

それぞれの翻訳アプローチを見る限り、ほとんどの作者が逐語訳を基本とし、原文の意味を変えない翻訳を試みているが、従来の注釈書の継承の仕方や情報伝達における重点の置き方には違いが見られる。本稿では、「テキストの字義を重視」「作者の意図・感受の解釈を重視」「読者の理解を重視」「その他」というコミュニケーションモデルの観点から分類を行った。この中で、原文の字義を重視する翻訳アプローチは、最も逐語訳にこだわっていた。作者の意図や感受を重視する、または読者の理解を重視する翻訳アプローチでは、語順や語句の多少の入れ替えや補いを許容していた。ただし、この分類には重なり合う部分もあると考えられる。

## 不一致率と追加率の推定結果

追加率の計算結果を @fig-data に示す。不一致率は 0–88 % の範囲であった [@tbl-data-review]。中でも、TKOK の現代語訳が最も不一致率が低く、17.2 % (sd = 0.1) であった [@fig-unmatch-rate]。一方、OZW の現代語訳が最も高く、23% (sd = 0.112) であった [@fig-unmatch-rate]。既に述べたように、OZW は語順を変更することをいとわないのに対し、竹岡は自身の方針に忠実に翻訳を行っている。この差がデータに明確に表れていると言える。

10 種の現代語訳のうち、697番歌は不一致率が 88.2% と最も高い和歌であった [@tbl-data-review]。つまり、和歌の中のほとんどの語が訳されていないことを示している。このような歌については、次の例で確認する。

```{R}
#| label: fig-data
#| fig-scap: 訳者別の追加率の確率分布
#| fig-cap: 訳者別の追加率の確率分布 Probability distribution of addition rates by translator
#| messge: false
#| warning: false

by_focus_annotation <- data |> group_by(Focus) |> 
  get_summary_stats(
    AdditionRate, 
    type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    ) 
  ) |>
  select(annotation) |>
  pull()

by_translator_annotation <- data |> group_by(Translator) |> 
  get_summary_stats(
      AdditionRate, 
      type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    )
  )|>
  select(annotation) |>
  pull()

data |>
  arrange(Focus, Translator) |>
  ggplot(
    aes(
      x = AdditionRate, 
      y = Translator, 
      fill = Focus,
      )
    ) + 
  stat_density_ridges(
    color = palette_okabe_ito(5),
    quantile_lines = TRUE, 
    quantiles = c(0.025, 0.5, 0.975), 
    jittered_points = TRUE, 
    position = "raincloud",
    vline_width = 1, vline_color = "red",
    point_size = 0.001, 
    point_alpha = 0.1,
    point_color = "black",
    alpha = 0.8,
    scale = 1,
    ) +
  # scale_fill_brewer(palette = "Blues") +  
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.2, 1.2)
  ) +  
  scale_y_discrete(labels = translator_labels) +
  geom_hline(
    yintercept = c("matsuda", "ozawa", "okumura", "kaneko"),
    linetype = "solid", 
    color = "black",
    linewidth = 1.5
    ) + 
  annotate(
    geom="text",
    x = -0.2, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    # color = "blue",
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = -0.1,
    hjust = 0,
    size = 6,
    label = c(
      "Others", 
      "Reader-focused",
      "Poet-focused",
      "Text-focused"
      )
    ) + 
  annotate(
    geom="text",
    x = -0.2, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = 1.2,
    hjust = 0,
    size = 3,
    label = by_focus_annotation,
    parse = TRUE
    ) + 
  annotate(
    geom="text",
    x = 1.2, y = c(levels(data$Translator)),
    color = "black",
    vjust = -0.2,
    hjust = 1,
    size = 3,
    label = by_translator_annotation,
    parse = TRUE
    ) +
  xlab("Addition Rate") +
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  labs(
    fill = "Translation Approach: ",
    caption = "2.5%, 50%, 97.5% quantiles are shown with red line"
  ) + 
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.text.y = element_text(
      face = "italic"
    ),
    legend.title = element_text(size = 12),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 2)) 
```

```{r}
#| label: fig-unmatch-rate
#| fig-scap: 不一致率（明確な対応をもたない要素が和歌原文を占める割合）の概要
#| fig-cap: 訳者別の不一致率の確率分布（明確な対応をもたない要素が和歌原文を占める割合） Probability distribution of unmatch rates by translator (unmatch rate is the proportion of elements in the original poem without agreement)

by_focus_annotation <- data |> group_by(Focus) |> 
  get_summary_stats(
    UnmatchRate, 
    type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    ) 
  ) |>
  select(annotation) |>
  pull()

by_translator_annotation <- data |> group_by(Translator) |> 
  get_summary_stats(
      UnmatchRate, 
      type = "mean_sd"
  ) |>
  mutate(
    annotation = paste0(
      formatC(mean * 100, format = "f", digits = 1),
      "*'%'~(N==",
      n,
      "*';'~std.==", 
      formatC(sd, format = "f", digits = 3),
      ")"
    )
  ) |>
  select(annotation) |>
  pull()

data |>
  arrange(Focus, Translator) |>
  ggplot(
    aes(
      x = UnmatchRate, 
      y = Translator, 
      fill = Focus,
    )
  ) + 
  stat_density_ridges(
    color = palette_okabe_ito(5),
    quantile_lines = TRUE, 
    quantiles = c(0.025, 0.5, 0.975), 
    jittered_points = TRUE, 
    position = "raincloud",
    vline_width = 1, vline_color = "red",
    point_size = 0.001, 
    point_alpha = 0.1,
    point_color = "black",
    alpha = 0.8,
    scale = 1,
  ) +
  # scale_fill_brewer(palette = "Blues") +  
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.2, 1.2)
  ) + 
  scale_y_discrete(labels = translator_labels) +
  geom_hline(
    yintercept = c("matsuda", "ozawa", "okumura", "kaneko"),
    linetype = "solid", 
    color = "black",
    linewidth = 1.5
  ) + 
  annotate(
    geom = "text",
    x = 0.4,
    y = c(
      "kojimaarai", "kyusojin",
      "takeoka", "katagiri"
    ), 
    # color = "blue",
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = -0.1,
    hjust = 0,
    size = 5,
    label = c(
      "Others", 
      "Reader-focused",
      "Poet-focused",
      "Text-focused"
    )
  ) + 
  annotate(
    geom = "text",
    x = 0.4, y = c("kojimaarai", "kyusojin", "takeoka", "katagiri"),
    color = palette_okabe_ito(order=c(2, 3, 6, 1)),
    vjust = 1.2,
    hjust = 0,
    size = 2.5,
    label = by_focus_annotation,
    parse = TRUE
  ) + 
  annotate(
    geom="text",
    x = 1.2, y = c(levels(data$Translator)),
    color = "black",
    vjust = -0.2,
    hjust = 1,
    size = 2.5,
    label = by_translator_annotation,
    parse = TRUE
  ) +
  geom_vline(
    xintercept = 0.2,
    color = palette_okabe_ito(9),
    linewidth = 1
  ) +
  xlab("Unmatch Rate") +
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  labs(
    fill = "Translation Approach: ",
    caption = "2.5%, 50%, 97.5% quantiles are shown with red line\n20% line is shown with black dashed line"
  ) + 
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.text.y = element_text(
      face = "italic"
    ),
    legend.title = element_text(size = 12),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 2)) 
```

```{R}
#| label: tbl-data-review
#| tbl-cap: "不一致率・追加率の概要 Summaries of unmatch and addition rates"
#| tbl-subcap: 
#|   - "不一致率・追加率の概要 Data ummary of unmatch and addition rates"
#|   - "不一致率の最も高い対訳（上位 5 対） Poem-translation pairs with the highest unmatch rates (top 5)"
#|   - "追加率の最も高い対訳（上位 5 対） Poem-translation pairs with the highest addition rates (top 5)"
#|   - "平均不一致率の最も高い歌（上位 5 首） Poem with the highest average unmatch rate in contemporary translations (top 5)"
#|   - "平均追加率の最も高い歌（上位 5 首） Poem with the highest average addition rate in contemporary translations (top 5)"
#| layout: [[100], [45, -10, 45], [45, -10, 45]]

# subtbl1
main.title.1 <- "不一致率・追加率の概要"
subtitle.1 <- "Data summary of unmatch and addition rates"
cols.1 <- c("", "最小値\nMin.", "最大値\nMax.", "中央値\nMedian", "平均値\nMean", "標準偏差\nsd")
tab.1 <- data |>  
  get_summary_stats(
    UnmatchRate, AdditionRate,
    type = "full"
  ) |>
  mutate(
    variable = case_when(
      variable == "UnmatchRate" ~ "不一致率 (Unmatch Rate)",
      variable == "AdditionRate" ~ "追加率 (Addition Rate)",
      TRUE ~ variable
    )
  ) |>
  select(variable, min, max, median, mean, sd)
create_kable_table(tab.1, cols.1)

# subtbl2
main.title.2 <- "不一致率の最も高い対訳（上位 5 対）"
subtitle.2 <- "Poem-translation pairs with the highest unmatch rates (top 5)"
cols.2 <- c("訳者\nTranslator", "歌番\nPoem ID", "不一致率\nUnmatch Rate")
tab.2 <- data |>  
  mutate(
    UnmatchRate = round(UnmatchRate, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  arrange(UnmatchRate) |>
  slice(n():(n()-4)) |>
  select(Translator, PoemID, UnmatchRate)
create_kable_table(tab.2, cols.2)

# subtbl3
main.title.3 <- "追加率の最も高い対訳（上位 5 対）"
subtitle.3 <- "Poem-translation pairs with the highest addition rates (top 5)"
cols.3 <- c("訳者\nTranslator", "歌番\nPoem ID", "不一致率\nUnmatch Rate")
tab.3 <- data |>
  mutate(
    AdditionRate = round(AdditionRate, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  arrange(AdditionRate) |>
  slice(n():(n()-4)) |>
  select(Translator, PoemID, AdditionRate)
create_kable_table(tab.3, cols.3)

# subtbl4
main.title.4 <- "平均不一致率の最も高い歌（上位 5 首）"
subtitle.4 <- "Poem with the highest average unmatch rate\nin contemporary translations (top 5)"
cols.4 <- c("歌番\nPoem ID", "平均値\nMean", "標準偏差\nsd")
tab.4 <- data |>
  mutate(
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |>
  group_by(PoemID) |> 
  get_summary_stats(
    UnmatchRate,
    type = "mean_sd"
  ) |>
  arrange(mean) |>
  slice(n():(n()-4)) |>
  select(PoemID, mean, sd)
create_kable_table(tab.4, cols.4)

# subtbl5
main.title.5 <- "平均追加率の最も高い歌（上位 5 首）"
subtitle.5 <- "Poem with the highest average addition rate\nin contemporary translations (top 5)"
cols.5 <- c("歌番\nPoem ID", "平均値\nMean", "標準偏差\nsd")
tab.5 <- data |> 
  mutate(
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID)
  )  |> 
  group_by(PoemID) |> 
  get_summary_stats(
    AdditionRate,
    type = "mean_sd"
  ) |>
  arrange(mean) |>
  slice(n():(n()-4)) |>
  select(PoemID, mean, sd)
create_kable_table(tab.5, cols.5)

# save tables
tab.fig.1 <- tab.1 |> ggtexttable(
  rows = NULL, 
  cols = cols.1,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = c(0, 1, 1, 1, 1, 1),
      x = c(.1, .9, .9, .9, .9, .9),
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 1, 1, 1, 1, 1), ncol = ncol(tab.1), nrow = nrow(tab.1), byrow = TRUE)),
      x = as.vector(matrix(c(.1, .9, .9, .9, .9, .9), ncol = ncol(tab.1), nrow = nrow(tab.1), byrow = TRUE)),
      ),
    )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle.2, face = "plain", size = 8, padding = unit(0.4, "line")) |>
  tab_add_title(text = main.title.2, face = "bold", size = 9, padding = unit(0.6, "line")) |>
  tab_add_hline(at.row = nrow(tab.1)+3, row.side = "bottom", linewidth = 3, linetype = 1)

tab.fig.2 <- tab.2 |> ggtexttable(
  rows = NULL, 
  cols = cols.2,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = c(0, 1, 1),
      x = c(.1, .9, .9),
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 1, 1), ncol = ncol(tab.2), nrow = nrow(tab.2), byrow = TRUE)),
      x = as.vector(matrix(c(.1, .9, .9), ncol = ncol(tab.2), nrow = nrow(tab.2), byrow = TRUE)),
      ),
    )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle.2, face = "plain", size = 8, padding = unit(0.4, "line")) |>
  tab_add_title(text = main.title.2, face = "bold", size = 9, padding = unit(0.6, "line")) |>
  tab_add_hline(at.row = nrow(tab.2)+3, row.side = "bottom", linewidth = 3, linetype = 1)

tab.fig.3 <- tab.3 |> ggtexttable(
  rows = NULL, 
  cols = cols.3,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = c(0, 1, 1),
      x = c(.1, .9, .9),
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 1, 1), ncol = ncol(tab.3), nrow = nrow(tab.3), byrow = TRUE)),
      x = as.vector(matrix(c(.1, .9, .9), ncol = ncol(tab.3), nrow = nrow(tab.3), byrow = TRUE)),
      ),
    )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle.3, face = "plain", size = 8, padding = unit(0.4, "line")) |>
  tab_add_title(text = main.title.3, face = "bold", size = 9, padding = unit(0.6, "line")) |>
  tab_add_hline(at.row = nrow(tab.3)+3, row.side = "bottom", linewidth = 3, linetype = 1)

tab.fig.4 <- tab.4 |> ggtexttable(
  rows = NULL, 
  cols = cols.4,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = c(0, 1, 1),
      x = c(.1, .9, .9),
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 1, 1), ncol = ncol(tab.4), nrow = nrow(tab.4), byrow = TRUE)),
      x = as.vector(matrix(c(.1, .9, .9), ncol = ncol(tab.4), nrow = nrow(tab.4), byrow = TRUE)),
      ),
    )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle.4, face = "plain", size = 8, padding = unit(0.4, "line")) |>
  tab_add_title(text = main.title.4, face = "bold", size = 9, padding = unit(0.6, "line")) |>
  tab_add_hline(at.row = nrow(tab.4)+3, row.side = "bottom", linewidth = 3, linetype = 1)

tab.fig.5 <- tab.5 |> ggtexttable(
  rows = NULL, 
  cols = cols.5,
  theme = ttheme(
    base_size = 8,
    colnames.style = colnames_style(
      fill = "white",
      hjust = c(0, 1, 1),
      x = c(.1, .9, .9),
      ),
    tbody.style = tbody_style(
      fill = "white",
      hjust = as.vector(matrix(c(0, 1, 1), ncol = ncol(tab.5), nrow = nrow(tab.5), byrow = TRUE)),
      x = as.vector(matrix(c(.1, .9, .9), ncol = ncol(tab.5), nrow = nrow(tab.5), byrow = TRUE)),
      ),
    )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>
  tab_add_title(text = subtitle.5, face = "plain", size = 8, padding = unit(0.4, "line")) |>
  tab_add_title(text = main.title.5, face = "bold", size = 9, padding = unit(0.6, "line")) |>
  tab_add_hline(at.row = nrow(tab.5)+3, row.side = "bottom", linewidth = 3, linetype = 1)

invisible(svg("figures/table-3-1.svg", width = 200 / 25.4, height = 40 / 25.4))
grid::grid.draw(tab.fig.1)
invisible(dev.off())

invisible(svg("figures/table-3-2.svg", width = 100 / 25.4, height = 60 / 25.4))
grid::grid.draw(tab.fig.2)
invisible(dev.off())

invisible(svg("figures/table-3-3.svg", width = 100 / 25.4, height = 60 / 25.4))
grid::grid.draw(tab.fig.3)
invisible(dev.off())

invisible(svg("figures/table-3-4.svg", width = 100 / 25.4, height = 65 / 25.4))
grid::grid.draw(tab.fig.4)
invisible(dev.off())

invisible(svg("figures/table-3-5.svg", width = 100 / 25.4, height = 65 / 25.4))
grid::grid.draw(tab.fig.5)
invisible(dev.off())
```

### 不一致率の高い対訳 {.unnumbered}

不一致率の高い歌の対訳において、10人の現代語訳に共通して欠落が見られたのは「序詞」「枕詞」「まわりくどい言い回し」の3種類であった。訳者の一部は、意識的に「序詞」や「枕詞」を訳さずに省略していることが観測された。例えば、@matsuda1968Shinshaku の現代語訳では、4首が原文よりも短くなっている。MTD (173) と MTD (665) の訳では、枕詞「ひさかたの」「みつしほの」が省略されている。MTD (684) および MTD (697) の訳においては、枕詞も序詞も省略されている。これらの歌は当然不一致率も高く、特に MTD (697) は原文よりも著しく短くなっている^[KSJ (404) もまた極端に短く、序詞が省略されている。]。MTD (697) では、大和の枕詞「敷島の」が省略されている。原文では「頃も」と「衣」が掛詞になっているが、その「衣」に掛かる序詞も省略されている。

![697番歌の @matsuda1968Shinshaku による現代語訳：アライメントの結果を書き換えている；「しきしまのやまとにはあらぬからころも」が省略されている。Contemporary translation of Poem #697 by @matsuda1968Shinshaku: The alignment has been revised; the *jokotoba* "Shikishima no Yamato ni wa aranu kara koromo" has been omitted.](./figures/matsuda-697.svg){#fig-mtd-697 width=100%}

```{python}
#| include: false

op697 = '''
01:000697:0001 A00 CH-JP-0000-00-0100 11 敷嶋 敷島 しきしま 敷島 しきしま
01:000697:0002 A00 BG-08-0061-07-0100 61 の の の の の
01:000697:0003 A00 BG-01-2590-01-0500 11 やまと 大和 やまと 大和 やまと
01:000697:0003 A10 CH-29-0000-00-2800 11 やまと 大和 やまと 大和 やまと
01:000697:0003 A20 CH-JP-0000-00-0300 11 やまと 大和 やまと 大和 やまと
01:000697:0004 A00 BG-08-0061-05-0100 61 に に に に に
01:000697:0005 A00 BG-08-0065-07-0100 65 は は は は は
01:000697:0006 A00 BG-02-1200-01-0102 47 あら 有り あり 有ら あら
01:000697:0007 A00 BG-03-1200-02-0800 74 ぬ ず ず ぬ ぬ
01:000697:0007 A10 BG-09-0010-01-0100 74 ぬ ず ず ぬ ぬ
01:000697:0008 B00 BG-01-4220-06-0800 02 唐衣 唐衣 からころも 唐衣 からころも
01:000697:0008 C00 BG-01-2590-02-0600 02 唐 唐 から 唐 から
01:000697:0008 C01 BG-01-4220-02-0200 02 衣 衣 ごろも 衣 ごろも
01:000697:0009 A00 BG-01-1610-01-0401 02 ころ 頃 ころ 頃 ころ
01:000697:0010 A00 BG-08-0065-08-0100 65 も も も も も
01:000697:0011 A00 BG-02-1600-01-0200 47 へ 経 ふ 経 へ
01:000697:0012 A00 BG-03-1200-02-0800 74 す ず ず ず ず
01:000697:0012 A10 BG-09-0010-01-0100 74 す ず ず ず ず
01:000697:0013 A00 BG-08-0064-38-0100 64 して して して して して
01:000697:0014 A00 BG-02-1556-01-0206 47 逢 逢ふ あふ 逢ふ あふ
01:000697:0014 A10 BG-02-3510-01-0100 47 逢 逢ふ あふ 逢ふ あふ
01:000697:0015 A00 BG-01-1020-02-0100 02 よし 由 よし 由 よし
01:000697:0015 A10 BG-01-3081-01-0800 02 よし 由 よし 由 よし
01:000697:0015 A20 BG-01-3081-04-1200 02 よし 由 よし 由 よし
01:000697:0016 A00 BG-03-1330-01-1400 69 もかな もがな もがな もがな もがな
01:000697:0016 A10 BG-03-3012-03-2700 69 もかな もがな もがな もがな もがな
01:000697:0016 A20 BG-08-0069-20-0100 69 もかな もがな もがな もがな もがな
'''
ct697 = '''
1 matsuda 0697 1 55 00 00 BG-03-1600-02-140-A 絶え間なく たえまなく 絶え間なく
1 matsuda 0697 3 55 00 00 BG-02-1240-04-010-A -- たえる 絶える
1 matsuda 0697 3 55 00 00 BG-01-1610-03-010-A -- ま 間
1 matsuda 0697 3 55 00 00 BG-09-0010-01-050-A -- ない ない
1 matsuda 0697 0 47 21 04 BG-02-1556-01-020-A 会い あう 会う
2 matsuda 0697 2 47 21 04 BG-02-3510-01-010-A 会い あう 会う
1 matsuda 0697 0 74 53 01 BG-03-3012-03-020-A たい たい たい
2 matsuda 0697 2 74 53 01 BG-09-0050-03-010-A たい たい たい
1 matsuda 0697 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0697 0 74 55 01 BG-09-0050-01-030-A だ だ だ
1 matsuda 0697 0 69 00 00 BG-04-3200-03-030-A なあ なあ なあ
2 matsuda 0697 2 69 00 00 BG-08-0069-11-040-A なあ なあ なあ
1 matsuda 0697 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op697, translation=ct697, mode=2, level=3)
```

```{bash}
#| include: false

awk '$1 ~ /01:000346/ && $2 ~ /[ABD]0/ {printf "%s", $5}' ./data/hachidaishu/hachidai.db
echo ""
awk -v translator="okumura" '$3 ~ /0346/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
```

```{python}
#| include: false

op346 = '''
01:000346:0001 A00 BG-01-2000-01-0102 14 わ 我 わ 我 わ
01:000346:0002 A00 BG-08-0061-02-0100 61 か が が が が
01:000346:0003 A00 BG-01-1911-03-0100 02 齢 齢 よはひ 齢 よはひ
01:000346:0004 A00 BG-01-2000-02-0300 14 君 君 きみ 君 きみ
01:000346:0005 A00 BG-08-0061-02-0100 61 か が が が が
01:000346:0006 B00 BG-03-1600-09-1500 02 やちよ 八千世 やちよ 八千世 やちよ
01:000346:0006 C00 BG-01-1950-04-0900 19 八千 八千 はっせん 八千 はっせん
01:000346:0006 C01 BG-01-2610-01-0400 02 世 世 よ 世 よ
01:000346:0007 A00 BG-08-0061-05-0100 61 に に に に に
01:000346:0008 A00 BG-02-1250-03-1100 47 とり 取る とる 取り とり
01:000346:0008 A10 BG-02-3061-04-0100 47 とり 取る とる 取り とり
01:000346:0008 A20 BG-02-3700-04-0100 47 とり 取る とる 取り とり
01:000346:0009 A00 BG-02-1556-05-0100 47 そへ 添ふ そふ 添へ そへ
01:000346:0009 A10 BG-02-1580-02-0700 47 そへ 添ふ そふ 添へ そへ
01:000346:0010 A00 BG-08-0064-16-0100 64 て て て て て
01:000346:0011 A00 BG-02-1240-01-1300 47 とゝめ 留む とどむ 留め とどめ
01:000346:0011 A10 BG-02-1512-01-0400 47 とゝめ 留む とどむ 留め とどめ
01:000346:0012 A00 BG-02-1515-03-0100 47 をき 置く おく 置き おき
01:000346:0013 A00 BG-09-0010-03-0100 74 て つ つ て て
01:000346:0014 A00 BG-08-0064-26-0100 64 は ば ば ば ば
01:000346:0015 A00 BG-02-3060-01-0101 47 思ひ 思ふ おもふ 思ひ おもひ
01:000346:0016 A00 BG-02-1210-01-0304 47 て 出づ いづ 出で いで
01:000346:0016 A10 BG-02-1530-01-0101 47 て 出づ いづ 出で いで
01:000346:0016 A20 BG-02-1540-04-0601 47 て 出づ いづ 出で いで
01:000346:0017 A00 BG-08-0061-05-0100 61 に に に に に
01:000346:0018 A00 BG-02-3420-01-0100 47 せよ す す せよ せよ
'''
ct346 = '''
1 okumura 0346 0 14 00 00 BG-01-2000-01-020-A 私 わたし 私
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 02 00 00 BG-01-5800-02-050-A 命数 めいすう 命数
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 14 00 00 BG-01-1730-03-030-A あなた あなた あなた
2 okumura 0346 2 14 00 00 BG-01-1731-02-030-A あなた あなた あなた
3 okumura 0346 2 14 00 00 BG-01-2000-02-010-A あなた あなた あなた
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 02 00 00 BG-01-5800-03-020-A 長寿 ちょうじゅ 長寿
1 okumura 0346 0 71 00 00 BG-08-0071-01-010-A の の の
1 okumura 0346 0 22 00 00 BG-01-1741-01-030-A 上 うえ 上
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 02 00 00 BG-03-1661-01-020-A さら さら さら
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 47 21 06 BG-02-1700-02-040-A 沿え そう 沿う
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 0 47 12 04 BG-02-1240-01-020-A 残し のこす 残す
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 0 48 08 04 BG-02-1515-03-010-A おき おく おく
1 okumura 0346 0 74 58 03 BG-09-0030-03-030-A ましょ ます ます
1 okumura 0346 0 74 70 01 BG-09-0010-02-010-A う う う
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 57 00 00 BG-03-1000-02-010-A その その その
1 okumura 0346 0 22 00 00 BG-01-1000-03-040-A 分 ぶん 分
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 43 00 00 BG-05-0070-01-010-A お お お
1 okumura 0346 0 47 06 04 BG-02-5810-04-010-A 生き いきる 生きる
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 47 17 01 BG-02-1220-01-030-A なる なる なる
1 okumura 0346 0 22 00 00 BG-01-5620-04-110-A とき とき とき
1 okumura 0346 0 61 00 00 BG-08-0061-05-010-A に に に
1 okumura 0346 0 65 00 00 BG-08-0065-07-010-A は は は
1 okumura 0346 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 okumura 0346 0 55 00 00 BG-04-3140-01-040-A どうぞ どうぞ どうぞ
1 okumura 0346 0 14 00 00 BG-01-2000-01-020-A 私 わたし 私
1 okumura 0346 0 61 00 00 BG-08-0061-10-010-A を を を
1 okumura 0346 0 47 12 04 BG-02-3050-03-070-A 思い出し おもいだす 思い出す
1 okumura 0346 0 64 00 00 BG-08-0064-16-010-A て て て
1 okumura 0346 1 48 19 09 BG-02-3770-05-030-A 下さい くださる 下さる
1 okumura 0346 2 48 19 09 BG-02-3770-05-020-A -- くれる くれる
1 okumura 0346 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op346, translation=ct346, mode=3, level=3, gap_penalty=0.01,u=10,g=20,e=50)
```

和歌と現代語訳の間に見られるまわりくどい表現の不一致は、翻訳における「欠落」というよりも、本稿の一致の探し方（アルゴリズムとして一対一で探索する）に課題があると言えるが、一例を挙げる。OKMR (#346) において、奥村の現代語訳は和歌の語をほとんど使用せず、あえて次のようにまわりくどい表現を用いている：

- 「とりそへて」=「さらにそえて」
- 「とどめおきて」=「のこしておきましょう」

特に整列法は、このような歌をうまくアライメントできなかった。

### 追加率の高い対訳 {.unnumbered}

MTD (#629) は追加率が高い訳のひとつである。この歌には「あやなし」「まだき」などの古語や、「なくに」のような現代語では使われない語法が含まれている。これらの語は、現代語と分類語彙表番号で対応づけることができなかった。また、「名の**たつ**」と「**たつ**たがは」の掛詞も存在する [@fig-mtd-629]。

追加率の平均値が上位の 10 首のうち、他にも 705 番歌、669 番歌、617 番歌など、追加率の高い和歌が含まれている。705 番歌には「身」と「雨」に「降（経）る」の掛詞が含まれている。669 番歌と 617 番歌には、それぞれ「海藻目」と「ながめ」の掛詞がある。掛詞を含む歌が典型的であった。

```{bash}
#| include: false
#| label: tatsuda-629

awk '$1 ~ /01:000629/ && $2 ~ /[ABD]0/ {printf "%s", $5}' ./data/hachidaishu/hachidai.db
echo ""
awk -v translator="matsuda" '$3 ~ /0629/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
```

![629 番歌の @matsuda1968Shinshaku による現代語訳：アライメントの結果を書き換えている Contemporary translation of Poem #629 by @matsuda1968Shinshaku: The alignment results have been modified.](./figures/matsuda-629.svg){#fig-mtd-629 width=100%}

```{python}
#| include: false

op629 = '''
01:000629:0001 A00 BG-01-3072-03-1100 51 あやなく 文無し あやなし 文無く あやなく
01:000629:0002 A00 BG-08-0064-16-0100 64 て て て て て
01:000629:0003 A00 BG-03-1660-03-1100 55 またき 夙 まだき 夙 まだき
01:000629:0004 B00 BG-01-3440-07-0700 02 なき名 無き名 なきな 無き名 なきな
01:000629:0004 C00 BG-03-1200-02-0100 51 無い 無い ない 無い ない
01:000629:0004 C01 BG-01-3102-02-0100 28 名 名 めい 名 めい
01:000629:0005 A00 BG-08-0061-07-0100 61 の の の の の
01:000629:0006 D00 CH-29-5250-01-0400 11 立田河 立田河 たつたがは 立田河 たつたがは
01:000629:0006 E00 CH-29-0000-00-1800 11 立田 立田 たつた 立田 たつた
01:000629:0006 E01 BG-08-0071-01-0100 71 の の の の の
01:000629:0006 E02 BG-01-5250-01-0100 02 川 川 かわ 川 かわ
01:000629:0007 A00 BG-02-1503-01-0201 47 わたら 渡る わたる 渡ら わたら
01:000629:0007 A10 BG-02-1521-04-0100 47 わたら 渡る わたる 渡ら わたら
01:000629:0007 A20 BG-02-1521-12-0100 47 わたら 渡る わたる 渡ら わたら
01:000629:0008 A00 BG-08-0064-17-0100 64 て で で で で
01:000629:0009 A00 BG-02-1502-03-0100 47 やま 止む やむ 止ま やま
01:000629:0010 A00 BG-03-3012-03-2600 74 ん む む む む
01:000629:0010 A10 BG-09-0010-02-0102 74 ん む む む む
01:000629:0011 A00 BG-01-1000-03-0201 02 物 物 もの 物 もの
01:000629:0011 A10 BG-01-4000-01-0800 02 物 物 もの 物 もの
01:000629:0012 A00 BG-09-0010-02-0700 74 なら なり なり なら なら
01:000629:0012 A10 BG-09-0050-01-0100 74 なら なり なり なら なら
01:000629:0013 A00 BG-03-1200-02-0800 74 な ず ず な な
01:000629:0013 A10 BG-09-0010-01-0100 74 な ず ず な な
01:000629:0014 A00 BG-08-0071-05-0100 71 く く く く く
01:000629:0015 A00 BG-08-0061-05-0100 61 に に に に に
'''
ct629 = '''
1 matsuda 0629 0 02 00 00 BG-01-1113-01-030-A わけ わけ わけ
2 matsuda 0629 2 02 00 00 BG-01-3070-01-030-A わけ わけ わけ
1 matsuda 0629 1 65 00 00 BG-08-0065-08-010-A も も も
1 matsuda 0629 2 65 00 00 BG-04-1130-01-200-A -- も も
1 matsuda 0629 0 51 50 07 BG-03-1200-02-010-A なく ない ない
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 55 00 00 BG-03-1650-03-010-A もう もう もう
2 matsuda 0629 2 55 00 00 BG-03-1992-07-030-A もう もう もう
1 matsuda 0629 0 02 00 00 BG-03-1010-02-060-A 無実 むじつ 無実
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 02 00 00 BG-01-3134-01-210-A 評判 ひょうばん 評判
2 matsuda 0629 2 02 00 00 BG-01-3142-02-010-A 評判 ひょうばん 評判
3 matsuda 0629 2 02 00 00 BG-01-3422-04-080-A 評判 ひょうばん 評判
1 matsuda 0629 0 61 00 00 BG-08-0061-02-010-A が が が
1 matsuda 0629 0 47 13 05 BG-02-1513-01-010-A 立っ たつ 立つ
2 matsuda 0629 2 47 13 05 BG-02-1521-06-020-A 立っ たつ 立つ
3 matsuda 0629 2 47 13 05 BG-02-3330-11-020-A 立っ たつ 立つ
4 matsuda 0629 2 47 13 05 BG-02-3391-02-110-A 立っ たつ 立つ
1 matsuda 0629 0 64 00 00 BG-08-0064-16-010-A て て て
1 matsuda 0629 0 48 21 05 BG-02-1502-02-040-A しまっ しまう しまう
2 matsuda 0629 2 48 21 05 BG-09-0010-03-050-A しまっ しまう しまう
1 matsuda 0629 0 74 54 01 BG-09-0010-04-010-A た た た
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 14 00 00 BG-01-1000-01-110-A いずれ いずれ いずれ
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 16 00 00 BG-01-1950-13-020-A 二人 ふたり 二人
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 17 00 00 BG-01-3020-11-030-A 恋 こい 恋
2 matsuda 0629 2 17 00 00 BG-02-3060-03-070-A 恋 こい 恋
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-3420-07-010-A 遂げ とげる 遂げる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-1200-02-010-A い いる いる
2 matsuda 0629 2 47 06 02 BG-02-1210-03-010-A い いる いる
3 matsuda 0629 2 47 06 02 BG-02-1530-07-010-A い いる いる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 17 01 BG-02-1200-01-010-A ある ある ある
1 matsuda 0629 0 64 00 00 BG-08-0064-04-010-A が が が
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 02 00 00 BG-01-1113-01-030-A わけ わけ わけ
2 matsuda 0629 2 02 00 00 BG-01-3070-01-030-A わけ わけ わけ
1 matsuda 0629 1 65 00 00 BG-08-0065-08-010-A も も も
1 matsuda 0629 2 65 00 00 BG-04-1130-01-200-A -- も も
1 matsuda 0629 0 51 50 07 BG-03-1200-02-010-A なく ない ない
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 55 00 00 BG-03-1650-03-010-A もう もう もう
2 matsuda 0629 2 55 00 00 BG-03-1992-07-030-A もう もう もう
1 matsuda 0629 0 02 00 00 BG-03-1010-02-060-A 無実 むじつ 無実
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 02 00 00 BG-01-3134-01-210-A 評判 ひょうばん 評判
2 matsuda 0629 2 02 00 00 BG-01-3142-02-010-A 評判 ひょうばん 評判
3 matsuda 0629 2 02 00 00 BG-01-3422-04-080-A 評判 ひょうばん 評判
1 matsuda 0629 0 61 00 00 BG-08-0061-02-010-A が が が
1 matsuda 0629 0 47 13 05 BG-02-1513-01-010-A 立っ たつ 立つ
2 matsuda 0629 2 47 13 05 BG-02-1521-06-020-A 立っ たつ 立つ
3 matsuda 0629 2 47 13 05 BG-02-3330-11-020-A 立っ たつ 立つ
4 matsuda 0629 2 47 13 05 BG-02-3391-02-110-A 立っ たつ 立つ
1 matsuda 0629 0 64 00 00 BG-08-0064-16-010-A て て て
1 matsuda 0629 0 48 21 05 BG-02-1502-02-040-A しまっ しまう しまう
2 matsuda 0629 2 48 21 05 BG-09-0010-03-050-A しまっ しまう しまう
1 matsuda 0629 0 74 54 01 BG-09-0010-04-010-A た た た
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
1 matsuda 0629 0 14 00 00 BG-01-1000-01-110-A いずれ いずれ いずれ
1 matsuda 0629 0 79 00 00 BG-16-0079-01-010-A 、 、 、
1 matsuda 0629 0 16 00 00 BG-01-1950-13-020-A 二人 ふたり 二人
1 matsuda 0629 0 71 00 00 BG-08-0071-01-010-A の の の
1 matsuda 0629 0 17 00 00 BG-01-3020-11-030-A 恋 こい 恋
2 matsuda 0629 2 17 00 00 BG-02-3060-03-070-A 恋 こい 恋
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-3420-07-010-A 遂げ とげる 遂げる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 06 02 BG-02-1200-02-010-A い いる いる
2 matsuda 0629 2 47 06 02 BG-02-1210-03-010-A い いる いる
3 matsuda 0629 2 47 06 02 BG-02-1530-07-010-A い いる いる
1 matsuda 0629 0 49 06 02 BG-02-1110-02-020-A られ られる られる
1 matsuda 0629 1 74 52 01 BG-09-0010-01-050-A ない ない ない
1 matsuda 0629 2 74 52 01 BG-03-1200-02-010-A -- ない ない
1 matsuda 0629 0 21 00 00 BG-01-1000-03-010-A もの もの もの
1 matsuda 0629 0 74 55 04 BG-09-0050-01-030-A で だ だ
1 matsuda 0629 0 65 00 00 BG-08-0065-07-010-A は は は
1 matsuda 0629 0 47 17 01 BG-02-1200-01-010-A ある ある ある
1 matsuda 0629 0 64 00 00 BG-08-0064-04-010-A が が が
1 matsuda 0629 0 78 00 00 BG-16-0078-01-010-A 。 。 。
'''

pipe(poem=op629, translation=ct629, mode=2, level=3)
```

## 翻訳アプローチによる追加率の差

本節では、統計モデリングを用いて翻訳アプローチによる追加率の差を検証する。モデルが推定した効果のいずれの $\hat{R}$ も 1 であり、1.1 を下回って収束が良好であることが示された [@Brooks1998General]。検証対象の効果について、ESS はすべて 2000 程度に達した。

```{r}
#| label: posterier-data
#| messge: false
#| warning: false

set.seed(123)

pred_addition_rate <- model |> 
  epred_draws(
    newdata = tibble(
      Focus = c(
       'Text-focused', 
       'Poet-focused',
       'Reader-focused',
       'Others'
      ),
      PoemID = NA,
      Translator = NA
    )
  ) |>
  mutate(
    Focus = factor(
      Focus,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    )
  )

pred_focus_annotation <- pred_addition_rate |>
  median_hdi(.epred, .width = 0.95) |> 
  mutate_if(is.numeric, round, digits = 2) |>
  mutate(median = paste0(
    "$",
    .epred*100,
    "\\%$"
    )
  ) |>
  mutate(annotation = paste0(
    .epred, 
    "*'%; '*",
    .width * 100,
    "*'% CrI ['*", 
    .lower, 
    "*', '*",
    .upper, 
    "*']'", 
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$\\mathrm{posterior\\; median} = ",
    .epred, 
    "\\%; ",
    .width * 100,
    "\\%\\;\\mathrm{CrI} = [", 
    .lower, 
    ", ",
    .upper, 
    "]$", 
    sep = ""
    )
  ) |>
  select(Focus,annotation, description, median)

pred_addition_rate_diff <- pred_addition_rate |> 
  compare_levels(
    variable = .epred, 
    by = Focus
  ) |>
  mutate(
    Focus = factor(
      Focus,
      levels = c(
        "Poet-focused - Text-focused",
        "Reader-focused - Poet-focused",
        "Reader-focused - Text-focused",
        "Others - Poet-focused",
        "Others - Reader-focused",
        "Others - Text-focused"
      )
    )
  )

pred_diff_CrI_annotation <- pred_addition_rate_diff |>
  median_hdi(.width = 0.95) |> 
  mutate_if(is.numeric, round, digits = 2) |>
  mutate(median = paste0(
    "$",
    .epred*100,
    "\\%$"
    ) 
  ) |>
  mutate(annotation = paste0(
    "Delta==",
    .epred, 
    "*'%; '*",
    .width * 100,
    "*'% CrI ['*", 
    .lower,  
    "*', '*",
    .upper, 
    "*']'", 
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$\\mathrm{posterior\\; median} = ",
    .epred, 
    "\\%; ",
    .width * 100,
    "\\%\\;\\mathrm{CrI} = [", 
    .lower, 
    ", ",
    .upper, 
    "]$", 
    sep = ""
    )
  ) |>
  select(Focus, annotation, description, median)

pred_diff_prob_g_0_annotation <- pred_addition_rate_diff |>
  group_by(Focus) |>
  summarise(
    prob_g_0 = mean(.epred > 0) * 100
  ) |>
  mutate_if(is.numeric, round, digits = 1) |>
  mutate(annotation = paste0(
    "italic(P)(Delta>0)==", 
    prob_g_0,
    "*'%'",
    sep = ""
    )
  ) |>
  mutate(description = paste0(
    "$P(\\Delta>0) = ",
    prob_g_0,
    "\\%$",
    sep = ""
    )
  ) |>
  select(Focus, annotation, description, prob_g_0)
```

### 翻訳アプローチによる追加率の相違が小さい {.unnumbered}

@fig-poster は翻訳アプローチごとの追加率の事後分布を示している。この図から以下の情報が得られた。

(a) 追加率は、翻訳アプローチにかかわらず、現代語訳の要素の約 50% が追加的な要素であることがわかった。この点は観測データからも確認されている。

(b) 翻訳アプローチグループ間で比較した結果、2 グループ間の差の事後分布の 95% CrI はすべて 0 を含んでおり、それぞれの 2 グループの追加率に有意な差は認められなかった。傾向としては、`Reader-focused` 群の追加率に比べ、`Other` 群の追加率が `{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(median) |> I()` 程度下回った (`{r} pred_diff_CrI_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Others - Reader-focused") |> pull(description) |> I()`)。また、`Reader-focused` 群の追加率は `Poet-focused` 群よりも `{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(median) |> I()` 程度下回った (`{r} pred_diff_CrI_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`, `{r} pred_diff_prob_g_0_annotation |> filter(Focus == "Reader-focused - Poet-focused") |> pull(description) |> I()`) ことが観測されているが、傾向差の基準には達しなかった。

```{r}
#| label: fig-poster
#| fig-scap: 追加率の事後分布
#| fig-cap: 追加率の事後分布 Posterior distribution of addition rates
#| fig-subcap: 
#|   - "各翻訳アプローチの追加率の事後分布 Posterior distribution of addition rates for each translation approach"
#|   - "翻訳アプローチによる追加率の差の事後分布 Posterior distribution of differences in addition rates by translation approach"
#| messge: false
#| warning: false
#| laylayout-nrow: 2
##| layout: [[61, 27]]

pred_addition_rate |>
  ggplot(aes(x = .epred, y = Focus)) + 
  stat_slab(
    aes(
      fill = Focus,
      fill_ramp = after_stat(
        cut_cdf_qi(cdf, .width = c(0.02, 0.8, 0.95, 1))
        )
      ),
    # height = 4,
    color = "white",
    slab_size = 0.05,
  ) + 
  stat_pointinterval(
    .width = c(.95, .8, .2)
  ) + 
  scale_fill_okabe_ito(order = c(1, 6, 3, 2), guide = "none") +
  scale_fill_ramp_discrete(range = c(1, 0.2), guide = "none") +
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(0, 0.25, 0.5, 0.75, 1),
    limits = c(-0.4, 0.85)
    ) +  
  labs(
    x = "Estimated Addition Rate",
    y = "Focus",
    caption = "Posterior medians are shown with points\n 80% and 95% credible intervals (HDI) are shown with inner, outer intervals and shading"
  ) +
  annotate(
    geom="text",
    x =-0.4, y = c(levels(pred_addition_rate$Focus)),
    color = palette_okabe_ito(order=c(1, 6, 3, 2)),
    # color = "black",
    vjust = -0.2,
    hjust = 0,
    size = 5,
    label = pred_focus_annotation$annotation,
    parse = TRUE
  ) + 
  geom_vline(
    xintercept = 0.5, 
    color = palette_okabe_ito(9), 
    linetype="dashed",
    linewidth = 1
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.title.y = element_blank()
  )

pred_addition_rate_diff  |>
  separate(
    Focus, 
    into = c("FocusA", "FocusB"), 
    sep = " - ",
    remove = FALSE
  ) |>
  mutate(
    FocusA = factor(
      FocusA,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    ),
    FocusB = factor(
      FocusB,
      levels = c(
        "Text-focused", 
        "Poet-focused", 
        "Reader-focused", 
        "Others"
      )
    )
  ) |>
  ggplot(
    aes(
      x = .epred, y = Focus
    )
  ) + 
  stat_halfeye(
    aes(
      fill = FocusA, 
      fill_ramp = stat(x < 0)
    )
  ) +
  stat_pointinterval(
    .width = c(.95, .8, .2)
  ) + 
  scale_fill_okabe_ito(order = c(6, 3, 2)) +
  scale_fill_ramp_discrete(
    from = "grey95",
    range = c(1, 0), guide = "none") +
  scale_x_continuous(
    labels = label_percent(),
    breaks = c(-0.25, 0, 0.25, 0.5, 0.75),
    limits = c(-0.6, .4)
    )+  
  labs(
    x = "Estimated Addition Rate Differences",
    y = "Focus",
    caption = "Posterior medians are shown with points\n 80% and 95% credible intervals (HDI) are shown with inner and outer intervals",
    fill = "Base Translation Focus"
  ) +
  annotate(
    geom="text",
    x = -0.05, y = c(levels(pred_addition_rate_diff$Focus)),
    # color = palette_okabe_ito(order=c(1, 6, 3, 2)),
    # color = "black",
    vjust = -0.1,
    hjust = 1,
    size = 3,
    label = pred_diff_CrI_annotation$annotation,
    parse = TRUE
  ) + 
  annotate(
    geom="text",
    x = 0.1, y = c(levels(pred_addition_rate_diff$Focus)),
    color = palette_okabe_ito(order=c(6, 3, 3, 2, 2, 2)),
    # color = "black",
    vjust = -0.1,
    hjust = 0,
    size = 3,
    label = pred_diff_prob_g_0_annotation$annotation,
    parse = TRUE
  ) + 
  geom_vline(
    xintercept = 0, 
    color = palette_okabe_ito(9), 
    linetype="dashed",
    linewidth = 1
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 0.5
    ),
    axis.title.y = element_blank()
  ) +
  guides(fill = guide_legend(nrow = 3)) 
```

### 訳者による追加率の変動より歌による変動のほうが大きい {.unnumbered}

階層モデリングにおいて、訳者と歌をランダム切片としてモデル化している。訳者グループと歌グループがそれぞれ共有していると仮定した正規分布のパラメータである標準偏差の事後分布を可視化した [@fig-hyperparameter]。訳者グループの標準偏差の分布は、歌グループの標準偏差の分布よりも左寄りであった。これは、訳者間の変動よりも歌間の変動のほうが大きいことを示している。つまり、ランダム効果の視点から見ると、歌が訳者に比べて追加率の変動により大きく寄与していると考えられる。

```{r}
#| label: fig-hyperparameter
#| fig-scap: グループレベルのハイパーパラメータの事後分布
#| fig-cap: グループレベルのハイパーパラメータの事後分布 Posterior distribution of group-level hyperparameters
#| warning: false
#| message: false

post <- model |> 
  as_draws_df() |>
  select(starts_with("sd")) |>
  select(-contains("pattern"))

group_labels <- c(
  "sd_PoemID__a_Intercept" = "Poem",
  "sd_Translator__a_Intercept" = "Translator"
  )

post |>
  pivot_longer(sd_PoemID__a_Intercept:sd_Translator__a_Intercept) |> 
  mutate(name = factor(name)) |>
  ggplot(aes(x = value, fill = name)) +
  geom_density(linewidth = 0, alpha = 3/4, adjust = 2/3, show.legend = F) +
  annotate(
    geom = "text", 
    x = 0.28, y = 20, 
    label = expression(sigma["Poem"]),
    color = palette_okabe_ito(7)
  ) +
  annotate(
    geom = "text", 
    x = 0.1, y = 10, 
    label = expression(sigma["Translator"]), 
    color = palette_okabe_ito(5)
  ) +
  scale_fill_okabe_ito(order = c(7, 5), guide = "none") + 
  scale_x_continuous(
    breaks = c(0.1, 0.2, 0.3),
    limits = c(0, .4)
    )+  
  scale_y_continuous(NULL, breaks = NULL) +
  labs(
    x = expression("Group hyperparameter"~sigma~"value"),
    y = "Group",
  ) +
  theme_set_b() +
  theme(
    axis.text.x = element_text(
      angle = 0, 
      hjust = 0.5, 
      vjust = 1
    ),
    axis.title.y = element_blank(),
    panel.grid.major.x = element_line(
      color = "gray80",
      linetype = "solid"
    )
  )
```

## 298 番「立田」歌の訳の事例分析

```{bash}
#| include: false
 
echo 'Original poem:'
grep 01:000298 ./data/hachidaishu/hachidai.db |\
  awk '$2 ~ /^[ABD]0/ {printf "%s", $5}'
echo ""

echo 'Contemporary translations:'
translators=("katagiri" "kubota" "matsuda" "okumura" "takeoka" "kaneko" "kojimaarai" "komachiya" "kyusojin" "ozawa")

for translator in "${translators[@]}"
do
    echo -n "$translator: "
    awk -v translator="$translator" '$3 ~ /0298/ && $0 ~ translator && $1 ~ /1/ && $4 ~ /[01]/ {printf "%s", $9}' ./data/translationExamples.txt
    echo ""
done
```

298 番「立田」の歌についての事例分析は、アライメントを示しながら進める。

298 番歌の不一致率および翻訳における追加率のまとめは、@tbl-tatsuta-review に示している。ここでの計算は整列法の結果に基づいている。歌のトークン数 19 のうち、アライメントで一致する 2 語対の数が OZW を除いて 14 を超えた。OZW は文の入れ替えを行っているため、アライメントがうまく行われなかった。原文の要素の不一致率は低い水準に保たれており、訳における追加率は OZW を除くと 50% から 70% となっていた。1 語あたり 1.5 から 1.7 語で訳されていた。アライメントはプログラムの出力を修正した上で @fig-alignment に整理している。修正前の出力については補足資料を参照されたい。さて、どのような追加要素があるか確認していく。

```{R}
#| label: tbl-tatsuta-review
#| tbl-cap: 「立田」歌 298 番の現代語訳の不一致率・追加率の概要 Summary of unmatch and addition rates in contemporary translations of "Tatsuta" Poem #298

main.title <- "「立田」歌 298 番の現代語訳の不一致率・追加率の概要"
subtitle <- "Summary of unmatch and addition rates in contemporary translations\nof \"Tatsuta\" Poem #298"
cols <- c("訳者\nTranslator", "歌番\nPoem ID", "計算手法\nMethod", "一致数\nAgreement Count", "不一致率\nUnmatch Rate", "追加率\nAddition Rate")
tatsuta_data <- read.csv("artifacts/calc_results.csv") |> filter(PoemID==298) |>
  mutate(
    UnmatchRate_a = round(UnmatchRate_a, 3),
    AdditionRate_a = round(AdditionRate_a, 3),
    Translator = translator_labels[Translator],
    PoemID = as.character(PoemID),
    Method = "Alignment" 
  ) |>
  select(Translator, PoemID, Method, TotalMatch_a, UnmatchRate_a, AdditionRate_a)

tab <- tatsuta_data |> ggtexttable(
    rows = NULL, 
    cols = cols,
    theme = ttheme(
      base_size = 5,
      colnames.style = colnames_style(
        fill = "white",
        hjust = c(0, 0, 0, 1, 1, 1),
        x = c(.1, .1, .1, .9, .9, .9),
        ),
      tbody.style = tbody_style(
        fill = "white",
        hjust = as.vector(matrix(c(0, 0, 0, 1, 1, 1), ncol = 6, nrow = nrow(tatsuta_data), byrow = TRUE)),
        x = as.vector(matrix(c(.1, .1, .1, .9, .9, .9), ncol = 6, nrow = nrow(tatsuta_data), byrow = TRUE)),
        ),
      )
  ) |>
  tab_add_hline(at.row = c(1, 2), row.side = "top", linewidth = 3, linetype = 1) |>  
  tab_add_title(text = subtitle, face = "plain", size = 14) |>
  tab_add_title(text = main.title, face = "bold", size = 16, padding = unit(0.5, "line")) |>
  tab_add_hline(at.row = 13, row.side = "bottom", linewidth = 3, linetype = 1)

# Save the table as an SVG file with a specified width of 200mm
invisible(svg("figures/table-4.svg", width = 200 / 25.4, height = 125 / 25.4))
grid::grid.draw(tab)
invisible(dev.off())

# Output
create_kable_table(tatsuta_data, cols)
```

::: {#fig-alignment layout-nrow=2}

![アライメント（前半）：たつたひめ 手向ける神の あればこそ Alignment (first half): Tatsutahime tamukeru kami no areba koso '(There is) the god exits for Tatsutahime to dedicate (things), so that ...'](./figures/tatsuta-1.svg){#fig-alignment-1 width=100%}

![アライメント（後半）：秋の木の葉の 幣と散るらめ Alignment (second half): aki no konoha no nusa to chiru rame 'leaves of autumn may be scattered as ritual clothes (which is dedicated to the god)'](./figures/tatsuta-2.svg){#fig-alignment-2 width=100%}

10人の訳者のアライメント（筆者がアライメント推定プログロムの出力を修正して作成）：「【】」は追加と判断する要素である；「（）」は言い換えと判断する要素である。「＊」は、句の順序の入れ替えで対応しうる文・語である。「・」は直訳されていないと判断する要素のプレースホルダーである。 Alignment of translations by 10 translators (the author corrected the output of the alignment estimation program): Elements in "【】" are judged as additions, those in "（ ）" are considered paraphrases, "＊" indicates phrases or words aligned through sentence reordering, and "・" represents elements judged not to be translated directly.

:::

#### 共出現語の訳出 {.unnumbered}

「立田」に関連するコーパスレベルの共出現語として、「山」「川」「紅葉づ」「姫」「手向く」「紅葉葉」「神無備」「秋」「幣」「散る」などが頻出する。298 番歌は、典型的な「立田」の歌として「姫」「手向く」「幣」「秋」を含んでおり、これらの語のほとんどがそのまま訳出されている。298 番歌には出現しない「紅葉葉」や「紅葉づ」は、「木の葉」を通じて暗示され、以下のように訳出されている：

- 紅葉した葉 [MTD]
- 木の葉のもみじ [K&A]
- 紅葉 [KSJ, OZW, OKMR]

一方、KBT、TKOK、KNK、KMCY、KTGR は「このは」についての処理を行わなかった。

また、コーパスレベルの共出現語である「幣」については、以下のような追加が見られた：

- 【色とりどりの】幣 [OZW]
- 【手向けの】幣 [KNK]
- 幣【を撒く】（ように）散（っている） [KTGR]

ただし、これらの追加が「立田」に帰属するべきかの判断は難しく、「幣」を介して間接的に情報を示すものと考えられる。

基本的に、コーパスレベルにおける「立田」の共出現要素の処理は、そのまま残す方針か、他の要素よりも多く追加する方針のいずれかとなっていることが伺える。また、「このは」のような共出現語ではない要素についても、全体的なコロケーションを考慮して「紅葉」として訳出されるケースが見られた。訳出の方針は、訳者にかかわらず安定的な翻訳が行われている。

訳と原文の差分から、コーパスレベルの共出現語に関連する重要な情報が見えてくると推測できる。

#### 構文パターンの訳出 {.unnumbered}

共出現する構文パターンとして、終止形で終わる歌の少なさ（古今集の12首のうち1首のみ）が観測されている。特に、古今集では12首中9首が係り結びを用いている。これらの文の終わり方などの構文パターンについて、298番歌の訳における処理を分析した。

298番歌の係り結びは、強意の「こそ」と推量の「らむ」の活用形「らめ」で構成されていた。その訳として、10人の訳者のうち7人が「こそ」を残しており、さらに9人が文末において「強調」の「ノ [であろう・でしょう]」構文を使用している。推量の「らむ」についても、9人が「だろう・でしょう」と訳している。唯一「だろう」で訳していない OZW は「だな」という詠嘆的な口調で訳している。KBT と K&A は文末にそれぞれ「よ」と「ね」の終助詞を追加している。

これらの構文パターンの訳出は、非常にロバストであることが確認できた。他の係り結びを使わない「立田」の歌の翻訳においても、この構文パターンが干渉して追加されているかを確認したが、該当する事例は見られなかった。つまり、特徴的な共出現の構文パターンの処理は、少なくとも「立田」の場合においては直訳に留まっている。

その他の文法的な要素として、格助詞の「と」や動詞の基本形式「-u」（例えば「なる」）の訳は、コーパスレベルにおいては「立田」の特徴的な共出現要素ではないが、分析を行った。その結果、以下のように多様な訳し方が確認された。

[...幣]「**と**」：

- [...幣を撒く|幣の]**ように** [KTGR, KBT, MTD, OKMR, KNK]
- [...幣|手向けもの]**として** [TKOK, K&A]
- [...幣]**となって** [KMCY, KSJ, OZW]

[...散]「**る**」

- [...散っ]**ている** [KTGR, MTD, OKMR, TKOK, KMCY, KSJ, OZW]
- [...散]**る** [KBT, KNK, K&A]

[...手向け]「**る**」

- [...手向けを]**する** [KTGR, K&A, KMCY]
- [...供え物をささげ|手向け]**る** [MTD, TKOK]
- [...手向けを|お手向け]**なさる** [OKMR, KNK]
- [...手向けを]**するべき** [KBT]
- [...手向け]**られる** [KSJ]
- [...それを供え]**ていらっしゃる** [OZW]

このように、コーパスレベルの共出現構文要素でないものの訳出において、追加や言い換えの揺れが大きかった。動詞フレーズの訳し方の揺れについては、理論よりも訳し方の揺れが大きいことが報告されている [@Yamamoto2023Development]。これらの追加要素や言い換えは、古語と現代語の言語変化や変異に由来していると考えられる。分類語彙表番号によって一致と認定できず、現代語訳と原文の差分として抽出されるが、ノンリテラル情報とは言い難い。

#### 共出現語の意味傾向の訳出 {.unnumbered}

「立田」のコーパスレベルでの共出現語の傾向としては、「立田川」「立田（の）山」など地名を構成する「山・川」のグループと、秋の「神」に関連する関連語のグループに属していることがあげられる。秋・紅葉が有名な神聖な場所の歌枕として使われている性質が伺える。この傾向が298番歌でどのように明確にされているかについては、やはり直接な追加がなかった。ただし、間接的な現象として、10人の訳者による訳の中で「立田姫」や「神」の周辺に追加要素が集中して出現していることが確認された。

「立田姫」に関する要素の追加は、10人のうち7人が行っている：

- 【秋をつかさどる】龍田姫【が旅立ちにあたって】 [KTGR]
- 【秋も終りに近づき秋の女神の】龍田姫【がお帰りになる】 [OKMR]
- 竜田姫【が旅にあって】 [TKOK]
- 立田姫【は秋の神だが】 [KNK]
- 【帰り道についた】龍田姫【が道中の無事を願って】 [KMCY]
- 【秋も終りに近づき】竜田姫【がお帰りになる際に】 [KSJ]
- 【もはや秋の終りで】龍田姫【が帰り道にお着きになった】 [OZW]

KBT、MTD、K&A の訳には「立田姫」に関する追加要素は見られなかった。

「手向ける神」の文脈に関連する追加要素は、5人の訳から観測された：

- 【旅中】（供え物をささげる）【道祖】神 [MTD]
- 【姫が道中の安全を祈って】手向け（をなさる）神 [OKMR]
- 【それすら暮れて行かれる折には】【お】手向け（なさる）【道の】神【様】 [KNK]
- 【旅の安全を祈って】手向け（られる）神 [KSJ]
- 【道の】（神様）【にそれを】（供えていらっしゃる）＊ [OZW]

K&A、KMCY、KTGR、KBT、TKOK の訳では、要素の追加は見られなかった。「立田姫」や「手向ける神」に関する情報は、他の要素よりも重点的に補足されている。「立田姫」が「秋の神」や秋の擬人化であり、立田姫の「手向け」の目的が「旅の安全」であること、手向けの対象が道の神、旅の神、道祖神であるといった情報が、現代語訳と原文の差分から補足されることがわかった。

# 考察 {#sec-discussion}

## 追加率からみる翻訳アプローチと翻訳実践とのずれ

現代語訳における追加率の階層モデリングの結果、いずれの翻訳アプローチにおいても、相当な割合で追加要素が含まれていた。また、訳者間の変動よりも、歌による変動のほうが大きかった。これらの注釈書では、多くの語の解釈がすでに注釈によって詳しく説明されているにもかかわらず、追加率が低いわけではなかった。訳者が翻訳アプローチとしてテキストを重視するにせよ、作者の意図を重視するにせよ、読者の読みやすさを重視するにせよ、基本的に追加せざるをえない要素が存在すると推測できる。

ただし、追加要素の中で、それぞれの訳を具体的に確認すると、OZW が語順の入れ替えを許容したり、TKOK が作者の意図を重視したりする方針は確実にその実践に反映されている。個別の歌を精査することで明確な差が見えてくるものの、全体としてはその差は傾向の域を超えなかった。それらの要素は、翻訳アプローチや訳者の個人差に左右されない量として十分に存在している。また、追加率の平均値が高い上位 10 首の歌を観察したところ、掛詞を用いた歌が顕著であった。掛詞の役割を明確にするには、訳において補足が求められており、現代語と古代語の差分で多くの要素が残ると考えられる。現代語訳によるノンリテラル要素の可視化は、量的に実現可能である。

一方、歌と現代語訳の差分からノンリテラル情報を抽出する際、訳されていない語がないことが望ましく、これが不一致率の高い歌の調査につながった。その結果、翻訳の「欠落」の多くは序詞や枕詞、まわりくどい表現であることが明らかになった。現代語文と歌の差分では、枕詞や序詞に関するノンリテラル要素の抽出が難しいことがわかった。ただし、まわりくどい表現については、基本的に歌ことばとそのまわりくどい言い回しの一部が一致することが確認されたが、まわりくどい表現全体との一致は見られなかった。この問題は語の一致の課題として指摘されているが、最初に述べた一対多の訳と同様に、まわりくどい表現は元の歌ことばに情報を付加して生成されることが多い。そのため、まわりくどい表現で一致しない要素、つまり「訳のあまりもの」は、ノンリテラル要素を調べる上でむしろ貴重なものであるといえる。

## 翻訳における追加要素の類型化

ケーススタディーの分析に基づき、拡張意味単位からヒントを得た3つの観点で訳における追加要素について、以下の類型化を提案する。

翻訳における追加要素には、いくつかの異なるパターンが見られる。まず、コーパスレベルで共出現する語に由来する追加がある。例えば、「木の葉」という語に対して「木の葉の紅葉」といった直接的な要素を付け加えたり、「幣」に「色とりどり」「撒く」といった二次的な要素を補足したりする場合がこれに該当する。
次に、構文や文法の変化による追加が挙げられる。これは、例えば「と」のような助詞を複数の異なる訳し方で説明する場合や、「手向ける」という動詞の基本形を訳す際に、テンス・アスペクト・モダリティの明示化に該当する要素を付け加える場合がこれに含まれる。
さらに、コーパスレベルの共出現語が持つ意味群全体に対して追加が行われることもある。特に、「秋」や「神」といった語群に関する補足が必要とされる場合、例えば「立田姫」や「道祖神」のような情報を付け加えて、読者に背景知識を提供する。このような追加は、共出現語の意味や関連性を強調し、現代語訳で理解を深める役割を果たしている。

翻訳との差分に基づく可視化システムを構築する際に、これらの要素の区別が重要である。まず、「木の葉」に補足しての「紅葉」は、センテンスレベルではノンリテラルであるが、コーパスレベルではリテラルな共出現語であるといえる。差分による可視化でもアクセスできることが確認できたものの、その他の共出現分析に用いる指標でも十分抽出できる。そのため、差分による可視化の必要性は低くなる。次に、構文の時代変化のギャップを埋めるための追加要素は、原文の語に由来するノンリテラル情報とは捉えられないため、除外する手続きを踏まなければならない。そして、共出現の語の全体的傾向性に関連する追加要素は、おそらく共出現語分析では抽出できない。この点において、翻訳との差分による可視化は独自な利点を持つと考えられる。

最後に、本稿では触れなかった拡張意味単位の第4のレベルである談話韻律の視点について補足する。談話韻律に相当する感情面の評価と、語の社会言語学的な属性は、訳の追加要素では分からない情報と考えている。これらの属性を直接的な補足と追加で明示化することはない。一部は現代語にあるconnotative termで言い換えられており、これら機能が相当する語の入れ替えはあっても、その入れ替えは元の歌語の談話韻律の説明として直接は成立しない。よって、談話韻律に相当するノンリテラル要素の評価は他の方法を求めるべきである。

## 現代語訳の知識としての信憑性

10人の翻訳と原文の差分を可視化するシステムは、各訳者が個々の歌に対して持つ知見を総合し、メタ分析や要約として機能すると考えられる。しかし、現代語訳に含まれる知識が、歌ことばのノンリテラルな情報にどこまでアクセスできるか、また可視化としてどの程度の妥当性や信頼性を持つかについては、本稿では取り扱っていない。

翻訳において、過剰な意味付けは解釈の妥当性や整合性を損なう可能性がある。元のテキストが持つシンプルな意味や意図が、余計な意味付けによって曖昧になり、読者が正しく理解することを困難にするおそれがある。そのような翻訳を可視化に応用すると、可視化そのものの信憑性が損なわれる可能性があるため、慎重に考慮する必要がある。いかにして訳者の訳語から信頼性の高い部分を抽出するかが、翻訳に基づく可視化の重要な課題となる。

## 翻訳研究の知見による解釈の必要性

本研究は、翻訳研究自体を目的としているわけではないが、翻訳における要素の追加や原文における要素の喪失といった現象は、翻訳研究における仮説や理論に基づいて解釈する余地が十分にあると考えられる。

例えば、翻訳普遍性仮説（translation universal hypothesis）における「長さの増加の普遍性」（law of lengthening）や「明示化の普遍性」（law of explicitation）は、現代語訳における追加要素の存在を説明する際に有効である[@Chesterman2004Hypotheses; @Edina2016Translation; @Vinay1958Comparative; @Baker1996Challenges; @Blum-Kulka1986Shifts]。これらの仮説に基づけば、現代語訳における追加要素は、翻訳における普遍的な現象であり、特に明示化の普遍性は本稿で言うノンリテラル要素の追加と深く関係している。翻訳における明示化について、@Blum-Kulka1986Shifts は、翻訳者がソーステキストにはない cohesive marker^[@Nunan1993Introducing [p. 21] によると、cohesive marker とは、書き手や話し手が文や発話の境界を越えて関係を確立し、テキスト内の文を結びつけるのに役立つ語やフレーズのことを指す。例えば、「そして」「しかし」「それ」などが含まれる。]をターゲットテキストに追加する傾向を指摘している。一方で、@Baker1996Challenges [p. 180] は、明示化の概念を、物事を暗黙的に残さずに明確に説明する傾向としてより広く捉えている。このような「明示化」はもともと談話標識や cohesive marker の訳文における増加傾向を指しており、本研究における要素の追加の一部はこの理論から説明できる。ただし、談話標識や cohesive marker の追加を取り除いた場合でも、分析事例において多くの追加要素が確認された。このように、すべての現象をこの仮説で解釈することは難しいが、知見として重要である。^[実際、翻訳普遍性仮説には反例も存在し、確率的な傾向として捉えられることが妥当であるとされている[@Pym2008Tourys; @Tymoczko1998Computerized; @Chesterman2004Hypotheses; @Chesterman2010Why]]

また、翻訳の認知的側面に関連する仮説として、「リテラル翻訳仮説」（literal translation hypothesis）も検討に値する。この仮説では、翻訳者がテキストを処理する際、まずリテラルな（逐語的な）訳を基にし、そこから自由な表現に向かう傾向があるとされる[@Chesterman2011Reflections]。この仮説に基づいて、認知処理と認知負荷の観点からリテラル翻訳の度合いを測定するための指標が提案されており[@Carl2017Measuring]、例えば、1) 原文と訳文の語順の類似性、2) 可能な異なる翻訳表現の数、などが挙げられる。これらの指標は本稿で言及するテキストの追加率や不一致率とは異なる視点を提供するが、特に2点目はノンリテラル要素の可視化に関連する可能性があり、今後の研究課題として検討する価値がある。

さらに、翻訳研究における「一致の単位」に関する問題も重要である。従来の翻訳研究では、翻訳等価性（translation equivalence）や翻訳単位（translation unit）に関する議論が多く行われてきた[@Nida1969Theory; @Koller1979Einfuehrung; @Malmkjaer2008Unit]。これらの視点から、翻訳における分析単位がどのように影響するかについての考察が必要である。

## 方法論の改善余地

本稿での一致率の計算は完全にルールベースの手法に基づいており、一貫性と簡素さの面では優れた方法であると考えられる。しかし、整列法（アライメント）については、動的計画法を用いたアライメントに課題が残る。古語と現代語の間では、一方が低リソース言語であることから、ニューラルネットワークを用いた手法や手動によるアライメントも検討する必要がある。例えば、@Palladino2022Using および @Camilleri2024Evaluating が提案する `Ugarit` プラットフォームを活用したアライメント手法では、一対多の対応関係の分析や、訳出パターンの共通点と分岐点、非対応の品詞情報の分析など、より精緻なコントロールが可能になると期待される。

## 分類語彙表番号の応用研究として

本稿における（不）一致率および追加率の計算では、言語処理のアライメントモデルではなく、安定した分類番号を用いた。特に、バッグ法は、句や語の入れ替えに依存せず、意味の一致を検出する上で有効であった。意味の分類体系が、同じ意味を持つ語を階層的に対応づけることの有用性は、古語研究においても再確認された。本研究では、旧分類語彙表番号を使用しているが、近年は @Asahara2022CHJWLSP によって、古語に対して新たな分類語彙番号が付与されており、これによって研究の可能性がさらに広がることが期待される。ただし、分類語彙表番号は2024年現在、概念レベルまでの対応であり、類義語、同義語、同語異表記などのメタコードや識別子としての一致検出にはまだ対応していない。そのため、研究者各自が研究の目標に合わせて適切にアダプテーションを行う必要がある。本稿で採用している意味付与の方法も、さらなる修正が求められる。この点において、意味体系の構築方法について、今後の検討の余地があると考えている。

<!-- ## 翻訳一般性仮説の観点から見る現代語訳の操作 -->

<!-- 翻訳における言い換え、追加、省略について、翻訳研究の観点からしばしば、翻訳一般性（普遍性）の仮説で解釈されている。@Chesterman2004Hypotheses と @Edina2016Translation に基づいて、翻訳において潜在的にかかわりうる翻訳一般性を以下に整理している： -->

<!-- - 単純化 (cf. law of simplication)：ソース言語の言語面、あるいは、情報面の翻訳における単純化 [@Baker1996Challenges] -->
<!-- - 標準化・慣習化 (cf. law of standardization / conventionalization)^[その逆として、ソース干渉の定理 (law of interference) が提起されている。それは、翻訳において外国語・外国文化を翻訳において伝わるようにする傾向を指す [@Tully2014Translation, p. 295]。] -->
<!--   - ソース言語の外国的特徴 (foreign feature) をターゲット言語のの文化へと修正し [@Tully2014Translation, p. 295]、 -->
<!--   - 翻訳のプロセスにおいてターゲット言語における典型的なパターンを踏襲し、ないしはそれを強調する [@Baker1993Corpus，p. 176] -->
<!--   - ソーステキストのテーマがターゲットテキストのレパートリーに変換される傾向がある [@Toury1995Descriptive, p. 268]  -->
<!-- - 長さ増加の定理 (law of lenghtening)：ターゲットテキストのがソーステキストより長い傾向 [@Vinay1958Comparative] -->
<!-- - 明示化の定理 (law of expicitation)：@Blum-Kulka1986Shifts では、翻訳者がソーステキストにはない Cohensive marker^[According to @Nunan1993Introducing [p. 21], cohensive markers are “words and phrases which enable the writer or speaker to establish relationship across sentence or utterance boundaries, and which help to tie the sentences in a text together”.] をターゲットテキストで示すことが示唆されている。@Baker1996Challenges [p. 180] は、この問題を「翻訳では『物事を暗黙的なままにしておくのではなく、明確に説明する』傾向がある」とより広く捉えられるようになった。ただし、ここで明示化とは、翻訳文や書き下し文で使用される品詞（接続詞、副詞、関係代名詞の使用など）の追加で原文の情報を明示化することを指す [@Jia2022Myth; @Puurtinen2004Corpusbased; @Palumbo2009Key]。^[明示化の反対に、暗示化 (law of implicitation) もあり、暗示化とは、暗示のプロセスは「原文では明確に明示されている情報を暗示的にする」ことである [@Bednar2015Social, p: 3]。] -->
<!-- - 重複削減の定理 (reduction of repetition)：翻訳において、原文に存在する重複が減少する [@Baker1993Corpus] -->

<!-- 本稿では、現代語訳の追加要素の存在について、長さ増加の普遍性、明示化の普遍性からしては、それが不思議なものではなく、むしろ翻訳における普遍的な現象である。 -->
<!-- ただし、追加要素が、最終的に本稿の最終目的である歌ことばのノンリテラル的情報の可視化につながっていくかいなかについて、単純な問題ではない。 -->

<!-- - 明示化のルールは、語の説明的補足よりも、翻訳研究ではわかりやすくするための文法的・機能的要素の追加が注目されている。つまり、個々の歌ことばの明示化のための要素ではなく、文の意味の明示化のための要素が主眼になっている。歌ことばのノンリテラル要素の可視化においては、文法的機能的な要素が古今和歌集の翻訳の多くを占めることは望ましくないとしている。 -->
<!-- - 実際、明示化に見えたことは、通時的な変化や、文化的なギャップである可能性もあり [@Mauranen2008Universal p. 39; @Yamamoto2019Analysis, p. 68]  、ノンリテラル要素の可視化においては、文化的ギャップを埋める明示化のほうが望ましい。 -->
<!-- - 文体的に明瞭な表現にする、いわゆる言語の様式（言い換え）の平易化を介した明示化と、翻訳の操作でノンリテラル的な要素の提示による明示化の区別も重要である。後者は情報の詳細化につながるため、本稿においては後者が望ましい。 -->

<!-- ケーススタディの例では、文法的・機能的要素、様式の平易化、通時的変化でない、語の明示化の要素とみられるものも多く観測されていたため、一応、ノンリテラル要素の抽出として価値があると考えている。 -->

<!-- 一方で、翻訳における省略の現象に関連する普遍性については、単純化と、暗示化と、重複の削除^[重複の削除は、前節で説明した現象を包括しているため、前節を参照されたい。] があると思われる。 -->
<!-- 単純化というのは、 -->

<!-- 1. 翻訳において表現が欠落するか、 -->
<!-- 2. 情報が欠落するか、または -->
<!-- 3. 語彙の豊富さ・密度が減るか、 -->

<!-- といった 3 つの側面がある。本稿の目的とかかかるのは、表現の欠落と情報の欠落である。表現が欠落することは、必ずしも情報の欠落を意味しているというわけではないが、語の追加もまた情報の追加を意味しない。この点については、暗示化と関連している。暗示化は、つまり、情報をターゲットテキストの語彙的要素・文法的要素に隠すことであり、情報量を削らない。本稿の議論では、現代語訳と原文の情報量が同等であることを前提にしていることに注意されたい。^[古語の意味は、筆者らが不可知・不可視であると捉える立場に立ち、訳者ができれば情報の欠落なく訳していると仮定している。] -->
<!-- この場合、表現の追加・省略は、訳者が強調したい情報が明らかにし、重要でないと思われている情報が背景にする、いわゆる注意力の配分の問題であると考えられる。追加要素の分析の価値が見出される。ただし、本稿の前提が強めの仮説であることを認めざるをえない、欠落の情報があり暗示化することも確認されていることは、つまり可視化において背景化された情報が不可視のままを意味している。翻訳に基づくノンリテラル可視化の課題のひとつと考えられる。 -->

<!-- 翻訳の標準化・慣習化の普遍性も古今和歌集の現代語訳において、追加と省略、とりわけ言い換え操作の解釈として考えられる。したし、「古今和歌集の注釈書における現代日本語訳」というのは、極めて特殊な例であると考えられる。同言語内の通時的変種間の翻訳であるため、いわゆる外国的な性質の保留はつまり古風的に訳すことになり、しかし、注釈書にある翻訳であるため文学的に訳す必要がない。標準化・慣習化はこのケースでは、どのような現象につながるかは不明であり、翻訳の操作の内実について検討する余地がある。 -->

<!-- このように、現代語訳における追加と省略は、一部は翻訳普遍性仮説で説明することができた。すべての現象についてこの仮説で解釈されることが難しい^[実際、その普遍性は、これらの一般性定理は、結局いずれも反例が存在するため、確率的な傾向、あるいは、普遍性とすることが妥当でであるとされてる [cf., @Pym2008Toury; @Tymoczko1998Computerized; @Chesterman2004Hypotheses; @Chesterman2010Why]。とりもなおさず、一般性といいつつ例外が認めているわけである。 -->
<!-- ] が翻訳を用いて語の非字義的な要素の可視化を目指す本稿では、翻訳普遍性の仮説から価値と課題と両方がみられた。 -->

<!-- 仮説への批判: -->
<!-- 贝克对翻译英语语料库的研究（TEC，Laviosa，1997，1998）局限于英语作为目标语言或源语言，而忽视了作者、体裁和源语言的起源（Martin，2017；Tsai，2020）。 -->
<!-- Pym (2010，第 78 页) 认为，普遍性要求某种语言现象只出现在翻译文本中，而在其他文本中不出现。他认为，这些语言普遍性应该属于翻译文本特征的分类之一。另一方面，实证研究结果（例如Puurtinen，2004 年；Saldanha，2004 年；Becher，2011 年）指出，并非所有翻译都存在此类固有特征，因此研究人员不得不认为，所揭示的现象不可能与所有类型的文本及其翻译背景相关（Tymoczko，1998 年）。 -->
<!-- Tymoczko (1998)等人指出了相关的缺陷。每当需要生成或检验关于普遍性的假设时，就会建立翻译语料库。然而，对于什么应该或不应该算作翻译以纳入该语料库，却并不清楚。例如，我们需要回答一些棘手的问题来决定这一重大步骤，包括询问如果翻译是由目标语言的母语人士完成的并且是最近出版的，是否应该纳入。问题可能还涉及它们是否可以归类为好或坏，或者它们是否由受过训练的专业人士、业余爱好者、团体、粉丝或个人完成，并包含改编或版本。在构建这样的语料库时，需要明确在何处划清纳入项目的界限。 -->

# 結論 {#sec-conclusions}

本稿では、古今和歌集の現代語訳を通じて、原文に含まれるノンリテラル要素を可視化するための材料としての有用性を示すことを目的とし、10種類の現代語訳における追加要素の分析を行った。

具体的には、古今和歌集の現代語訳の全体像を紹介し、20世紀における和歌の現代語訳の翻訳アプローチを、注釈書に記された訳者の意識に基づいて整理した。これにより、訳者の翻訳アプローチを、コミュニケーションモデルの視点から「歌人の作意（source）を重視する」「テキストの字義（signal）を重視する」「読者（destination）を重視する」「その他の明確でないもの」の4種類に分類した。

これらの翻訳意識や翻訳アプローチが、訳文における追加要素や一致率にどのように反映されているかを検討するために、@Yamamoto2019Analysis で行われた追加率の計算手順を明確化し、より明確な設定と更新データを用いて再計算を行った。古語と現代語訳における語レベルでの不一致率および現代語訳における追加率の計算と統計モデリングにより、翻訳アプローチに関わらず、現代語訳には普遍的に情報の追加が見られ、訳者間の追加率の変動が歌間の追加率の変動よりも小さいことを示した。不一致率は、20% を下回る傾向が見受けられ原文の要素の省略が避けられていることが推測できる。これにより、翻訳の追加要素は量的に十分にあることを確認した。

さらに、追加要素が十分にノンリテラル要素として機能するかを確認するために、298番歌「立田」の現代語訳を対象に、10人の訳者によるアライメントを同時に提示し、対象語のコーパスレベルでの共出現語、共出現構文パターン、共出現語の意味志向が、センテンスレベルの現代語訳でどのように処理されているかを調査した。その結果、コーパスレベルで共出現傾向を持つ単位は、センテンスレベルの処理において10人の訳者間で比較的安定した処理が見られた。一方で、共出現傾向のない要素の追加には多様なバリエーションが見られた。特に注目すべき点は、コーパスレベルでの共出現語が訳の推論に用いられ、また、共出現語の意味志向に関連する語が、訳文でより多くの補足的説明を伴うという現象である。一方、構文面の追加は、言語変化のギャップを埋めるためのものであった。

これらの結果から、和歌の現代語訳は、たとえ直訳や逐語訳に拘るものであっても、和歌辞典とは異なる解釈材料として、和歌に含まれるノンリテラル情報を補足し説明するために有用であることを論じた。しかし同時に、言語変化のギャップを埋めるための要素の除外や、翻訳における信頼性の高い要素を選び出す工夫の重要性も示唆された。

# データの公開利用 {.appendix .unnumbered}

公開できるデータである @kaneko1933Kokin による現代語訳の分割語彙データは XXXXX にて参照する。

# 補足材料 {.appendix .unnumbered}

補足資料は、[https://github.com/idiig/replication-test/blob/main/supplementary-materials/補足資料 Supplementary materials.pdf](https://github.com/idiig/replication-test/blob/main/supplementary-materials/補足資料 Supplementary materials.pdf) を参照する。再現実験について、[https://github.com/idiig/replication-test/tree/main](https://github.com/idiig/replication-test/tree/main) を参照する。

# 謝辞 {.appendix .unnumbered}

本研究は、JSPS科研費 JP23K00545, JP23KJ0910 の助成を受けたものである。

# 参考文献 {.appendix .unnumbered}